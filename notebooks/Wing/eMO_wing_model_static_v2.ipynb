{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wing Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "This Jupyter Notebook documents the workflow for developing and evaluating a machine learning model to predict aerodynamic coefficients (lift and drag) for a wing model. The notebook includes the following steps:\n",
    "\n",
    "1. **Import Libraries**: Import necessary libraries and modules for data processing, model building, and evaluation.\n",
    "2. **Set Parameters and Paths**: Define global parameters and paths for data and model storage.\n",
    "3. **Check GPU Availability**: Verify if a GPU is available for model training.\n",
    "4. **Data Preparation**: \n",
    "    - Downsample input data using average pooling.\n",
    "    - Organize input data into a structured format.\n",
    "    - Create custom dataset classes for wing data and simulation data.\n",
    "5. **Model Definition**: \n",
    "    - Define convolutional neural network (CNN) models for predicting lift and drag coefficients.\n",
    "    - Define radial basis function (RBF) network models for airfoil data refining the lift and drag coefficient values.\n",
    "    - Load pre-trained model weights.\n",
    "6. **Dataset Preparation**: \n",
    "    - Prepare the wing dataset by loading and processing CSV files.\n",
    "    - Extract relevant features and target variables.\n",
    "    - The CNN and RBF models are used to perdict airfol level lift and drag coefficients.\n",
    "    - The airfoil-level values are then converted into wing-level values using empirical relations. \n",
    "7. **LSTM Model with Attention**: \n",
    "    - Define an LSTM model with attention mechanism for sequence prediction.\n",
    "    - Set hyperparameters for model training.\n",
    "8. **Data Normalization**: Normalize input and output data using MinMaxScaler.\n",
    "9. **Train-Validation Split**: Split the dataset into training and validation sets.\n",
    "10. **Model Training**: \n",
    "     - Train the LSTM model with attention on the training dataset.\n",
    "     - Evaluate the model on the validation dataset.\n",
    "11. **Loss Visualization**: Plot training and validation loss curves.\n",
    "12. **Model Saving**: Save the trained model and scalers if required.\n",
    "13. **Model Testing**: \n",
    "     - Load test data and make predictions using the trained model.\n",
    "     - Compare predicted results with ground truth data.\n",
    "14. **Evaluation**: \n",
    "     - Compute evaluation metrics such as MAPE, RÂ² score, and relative L2 norm error.\n",
    "     - Print and summarize evaluation results across all test cases.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import torch\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.utils.data import TensorDataset\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "# from torchviz import make_dot\n",
    "from scipy.fftpack import fft, ifft\n",
    "from scipy.interpolate import CubicSpline\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PLOT_RESULTS = False\n",
    "SAVE_TRAINED_MODEL = False\n",
    "\n",
    "project_path = '/mnt/e/eVTOL_model/eVTOL-VehicleModel/'\n",
    "data_path = project_path + 'data/wing_data/'\n",
    "model_path = project_path + 'trained_models/'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "date = datetime.date.today()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if GPU is available\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Downsampling using average pooling\n",
    "\"\"\"\n",
    "Downsample the input array to 35 elements using interpolation.\n",
    "\"\"\"\n",
    "\n",
    "def downsample_to_35(input_array):\n",
    "    input_tensor = torch.tensor(input_array, dtype=torch.float32)\n",
    "    \n",
    "    # Reshape the input to be 1D (if it's not already)\n",
    "    if input_tensor.dim() == 1:\n",
    "        input_tensor = input_tensor.unsqueeze(0).unsqueeze(0)  # Shape (1, 1, original_length)\n",
    "    elif input_tensor.dim() == 2:\n",
    "        input_tensor = input_tensor.unsqueeze(0)  # Shape (1, original_channels, original_length)\n",
    "    \n",
    "    # Perform interpolation to downsample to 35 elements\n",
    "    downsampled_tensor = F.interpolate(input_tensor, size=35, mode='linear', align_corners=True)\n",
    "    \n",
    "    # Remove the unnecessary dimensions to return a 1D tensor\n",
    "    downsampled_array = downsampled_tensor.squeeze().numpy()\n",
    "    \n",
    "    return downsampled_array\n",
    "\n",
    "\"\"\"\n",
    "Create the dataset\n",
    "Arange the input data in columns [x, y, alpha (AOA), Re, M]\n",
    "\"\"\"\n",
    "def organize_data(x_f, y_f, alphas):\n",
    "\n",
    "    Elements = []\n",
    "\n",
    "    # Loop through the polars\n",
    "    for n_file in range(len(x_f)):\n",
    "        x_temp = x_f[n_file]\n",
    "        y_temp = y_f[n_file]\n",
    "        alpha_temp = alphas[n_file]\n",
    "        \n",
    "        for j in range(len(alpha_temp)):\n",
    "            batch = []\n",
    "            # Loop through the coodrinates\n",
    "            for i in range(len(x_temp)-1):\n",
    "                element = np.array([x_temp[i], y_temp[i], x_temp[i+1], y_temp[i+1], alpha_temp[j]])\n",
    "                batch.append(element)\n",
    "            batch = np.array(batch)\n",
    "            batch = batch.flatten()\n",
    "            Elements.append(batch)\n",
    "\n",
    "    Elements = np.array(Elements)\n",
    "\n",
    "    return Elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Element Spatial Convolutional Neural Network model\n",
    "Number of convolutional layers - 4\n",
    "Number of fully connected layers - 2\n",
    "\"\"\"\n",
    "\n",
    "# Model for lift coefficient\n",
    "class ESCNN_Cl(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ESCNN_Cl, self).__init__()\n",
    "        \n",
    "        # Conv1: Assume 1D Convolution\n",
    "        self.conv1 = nn.Conv1d(in_channels=1, out_channels=200, kernel_size=5, stride=5)\n",
    "        self.relu1 = nn.ReLU()\n",
    "\n",
    "        #conv2\n",
    "        self.conv2 = nn.Conv1d(in_channels=200, out_channels=200, kernel_size=1)\n",
    "        self.relu2 = nn.ReLU()\n",
    "\n",
    "        # Conv3\n",
    "        self.conv3 = nn.Conv1d(in_channels=200, out_channels=100, kernel_size=1)\n",
    "        self.relu3 = nn.ReLU()\n",
    "        \n",
    "        # Conv4\n",
    "        self.conv4 = nn.Conv1d(in_channels=100, out_channels=1, kernel_size=5, padding=2)\n",
    "        self.relu4 = nn.ReLU()\n",
    "        \n",
    "        # Final fully connected layer to output scalar\n",
    "        self.fc1 = nn.Linear(in_features=34, out_features=34)\n",
    "        self.relu5 = nn.ReLU()\n",
    "\n",
    "        self.fc2 = nn.Linear(in_features=34, out_features=1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # Reshape input if necessary, ensure it's in the shape (batch_size, channels, elements)\n",
    "        x = x.view(-1, 1, 170)  # Reshape to (batch_size, channel=1, elements=170)\n",
    "        \n",
    "        x = self.conv1(x)  \n",
    "        x = self.relu1(x)\n",
    "        \n",
    "        x = self.conv2(x)  \n",
    "        x = self.relu2(x)\n",
    "\n",
    "        x = self.conv3(x)  \n",
    "        x = self.relu3(x)\n",
    "        \n",
    "        x = self.conv4(x)  \n",
    "        x = self.relu4(x)\n",
    "        \n",
    "        x = torch.flatten(x, 1)\n",
    "        \n",
    "        x = self.fc1(x)  \n",
    "        x = self.relu5(x)\n",
    "\n",
    "        x = self.fc2(x)\n",
    "        \n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Element Spatial Convolutional Neural Network model\n",
    "Number of convolutional layers - 3\n",
    "Number of fully connected layers - 2\n",
    "\"\"\"\n",
    "\n",
    "class ESCNN_Cd(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ESCNN_Cd, self).__init__()\n",
    "        \n",
    "        # Conv1: Assume 1D Convolution\n",
    "        self.conv1 = nn.Conv1d(in_channels=1, out_channels=200, kernel_size=5, stride=5)\n",
    "        self.relu1 = nn.ReLU()\n",
    "\n",
    "        #conv2\n",
    "        self.conv2 = nn.Conv1d(in_channels=200, out_channels=200, kernel_size=1)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        \n",
    "        # Conv2\n",
    "        self.conv3 = nn.Conv1d(in_channels=200, out_channels=1, kernel_size=5, padding=2)\n",
    "        self.relu3 = nn.ReLU()\n",
    "        \n",
    "        # Final fully connected layer to output scalar\n",
    "        self.fc1 = nn.Linear(in_features=34, out_features=34)\n",
    "        self.relu4 = nn.ReLU()\n",
    "\n",
    "        self.fc2 = nn.Linear(in_features=34, out_features=1)\n",
    "\n",
    "        # Define learnable parameters for C_d0 and k\n",
    "        self.Cd0 = nn.Parameter(torch.tensor(0.02))  # Initialized zero-lift drag coefficient\n",
    "        self.k = nn.Parameter(torch.tensor(0.05))    # Initialized induced drag factor\n",
    "\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # Reshape input if necessary, ensure it's in the shape (batch_size, channels, elements)\n",
    "        x = x.view(-1, 1, 170)  # Reshape to (batch_size, channel=1, elements=170)\n",
    "        \n",
    "        x = self.conv1(x)  \n",
    "        x = self.relu1(x)\n",
    "        \n",
    "        x = self.conv2(x)  \n",
    "        x = self.relu2(x)\n",
    "\n",
    "        x = self.conv3(x)  \n",
    "        x = self.relu3(x)\n",
    "        \n",
    "        \n",
    "        x = torch.flatten(x, 1)\n",
    "        \n",
    "        x = self.fc1(x) \n",
    "        x = self.relu4(x)\n",
    "\n",
    "        x = self.fc2(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize airfoil model (Use the saved trained model)\n",
    "\n",
    "# Cl Model\n",
    "class RBFLayer_cl(nn.Module):\n",
    "    def __init__(self, in_features, out_features, centers=None):\n",
    "        super(RBFLayer_cl, self).__init__()\n",
    "        self.in_features = in_features\n",
    "        self.out_features = out_features\n",
    "        \n",
    "        # Centers initialized using KMeans or passed explicitly\n",
    "        if centers is None:\n",
    "            self.centers = nn.Parameter(torch.Tensor(out_features, in_features))\n",
    "            nn.init.uniform_(self.centers, -1, 1)  # Random if not initialized with KMeans\n",
    "        else:\n",
    "            self.centers = nn.Parameter(torch.Tensor(centers))  # Set centers from KMeans\n",
    "        \n",
    "        # Initialize the beta (width) parameter, positive constraint with softplus\n",
    "        self.log_beta = nn.Parameter(torch.ones(out_features) * torch.log(torch.tensor(0.1)))\n",
    "\n",
    "    @property\n",
    "    def beta(self):\n",
    "        # Ensures beta is positive using softplus\n",
    "        return F.softplus(self.log_beta)\n",
    "    \n",
    "    def forward(self, input):\n",
    "        # Compute distances between inputs and centers\n",
    "        x = input.unsqueeze(1).expand(-1, self.out_features, self.in_features)\n",
    "        c = self.centers.unsqueeze(0).expand(input.size(0), -1, -1)\n",
    "        \n",
    "        # Squared Euclidean distance\n",
    "        distances = torch.sum((x - c) ** 2, dim=-1).to(device)\n",
    "        \n",
    "        # Apply Gaussian RBF\n",
    "        return torch.exp(-self.beta.unsqueeze(0) * distances)\n",
    "\n",
    "class RBFNet_cl(nn.Module):\n",
    "    def __init__(self, input_size, rbf_units, output_size, centers=None):\n",
    "        super(RBFNet_cl, self).__init__()\n",
    "        self.rbf = RBFLayer_cl(input_size, rbf_units, centers)\n",
    "        self.fc = nn.Linear(rbf_units, output_size)\n",
    "        \n",
    "        # Initialize weights for the linear layer\n",
    "        nn.init.xavier_uniform_(self.fc.weight)\n",
    "        nn.init.zeros_(self.fc.bias)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        rbf_out = self.rbf(x)\n",
    "        return self.fc(rbf_out)\n",
    "\n",
    "# Cd Model\n",
    "class RBFLayer_cd(nn.Module):\n",
    "    def __init__(self, in_features, out_features, centers=None):\n",
    "        super(RBFLayer_cd, self).__init__()\n",
    "        self.in_features = in_features\n",
    "        self.out_features = out_features\n",
    "        \n",
    "        # Centers initialized using KMeans or passed explicitly\n",
    "        if centers is None:\n",
    "            self.centers = nn.Parameter(torch.Tensor(out_features, in_features))\n",
    "            nn.init.uniform_(self.centers, -1, 1)  # Random if not initialized with KMeans\n",
    "        else:\n",
    "            self.centers = nn.Parameter(torch.Tensor(centers))  # Set centers from KMeans\n",
    "        \n",
    "        # Initialize the beta (width) parameter, positive constraint with softplus\n",
    "        self.log_beta = nn.Parameter(torch.ones(out_features) * torch.log(torch.tensor(18.2)))\n",
    "\n",
    "    @property\n",
    "    def beta(self):\n",
    "        # Ensures beta is positive using softplus\n",
    "        return F.softplus(self.log_beta)\n",
    "    \n",
    "    def forward(self, input):\n",
    "        # Compute distances between inputs and centers\n",
    "        x = input.unsqueeze(1).expand(-1, self.out_features, self.in_features)\n",
    "        c = self.centers.unsqueeze(0).expand(input.size(0), -1, -1)\n",
    "        \n",
    "        # Squared Euclidean distance\n",
    "        distances = torch.sum((x - c) ** 2, dim=-1).to(device)\n",
    "        \n",
    "        # Apply Gaussian RBF\n",
    "        return torch.exp(-self.beta.unsqueeze(0) * distances)\n",
    "\n",
    "class RBFNet_cd(nn.Module):\n",
    "    def __init__(self, input_size, rbf_units, output_size, centers=None):\n",
    "        super(RBFNet_cd, self).__init__()\n",
    "        self.rbf = RBFLayer_cd(input_size, rbf_units, centers)\n",
    "        self.fc = nn.Linear(rbf_units, output_size)\n",
    "        \n",
    "        # Initialize weights for the linear layer\n",
    "        nn.init.xavier_uniform_(self.fc.weight)\n",
    "        nn.init.zeros_(self.fc.bias)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        rbf_out = self.rbf(x)\n",
    "        return self.fc(rbf_out)\n",
    "     \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the model weights\n",
    "af_model_ESCNN_Cl = ESCNN_Cl()\n",
    "af_model_ESCNN_Cl.load_state_dict(torch.load(model_path+'/models/airfoil/2024-11-18_model_Cl_ESCNN_lr1e-05_e1500_rbf170_convL4.pth'))\n",
    "af_model_ESCNN_Cl = af_model_ESCNN_Cl.to(device)\n",
    "af_model_ESCNN_Cl.eval()\n",
    "\n",
    "# Load the model weights\n",
    "af_model_ESCNN_Cd = ESCNN_Cd()\n",
    "af_model_ESCNN_Cd.load_state_dict(torch.load(model_path+'/models/airfoil/2024-11-18_model_Cd_ESCNN_lr5e-05_e250_convL3.pth'))\n",
    "af_model_ESCNN_Cd = af_model_ESCNN_Cd.to(device)\n",
    "af_model_ESCNN_Cd.eval()\n",
    "\n",
    "\n",
    "\n",
    "input_size = 140\n",
    "output_size = 4\n",
    "num_rbf_units = 4\n",
    "\n",
    "kmeans_center_cl = torch.load(model_path+'/models/airfoil/2024-11-19_airfoil_model_Cl_ESCNN_RBF_lr0.06_epoch200_rbfUnits4_RBFcenters.pth')\n",
    "kmeans_center_cd = torch.load(model_path+'/models/airfoil/2024-11-19_airfoil_model_Cd_ESCNN_RBF_lr0.025_epoch100_rbfUnits4_RBFcenters.pth')\n",
    "\n",
    "\n",
    "class airfoilModel_cl(RBFNet_cl):\n",
    "    def __init__(self):\n",
    "        super(airfoilModel_cl, self).__init__(input_size, num_rbf_units, output_size, kmeans_center_cl)\n",
    "\n",
    "\n",
    "class airfoilModel_cd(RBFNet_cd):\n",
    "    def __init__(self):\n",
    "        super(airfoilModel_cd, self).__init__(input_size, num_rbf_units, output_size, kmeans_center_cd)\n",
    "\n",
    "\n",
    "# Initialize the model\n",
    "airfoil_cl = airfoilModel_cl()\n",
    "airfoil_cl.load_state_dict(torch.load(model_path+'/models/airfoil/2024-11-19_airfoil_model_Cl_ESCNN_RBF_lr0.06_epoch200_rbfUnits4.pth'))\n",
    "\n",
    "airfoil_cd = airfoilModel_cd()\n",
    "airfoil_cd.load_state_dict(torch.load(model_path+'/models/airfoil/2024-11-19_airfoil_model_Cd_ESCNN_RBF_lr0.025_epoch100_rbfUnits4.pth'))\n",
    "\n",
    "airfoil_cl = airfoil_cl.to(device)\n",
    "airfoil_cd = airfoil_cd.to(device)\n",
    "\n",
    "airfoil_cl.eval()\n",
    "airfoil_cd.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare wing dataset\n",
    "\n",
    "# Condition function to filter subdirectories\n",
    "def subdir_condition(subdir_name):\n",
    "    \"\"\"\n",
    "    Condition: Only process subdirectories whose names start with 'propeller-example_dji'.\n",
    "    Modify this function to apply a specific filtering logic.\n",
    "    \"\"\"\n",
    "    return subdir_name.startswith('wing_dataset')  # Change this condition as needed\n",
    "\n",
    "\n",
    "class WingDataset(Dataset):\n",
    "    def __init__(self, root_dir, af_data_path='/mnt/e/Course_Materials/ROM/wing_model/wing_section/small_database_testing_csv', subdir_condition=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            root_dir (string): Root directory with subdirectories containing CSV files.\n",
    "            af_data_path (string): Airfoil polar database directory contaiing airfoil polars of used airfoils.            \n",
    "            subdir_condition (callable, optional): A function or condition to filter subdirectories by name.\n",
    "        \"\"\"\n",
    "        self.root_dir = root_dir\n",
    "        self.data = []\n",
    "        self.targets = []\n",
    "        self.time_data = []  # Store time data separately\n",
    "        self.AOA_data = []\n",
    "        self.v_inf_data = []\n",
    "        self.cl_data = []\n",
    "        self.cd_data = []\n",
    "\n",
    "        self.cl_data = []\n",
    "        self.cd_data = []\n",
    "        self.fft_cl_r = []\n",
    "        self.fft_cl_i = []\n",
    "        self.fft_cd_r = []\n",
    "        self.fft_cd_i = []\n",
    "        \n",
    "        self.subdir_condition = subdir_condition\n",
    "        self.af_data_path = af_data_path\n",
    "\n",
    "        # Traverse the root directory to gather data\n",
    "        self._load_data()\n",
    "\n",
    "    def _load_data(self):\n",
    "        \"\"\"\n",
    "        Helper function to read CSV files from each subdirectory and extract relevant columns.\n",
    "        \"\"\"\n",
    "        # Iterate through each subdirectory in the root directory\n",
    "        for subdir, _, files in os.walk(self.root_dir):\n",
    "            subdir_name = os.path.basename(subdir)\n",
    "            \n",
    "            # Apply subdirectory name condition\n",
    "            if self.subdir_condition and not self.subdir_condition(subdir_name):\n",
    "                continue\n",
    "\n",
    "            for file in files:\n",
    "\n",
    "                if file.endswith(\"_convergence.csv\"):\n",
    "                    # Load the CSV file\n",
    "                    csv_path = os.path.join(subdir, file)\n",
    "                    df = pd.read_csv(csv_path)\n",
    "                    \n",
    "                    # Extract necessary columns for input features from wing_convergence.csv\n",
    "                    time = df['T'].values  # Time\n",
    "                    \n",
    "                    v_inf = df['Vinf'].values\n",
    "                    AOA = df['alpha(eff)'].values\n",
    "                    theta = df['theta'].values\n",
    "                    vz = df['vVehicle_z'].values\n",
    "                                        \n",
    "                    # Extract Cl and Cq for output variables\n",
    "                    cl = df['CL'].values  # Lift coefficient (CL)\n",
    "                    cd = df['CD'].values  # Drag coefficient (CD)\n",
    "\n",
    "                    fft_cl = fft(cl)\n",
    "                    fft_cl_real = np.real(fft_cl)\n",
    "                    fft_cl_imag = np.imag(fft_cl)\n",
    "\n",
    "                    fft_cd = fft(cd)\n",
    "                    fft_cd_real = np.real(fft_cd)\n",
    "                    fft_cd_imag = np.imag(fft_cd)\n",
    "\n",
    "                    # Add the geometry parameters\n",
    "                    geom_data_path = os.path.join(subdir, 'wing_geometry_data.csv')         # Read from wing_geometry_data.csv file - b, ar, tr, sweep, dihedral\n",
    "                    geom_df = pd.read_csv(geom_data_path, nrows=1)\n",
    "\n",
    "                    ones_empty = np.ones_like(time)                                         # Empty array of ones\n",
    "                    \n",
    "                    b_data = geom_df[\"b_wing\"].values\n",
    "                    b_data_array = geom_df[\"b_wing\"].values * ones_empty                    # Making this an array simplifies things later\n",
    "                    \n",
    "                    ar_data = geom_df[\"ar_wing\"].values\n",
    "                    ar_data_array = geom_df[\"ar_wing\"].values * ones_empty\n",
    "                    \n",
    "                    tr_data = geom_df[\"tr\"].values\n",
    "                    tr_data_array = geom_df[\"tr\"].values * ones_empty\n",
    "\n",
    "                    sweep_data = geom_df[\"lambda\"].values\n",
    "                    sweep_data_array = geom_df[\"lambda\"].values * ones_empty\n",
    "                    \n",
    "                    gamma_data = geom_df[\"gamma\"].values\n",
    "                    gamma_data_array = geom_df[\"gamma\"].values * ones_empty\n",
    "                    \n",
    "                    # Store the following in separate lists for easy access\n",
    "                    self.time_data.append(time)\n",
    "                    self.AOA_data.append(AOA)\n",
    "                    self.v_inf_data.append(v_inf)\n",
    "                    \n",
    "                    self.cl_data.append(cl)\n",
    "                    self.cd_data.append(cd)\n",
    "\n",
    "                    self.fft_cl_r.append(fft_cl_real)\n",
    "                    self.fft_cl_i.append(fft_cl_imag)\n",
    "                    self.fft_cd_r.append(fft_cd_real)\n",
    "                    self.fft_cd_i.append(fft_cd_imag)\n",
    "\n",
    "                    # Extract the airfoil details\n",
    "                    af_name = geom_df[\"airfoil \"].values\n",
    "                    extension = '.csv'\n",
    "                    af_name = str(af_name[0]+extension)\n",
    "\n",
    "                    af_name_new = af_name.split('-')\n",
    "                    af_coordinate = str(af_name_new[1]+'_coordinates.dat')          # Name of airfoil coordinates. Adjust it according to the names being used\n",
    "                    # print(af_coordinate)\n",
    "                    \n",
    "                    af_polar_data = pd.read_csv(os.path.join(self.af_data_path, af_name), skiprows=10)\n",
    "                    # af_polar_data = af_polar_data[[(af_polar_data[\"Alpha\"] >= -2) & (af_polar_data[\"Alpha\"] <= 12)]]\n",
    "                    # af_coordinate_data = pd.read_csv(os.path.join(self.af_data_path, af_coordinate), delim_whitespace=True)  # or use delimiter=','\n",
    "                    af_coordinate_data = np.loadtxt(os.path.join(self.af_data_path, af_coordinate))\n",
    "\n",
    "                    af_coordinate_x = af_coordinate_data[:,0]\n",
    "                    af_coordinate_y = af_coordinate_data[:,1] \n",
    "\n",
    "                    AOA_af_polar = af_polar_data[\"Alpha\"].values\n",
    "                    cl_af_polar = af_polar_data[\"Cl\"].values\n",
    "                    cd_af_polar = af_polar_data[\"Cd\"].values\n",
    "\n",
    "                    # Fit a polynomial to Cl and Cd data\n",
    "                    # Create cubic spline interpolation\n",
    "                    spline_cl_airfoil = CubicSpline(AOA_af_polar, cl_af_polar)\n",
    "                    spline_cd_airfoil = CubicSpline(AOA_af_polar, cd_af_polar)\n",
    "\n",
    "                    cl_poly_coeff = np.polyfit(AOA_af_polar, cl_af_polar, deg=6)\n",
    "                    cd_poly_coeff = np.polyfit(AOA_af_polar, cd_af_polar, deg=6)\n",
    "\n",
    "                    cl_airfoil_calc = spline_cl_airfoil(AOA)\n",
    "                    cd_airfoil_calc = spline_cd_airfoil(AOA)\n",
    "\n",
    "                    #-------------------------------------------------------------------------------------------------------------------\n",
    "                    # Note - To determine the airfoil aerodynamic coefficients, there are two approaaches.\n",
    "                    # 1. Use the polar file from the database to fit a polynomial function and then estimate the Cl/Cd for any given AOA.\n",
    "                    # 2. USe the pre-trained Neural Network to predict the Cl/Cd.  \n",
    "                    #-------------------------------------------------------------------------------------------------------------------\n",
    "                    \n",
    "                    # Using approach 2 - Using RBF NN to predict the Cl and Cd\n",
    "                    #-------------------------------------------------------------------------------------------------------------------\n",
    "                \n",
    "                    degree = 3\n",
    "                    \n",
    "                    input_sequence_cl_NN = []\n",
    "                    input_sequence_cd_NN = []\n",
    "\n",
    "                    # Prepare the data to input to ESCNN Model\n",
    "                    x_escnn = np.array(downsample_to_35(af_coordinate_x)).reshape(1, -1)\n",
    "                    y_escnn = np.array(downsample_to_35(af_coordinate_y)).reshape(1, -1)\n",
    "                    aoa_escnn = np.array(AOA_af_polar).reshape(1, -1)\n",
    "\n",
    "                    elements_ESCNN = organize_data(x_escnn, y_escnn, aoa_escnn)\n",
    "\n",
    "                    if elements_ESCNN.shape != (0,):\n",
    "                        input_escnn = elements_ESCNN\n",
    "\n",
    "                        input_escnn = torch.tensor(input_escnn, dtype=torch.float32).to(device)\n",
    "\n",
    "                        # Evaluate the model on test dataset\n",
    "                        with torch.no_grad():\n",
    "                            Cl_escnn_pred = af_model_ESCNN_Cl.forward(input_escnn)\n",
    "                            Cd_escnn_pred = af_model_ESCNN_Cd.forward(input_escnn)\n",
    "                            \n",
    "                        Cl_escnn_pred = Cl_escnn_pred.cpu().detach().numpy()  # Convert tensor to numpy array\n",
    "                        Cl_escnn_pred = Cl_escnn_pred.squeeze(1)\n",
    "\n",
    "                        Cd_escnn_pred = Cd_escnn_pred.cpu().detach().numpy()  # Convert tensor to numpy array\n",
    "                        Cd_escnn_pred = Cd_escnn_pred.squeeze(1)\n",
    "\n",
    "                        plt_af_polar_comparison = False     # If needed for debugging\n",
    "                        if plt_af_polar_comparison == True:\n",
    "                            plt.figure()\n",
    "                            # plt.plot(aoa_test[j], Cl_escnn_pred)\n",
    "                            # # plt.plot(alphas_t[0], Cl_eval_org_scale)\n",
    "                            # plt.plot(aoa_test[j], cl_test[j])\n",
    "\n",
    "                            plt.legend(['NN Model - ESCNN', 'UIUC database'])\n",
    "                            # plt.title(r'$C_d$ vs $\\alpha$ for {} airfoil'.format(keyword))\n",
    "                            plt.xlabel(r'AOA [$\\alpha$]')\n",
    "                            plt.ylabel(r'$C_l$')\n",
    "\n",
    "                    else:\n",
    "                        continue\n",
    "\n",
    "                    af_coordinate_x_i = downsample_to_35(af_coordinate_x)\n",
    "                    af_coordinate_y_i = downsample_to_35(af_coordinate_y)\n",
    "                    AOA_af_polar_i = downsample_to_35(AOA_af_polar)\n",
    "                    cl_af_polar_i = downsample_to_35(Cl_escnn_pred)\n",
    "                    cd_af_polar_i = downsample_to_35(Cd_escnn_pred)\n",
    "\n",
    "                    input_sequence_cl_NN = [\n",
    "                                            af_coordinate_x_i, af_coordinate_y_i, AOA_af_polar_i, cl_af_polar_i\n",
    "                                        ]\n",
    "                    \n",
    "                    input_sequence_cd_NN = [\n",
    "                                            af_coordinate_x_i, af_coordinate_y_i, AOA_af_polar_i, cd_af_polar_i\n",
    "                                        ]\n",
    "\n",
    "\n",
    "\n",
    "                    input_sequence_cl_NN = np.array(input_sequence_cl_NN, dtype=float).reshape(1, -1)\n",
    "                    input_sequence_cd_NN = np.array(input_sequence_cd_NN, dtype=float).reshape(1, -1)\n",
    "                    \n",
    "                    # print(\"Airfoil Cl NN - Input shape: \", input_sequence_cl_NN.shape)\n",
    "                    # print(\"Airfoil Cd NN - Input shape: \", input_sequence_cd_NN.shape)\n",
    "\n",
    "                    NN_cl_model_ip_data = torch.tensor(input_sequence_cl_NN, dtype=torch.float32).to(device) \n",
    "                    NN_cd_model_ip_data = torch.tensor(input_sequence_cd_NN, dtype=torch.float32).to(device) \n",
    "\n",
    "            \n",
    "                    # Neural network model to predict the airfoil aerodynamic coeficients    \n",
    "                    with torch.no_grad():  # Disable gradient computation for inference\n",
    "                        predicted_coefficients_cl = airfoil_cl(NN_cl_model_ip_data)\n",
    "                        predicted_coefficients_cd = airfoil_cd(NN_cd_model_ip_data)\n",
    "\n",
    "                    predicted_af_coefficients_cl = predicted_coefficients_cl.cpu().detach().numpy()\n",
    "                    predicted_af_coefficients_cd = predicted_coefficients_cd.cpu().detach().numpy()\n",
    "                    \n",
    "                    # print(predicted_af_coefficients_cl)\n",
    "\n",
    "                    # polynomial_cl_new = np.poly1d(predicted_coefficients[0])\n",
    "                    polynomial_cl_pred = np.poly1d(predicted_af_coefficients_cl[0])\n",
    "                    polynomial_cd_pred = np.poly1d(predicted_af_coefficients_cd[0])\n",
    "\n",
    "                    x_new = np.linspace(AOA_af_polar[0], AOA_af_polar[-1], 100)\n",
    "                    # y_new_cl = polynomial_cl_new(x_new_cl)\n",
    "                    y_new_cl = polynomial_cl_pred(x_new)\n",
    "                    y_new_cd = polynomial_cd_pred(x_new)\n",
    "\n",
    "                    \n",
    "\n",
    "                    # # plt.figure()\n",
    "                    plt_af_polar_NN = False\n",
    "                    if plt_af_polar_NN == True:\n",
    "                        plt.figure(figsize=(15, 5))\n",
    "                        # plt.title(af_name)\n",
    "                        \n",
    "                        plt.subplot(1,2,1)\n",
    "                        plt.plot(AOA_af_polar, cl_af_polar, color='red', label='UIUC Database')\n",
    "                        plt.plot(x_new, y_new_cl, label=f'Polynomial Degree {degree} - NN')\n",
    "                        plt.xlabel(r'$\\alpha$')\n",
    "                        plt.ylabel(r'$C_l$')\n",
    "                        plt.title(af_name)\n",
    "                        plt.legend()\n",
    "\n",
    "\n",
    "                        plt.subplot(1,2,2)\n",
    "                        plt.plot(AOA_af_polar, cd_af_polar, color='red', label='UIUC Database')\n",
    "                        plt.plot(x_new, y_new_cd, label=f'Polynomial Degree {degree} - NN')\n",
    "                        plt.xlabel(r'$\\alpha$')\n",
    "                        plt.ylabel(r'$C_d$')\n",
    "                        plt.title(af_name)\n",
    "                        plt.legend()\n",
    "                    \n",
    "                    \n",
    "                    cl_af_NN = polynomial_cl_pred(AOA)\n",
    "                    cd_af_NN = polynomial_cd_pred(AOA)\n",
    "\n",
    "\n",
    "                    # print(cl_af_NN)\n",
    "                    # print(cl_airfoil_calc)\n",
    "                    plt_af_lvl_coeff = False\n",
    "                    if plt_af_lvl_coeff==True:\n",
    "                        plt.figure(figsize=(15, 5))\n",
    "                        \n",
    "                        \n",
    "                        plt.subplot(1,2,1)\n",
    "                        plt.plot(time, cl_airfoil_calc, color='red', label='UIUC Database')\n",
    "                        plt.plot(time, cl_af_NN, label=f'Polynomial Degree {degree} - NN')\n",
    "                        plt.xlabel(r'$\\alpha$')\n",
    "                        plt.ylabel(r'$C_l$')\n",
    "                        plt.title(af_name)\n",
    "                        plt.legend()\n",
    "\n",
    "                        plt.subplot(1,2,2)\n",
    "                        plt.plot(time, cd_airfoil_calc, color='red', label='UIUC Database')\n",
    "                        plt.plot(time, cd_af_NN, label=f'Polynomial Degree {degree} - NN')\n",
    "                        plt.xlabel(r'$\\alpha$')\n",
    "                        plt.ylabel(r'$C_d$')\n",
    "                        plt.title(af_name)\n",
    "                        plt.legend()\n",
    "                    \n",
    "                    #-------------------------------------------------------------------------------------------------------------------\n",
    "                    # Calculate the Cl and Cd using the emperical equations using airfoil aerodynamic coefficients\n",
    "                    # Calculate Wing Aerodynamic Coefficients\n",
    "\n",
    "                    vel_comp_factor_cl = 0.01                # Assumed from trial & error. Depends on flow velocity and wing geometry\n",
    "                    vel_comp_factor_cd = 0.00005              # Assumed from trial & error. Depends on flow velocity and wing geometry\n",
    "                    e = 0.85                                # Oswald factor\n",
    "\n",
    "                    # cl_wing_calc = cl_airfoil_calc / (1 + cl_airfoil_calc / (np.pi * ar_data * e)) * vel_comp_factor_cl\n",
    "\n",
    "                    # cd_induced = (cl_wing_calc ** 2) / (np.pi * ar_data * e) * vel_comp_factor_cd\n",
    "\n",
    "                    cl_wing_calc = cl_af_NN / (1 + cl_af_NN / (np.pi * ar_data * e)) * vel_comp_factor_cl\n",
    "\n",
    "                    cd_induced = (cl_wing_calc ** 2) / (np.pi * ar_data * e) * vel_comp_factor_cd\n",
    "\n",
    "                    # Step 5: Total drag coefficient for the wing\n",
    "                    cd_wing_calc = cd_af_NN + cd_induced\n",
    "                    # cd_wing_calc = cd_airfoil_calc + cd_induced\n",
    "\n",
    "                    # For each simulation, the input sequence is structured as (n_timesteps, n_features)\n",
    "                    sequence_inputs = []\n",
    "                    sequence_outputs = []\n",
    "                    for i in range(len(time)):\n",
    "                        input_data = [\n",
    "                            time[i], AOA[i], v_inf[i], b_data_array[i], ar_data_array[i], tr_data_array[i], sweep_data_array[i], \n",
    "                            gamma_data_array[i], cl_wing_calc[i], cd_wing_calc[i]\n",
    "                        ]\n",
    "                        output_data = [cl[i], cd[i]]\n",
    "                        \n",
    "                        \n",
    "                        sequence_inputs.append(input_data)\n",
    "                        sequence_outputs.append(output_data)\n",
    "\n",
    "                    sequence_inputs = np.array([sequence_inputs], dtype=float)\n",
    "                    sequence_outputs = np.array([sequence_outputs], dtype=float)\n",
    "\n",
    "                    # Append input sequence (n_timesteps, num_features) and output (Cl, Cd)\n",
    "                    self.data.append(sequence_inputs)\n",
    "                    self.targets.append(sequence_outputs)  # Append the whole Cl and Cd sequences\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"\n",
    "        Returns the total number of sequences in the dataset.\n",
    "        \"\"\"\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"\n",
    "        Returns a single sequence and its targets.\n",
    "        \"\"\"\n",
    "        inputs = self.data[idx]  # Input sequence: (n_timesteps, n_features)\n",
    "        targets = self.targets[idx]  # Output: (n_timesteps, 2)\n",
    "        # return inputs, targets\n",
    "        return torch.tensor(inputs, dtype=torch.float32), torch.tensor(targets, dtype=torch.float32)\n",
    "\n",
    "    def get_variable(self, variable_name):\n",
    "        \"\"\"\n",
    "        Returns a list of arrays for the specified variable.\n",
    "        Args:\n",
    "            'time' - timesteps\n",
    "            \n",
    "        \"\"\"\n",
    "        if variable_name == 'time':\n",
    "            return self.time_data  # Return all time steps for each simulation\n",
    "        elif variable_name == 'CL':\n",
    "            return self.cl_data  # Return all omega (RPM) values for each simulation\n",
    "        elif variable_name == 'CD':\n",
    "            return self.cd_data\n",
    "        elif variable_name == 'AOA':\n",
    "            return self.AOA_data\n",
    "        elif variable_name == 'Vinf':\n",
    "            return self.v_inf_data  \n",
    "        elif variable_name == 'fft_cl':\n",
    "            return self.fft_cl_r, self.fft_cl_i \n",
    "        elif variable_name == 'fft_cd':\n",
    "            return self.fft_cd_r, self.fft_cd_i \n",
    "        else:\n",
    "            raise ValueError(f\"Variable {variable_name} not supported.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the custom dataset class\n",
    "# Creates training and validation datasets\n",
    "class SimulationDataset(Dataset):\n",
    "    def __init__(self, inputs, outputs):\n",
    "        self.inputs = inputs\n",
    "        self.outputs = outputs\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.inputs)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return torch.tensor(self.inputs[idx], dtype=torch.float32), torch.tensor(self.outputs[idx], dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_train = data_path + '/training_data/'\n",
    "\n",
    "# Wing geometry\n",
    "b               = 2.489                     # (m) span length\n",
    "ar              = 5.0                       # Aspect ratio b/c_tip\n",
    "tr              = 1.0                       # Taper ratio c_tip/c_root\n",
    "twist_root      = 0.0                       # (deg) twist at root\n",
    "twist_tip       = 0.0                       # (deg) twist at tip\n",
    "sweep          = 45.0                       # (deg) sweep\n",
    "gamma           = 0.0                       # (deg) dihedral\n",
    "\n",
    "dataset = WingDataset(root_train, subdir_condition=subdir_condition)\n",
    "inputs, outputs = dataset[0:]\n",
    "\n",
    "input_tensor = inputs.squeeze(1)  # Reshaping\n",
    "print(\"Input shape:\", input_tensor.shape)  # Should print: torch.Size([6, 145, 7])\n",
    "\n",
    "output_tensor = outputs.squeeze(1)\n",
    "print(\"Output shape:\",output_tensor.shape)  # Should print: torch.Size([6, 145, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMNetWithAttention(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, num_layers, num_heads, bias=0.0):\n",
    "        super(LSTMNetWithAttention, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        # LSTM layer\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True, dropout=0.2)\n",
    "\n",
    "        # Multi-head attention layer\n",
    "        self.multihead_attention = nn.MultiheadAttention(hidden_size, num_heads, batch_first=True)\n",
    "\n",
    "        # Fully connected output layer\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        x: Input tensor of shape (batch_size, seq_length, input_size)\n",
    "        \"\"\"\n",
    "        # Pass through LSTM\n",
    "        lstm_out, _ = self.lstm(x)  # lstm_out: (batch_size, seq_length, hidden_size)\n",
    "\n",
    "        # Multi-head attention: Query, Key, and Value are all lstm_out\n",
    "        attention_output, attention_weights = self.multihead_attention(lstm_out, lstm_out, lstm_out)\n",
    "\n",
    "        # Pass attention output through the fully connected layer\n",
    "        output = self.fc(attention_output)  # (batch_size, seq_length, output_size)\n",
    "\n",
    "        # Add bias to the output\n",
    "        output = output + self.bias\n",
    "\n",
    "        return output, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "input_size = 10     # Number of input features (e.g., 7 input variables)\n",
    "hidden_size = 50    # Number of LSTM units (hidden state size)\n",
    "output_size = 2     # Number of output features (e.g., 2 for thrust and torque coefficients)\n",
    "num_layers = 2      # Number of LSTM layers\n",
    "learning_rate = 5e-4\n",
    "num_epochs = 2000\n",
    "batch_size = 8\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize scalers for input and output\n",
    "input_scaler = MinMaxScaler()\n",
    "output_scaler = MinMaxScaler()\n",
    "\n",
    "# Reshape data for scaling (flatten along the time dimension)\n",
    "inputs_reshaped = input_tensor.reshape(-1, input_size)\n",
    "outputs_reshaped = output_tensor.reshape(-1, output_size)\n",
    "\n",
    "print(inputs_reshaped.shape)\n",
    "print(outputs_reshaped.shape)\n",
    "\n",
    "# Fit and transform inputs and outputs\n",
    "inputs_normalized = input_scaler.fit_transform(inputs_reshaped).reshape(input_tensor.shape)\n",
    "outputs_normalized = output_scaler.fit_transform(outputs_reshaped).reshape(output_tensor.shape)\n",
    "\n",
    "print(\"Normalized input shape:\", inputs_normalized.shape)\n",
    "print(\"Normalized output shape:\", outputs_normalized.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split dataset randomly\n",
    "inputs_train, inputs_val, outputs_train, outputs_val = train_test_split(\n",
    "    inputs_normalized, outputs_normalized, test_size=0.25, random_state=42, shuffle=True\n",
    ")\n",
    "\n",
    "# Create datasets\n",
    "train_dataset = SimulationDataset(inputs_train, outputs_train)\n",
    "val_dataset = SimulationDataset(inputs_val, outputs_val)\n",
    "\n",
    "# Create DataLoaders\n",
    "trainDataLoader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)  \n",
    "valDataLoader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)  # No need to shuffle validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate model, loss function, and optimizer\n",
    "\n",
    "num_heads = 2\n",
    "bias = 0.1\n",
    "model = LSTMNetWithAttention(input_size, hidden_size, output_size, num_layers, num_heads, bias).to(device)\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Lists to store losses\n",
    "train_losses = []\n",
    "eval_losses = []\n",
    "\n",
    "print(\"[INFO] training the network...\")\n",
    "\n",
    "# Training Loop\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    \n",
    "    for inputs, targets in trainDataLoader:\n",
    "        inputs, targets = inputs.squeeze(1).to(device), targets.squeeze(1).to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        outputs, attention_weights = model(inputs)\n",
    "        \n",
    "        loss = criterion(outputs, targets)\n",
    "\n",
    "        # Backward pass and optimization\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "\n",
    "    avg_train_loss = running_loss / len(trainDataLoader)\n",
    "    train_losses.append(avg_train_loss)\n",
    "\n",
    "\n",
    "    # Evaluation Loop\n",
    "    model.eval()\n",
    "    eval_loss = 0.0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, targets in valDataLoader:\n",
    "            inputs, targets = inputs.squeeze(1).to(device), targets.squeeze(1).to(device)\n",
    "            \n",
    "            # Forward pass\n",
    "            outputs, attention_weights = model(inputs)\n",
    "\n",
    "            loss = criterion(outputs, targets)\n",
    "\n",
    "            eval_loss += loss.item()\n",
    "\n",
    "        avg_eval_loss = eval_loss / len(valDataLoader)\n",
    "        eval_losses.append(avg_eval_loss)\n",
    "    \n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}],\\n Training Loss: {running_loss/len(trainDataLoader):.4f}')\n",
    "    print(f'Evaluation Loss: {eval_loss/len(valDataLoader):.4f}')\n",
    "\n",
    "\n",
    "print(\"\\nFinished Training...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6), dpi=300)  # High-resolution plot\n",
    "\n",
    "plt.plot(train_losses, color='black', linewidth=1.5, label=\"Training loss\")\n",
    "plt.plot(eval_losses, color='red', linewidth=1.5, label=\"Validation loss\")\n",
    "plt.title(\"Training Loss and Validation Loss\", fontsize=12)\n",
    "plt.grid(True, linestyle='--', linewidth=0.5)\n",
    "plt.xlabel(\"Epoch\", fontsize=10)\n",
    "plt.ylabel(\"MSE Loss\", fontsize=10)\n",
    "plt.legend(loc='upper right', fontsize=10)\n",
    "# plt.gca().set_aspect('equal', adjustable='box')  # Maintain correct aspect ratio\n",
    "# plt.savefig(\"wing_model_loss.pdf\", format=\"pdf\", dpi=300, bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if SAVE_TRAINED_MODEL:\n",
    "\n",
    "    save_path =  model_path + '/models/wing/{}_LSTM_eMO_wingModel_static_lr{}_e{}_nL{}_numNN{}.pth'.format(date, learning_rate, num_epochs, num_layers, hidden_size)\n",
    "    print(\"The model will be saved as the following:\\n {}\".format(save_path))\n",
    "\n",
    "    torch.save(model.state_dict(), save_path)\n",
    "\n",
    "    # Save the scalers\n",
    "    joblib.dump(input_scaler, model_path+'/scalers/wing/{}_LSTM_eMO_wingModel_static_ipScaler_lr{}_e{}_nL{}_numNN{}.pkl'.format(date, learning_rate, num_epochs, num_layers, hidden_size))\n",
    "    joblib.dump(output_scaler, model_path+'/scalers/wing/{}_LSTM_eMO_wingModel_static_opScaler_lr{}_e{}_nL{}_numNN{}.pkl'.format(date, learning_rate, num_epochs, num_layers, hidden_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Root directory where simulation subdirectories are stored\n",
    "root_test_base = data_path + '/testing_data/'\n",
    "\n",
    "for simulation_case in os.listdir(root_test_base):\n",
    "    # Root directory where simulation subdirectories are stored\n",
    "    root_dir_test_sim = root_test_base+simulation_case\n",
    "  \n",
    "\n",
    "    # Create the dataset with a subdirectory condition\n",
    "    dataset_test = WingDataset(root_dir_test_sim, subdir_condition=subdir_condition)\n",
    "    inputs_test, outputs_test = dataset_test[0:]\n",
    "\n",
    "    # Assuming your input tensor is named `input_tensor`\n",
    "    input_tensor_test = inputs_test.squeeze(1)  # Remove the singleton dimension at index 1\n",
    "    print(\"Input shape:\", input_tensor_test.shape)  # Should print: torch.Size([6, 145, 7])\n",
    "\n",
    "    output_tensor_test = outputs_test.squeeze(1)\n",
    "    print(\"Output shape:\",output_tensor_test.shape)\n",
    "\n",
    "    inputs_test_reshaped = input_tensor_test.reshape(-1, input_size)\n",
    "\n",
    "    test_inputs_normalized = input_scaler.transform(inputs_test_reshaped.reshape(-1, input_size)).reshape(input_tensor_test.shape)\n",
    "\n",
    "    test_inputs_tensor = torch.tensor(test_inputs_normalized, dtype=torch.float32).to(device)\n",
    "\n",
    "    # Make predictions using the trained model\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    with torch.no_grad():\n",
    "        predicted_outputs, attention_weights = model(test_inputs_tensor)\n",
    "\n",
    "\n",
    "    # Convert the predictions back to numpy and inverse scale the outputs\n",
    "    predicted_outputs = predicted_outputs.cpu().detach().numpy()  # Convert tensor to numpy array\n",
    "    predicted_outputs_original_scale = output_scaler.inverse_transform(predicted_outputs.reshape(-1, output_size))\n",
    "\n",
    "    # Reshape the predictions to match the original sequence structure if needed\n",
    "    predicted_outputs_original_scale = predicted_outputs_original_scale.reshape(input_tensor_test.shape[0], input_tensor_test.shape[1], output_size)\n",
    "    predicted_outputs_original_scale = predicted_outputs_original_scale[0]\n",
    "\n",
    "\n",
    "    cl_test_NN = predicted_outputs_original_scale[:,0]\n",
    "    cd_test_NN = predicted_outputs_original_scale[:,1]\n",
    "\n",
    "    # Load timesteps, CT and CQ from FLOWUnsteady simualtions\n",
    "    time_steps = dataset_test.get_variable('time')\n",
    "\n",
    "    cl_test_flowuns = dataset_test.get_variable('CL')\n",
    "    cd_test_flowuns = dataset_test.get_variable('CD')\n",
    "\n",
    "    if PLOT_RESULTS:\n",
    "        # plt.figure()\n",
    "        plt.figure(figsize=(15, 5))\n",
    "        plt.subplot(1, 2, 1)\n",
    "        plt.plot(cl_test_NN, label = 'cl_NN')\n",
    "        plt.plot((cl_test_flowuns[0]), label = 'cl_flowuns')\n",
    "        plt.xlabel('Time [s]')\n",
    "        plt.ylabel('Lift coefficient, $C_T$')\n",
    "        plt.title(simulation_case)\n",
    "        plt.legend()\n",
    "\n",
    "        # plt.figure()\n",
    "        plt.subplot(1, 2, 2)\n",
    "        plt.plot(cd_test_NN, label = 'cd_NN')\n",
    "        plt.plot(cd_test_flowuns[0], label = 'cd_flowuns')\n",
    "        plt.xlabel('Time [s]')\n",
    "        plt.ylabel('Drag coefficient, $C_Q$')\n",
    "        plt.title(simulation_case)\n",
    "        plt.legend()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "\n",
    "root_test_base = data_path + '/testing_data/'\n",
    "\n",
    "def mape(y_true, y_pred):\n",
    "    \"\"\"Compute Mean Absolute Percentage Error (MAPE)\"\"\"\n",
    "    mask = y_true != 0  # Avoid division by zero\n",
    "    return np.mean(np.abs((y_true[mask] - y_pred[mask]) / y_true[mask])) * 100\n",
    "\n",
    "def relative_l2_norm(y_true, y_pred):\n",
    "    \"\"\"Compute Relative L2 Norm Error (Îµ)\"\"\"\n",
    "    mask = y_true != 0  # Avoid division by zero\n",
    "    numerator = np.linalg.norm(y_pred[mask] - y_true[mask], ord=2)  # ||pred - true||_2\n",
    "    denominator = np.linalg.norm(y_true[mask], ord=2)  # ||true||_2\n",
    "    return (numerator / denominator) * 100\n",
    "\n",
    "# Initialize lists to store evaluation results\n",
    "mape_cl_list, mape_cd_list = [], []\n",
    "r2_cl_list, r2_cd_list = [], []\n",
    "relative_l2_norm_cl_list, relative_l2_norm_cd_list = [], []\n",
    "\n",
    "for simulation_case in os.listdir(root_test_base):\n",
    "    root_dir_test_sim = root_test_base + simulation_case\n",
    "\n",
    "    # Load dataset\n",
    "    dataset_test = WingDataset(root_dir_test_sim, subdir_condition=subdir_condition)\n",
    "    inputs_test, outputs_test = dataset_test[0:]\n",
    "\n",
    "    input_tensor_test = inputs_test.squeeze(1)  # Remove singleton dimension\n",
    "    output_tensor_test = outputs_test.squeeze(1)\n",
    "\n",
    "    # Normalize inputs\n",
    "    inputs_test_reshaped = input_tensor_test.reshape(-1, input_size)\n",
    "    test_inputs_normalized = input_scaler.transform(inputs_test_reshaped).reshape(input_tensor_test.shape)\n",
    "    test_inputs_tensor = torch.tensor(test_inputs_normalized, dtype=torch.float32).to(device)\n",
    "\n",
    "    # Model prediction\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        predicted_outputs, _ = model(test_inputs_tensor)  # Assuming model returns attention weights too\n",
    "\n",
    "    # Convert predictions back to original scale\n",
    "    predicted_outputs = predicted_outputs.cpu().detach().numpy()\n",
    "    predicted_outputs_original_scale = output_scaler.inverse_transform(predicted_outputs.reshape(-1, output_size))\n",
    "    predicted_outputs_original_scale = predicted_outputs_original_scale.reshape(input_tensor_test.shape[0], input_tensor_test.shape[1], output_size)\n",
    "    predicted_outputs_original_scale = predicted_outputs_original_scale[0]  # Select first batch if needed\n",
    "\n",
    "    # Extract Cl and Cd predictions\n",
    "    cl_test_NN = predicted_outputs_original_scale[:, 0]\n",
    "    cd_test_NN = predicted_outputs_original_scale[:, 1]\n",
    "\n",
    "    # Load ground truth (FLOWUnsteady simulation)\n",
    "    cl_test_flowuns = dataset_test.get_variable('CL')[0]  # Ensure correct shape\n",
    "    cd_test_flowuns = dataset_test.get_variable('CD')[0]\n",
    "\n",
    "    # Compute MAPE and RÂ² Score\n",
    "    mape_cl = mape(cl_test_flowuns, cl_test_NN)\n",
    "    mape_cd = mape(cd_test_flowuns, cd_test_NN)\n",
    "    r2_cl = r2_score(cl_test_flowuns, cl_test_NN)\n",
    "    r2_cd = r2_score(cd_test_flowuns, cd_test_NN)\n",
    "    relative_l2_norm_cl = relative_l2_norm(cl_test_flowuns, cl_test_NN)\n",
    "    relative_l2_norm_cd = relative_l2_norm(cd_test_flowuns, cd_test_NN)\n",
    "\n",
    "\n",
    "    # Store results\n",
    "    mape_cl_list.append(mape_cl)\n",
    "    mape_cd_list.append(mape_cd)\n",
    "    r2_cl_list.append(r2_cl)\n",
    "    r2_cd_list.append(r2_cd)\n",
    "    relative_l2_norm_cl_list.append(relative_l2_norm_cl)\n",
    "    relative_l2_norm_cd_list.append(relative_l2_norm_cd)\n",
    "\n",
    "    # Print metrics for this simulation case\n",
    "    print(f\"Simulation Case: {simulation_case}\")\n",
    "    print(f\"  MAPE Cl: {mape_cl:.2f}%, MAPE Cd: {mape_cd:.2f}%\")\n",
    "    print(f\"  RÂ² Cl: {r2_cl:.4f}, RÂ² Cd: {r2_cd:.4f}\")\n",
    "    print(f\"  Îµ Cl: {relative_l2_norm_cl:.2f}%, Îµ Cd: {relative_l2_norm_cd:.2f}%\")\n",
    "\n",
    "# Compute average metrics across all test cases\n",
    "print(\"\\nOverall Metrics Across All Test Cases:\")\n",
    "print(f\"  Avg MAPE Cl: {np.mean(mape_cl_list):.2f}%, Avg MAPE Cd: {np.mean(mape_cd_list):.2f}%\")\n",
    "print(f\"  Avg RÂ² Cl: {np.mean(r2_cl_list):.4f}, Avg RÂ² Cd: {np.mean(r2_cd_list):.4f}\")\n",
    "print(f\"  Avg Îµ Cl: {np.mean(relative_l2_norm_cl_list):.2f}%, Avg Îµ Cd: {np.mean(relative_l2_norm_cd_list):.2f}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vehicle_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
