{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train ESCNN $C_d$ Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This Jupyter Notebook is designed to train and evaluate an Element Spatial Convolutional Neural Network (ESCNN) model for predicting the drag coefficient ($C_d$) of airfoils. The workflow includes data preprocessing, model training, and evaluation. The notebook leverages PyTorch for building and training the neural network, and various Python libraries for data manipulation and visualization.\n",
    "\n",
    "### Workflow:\n",
    "1. **Data Preparation**:\n",
    "    - Load and preprocess airfoil coordinate and polar data.\n",
    "    - Downsample the coordinates to a fixed size.\n",
    "    - Organize the data into a suitable format for the neural network.\n",
    "\n",
    "2. **Model Definition**:\n",
    "    - Define the ESCNN model architecture for predicting $C_d$.\n",
    "    - Define a custom loss function that incorporates both data-driven and physics-informed components.\n",
    "\n",
    "3. **Training**:\n",
    "    - Split the data into training and validation sets.\n",
    "    - Train the ESCNN model using the training data.\n",
    "    - Monitor the training and validation loss over epochs.\n",
    "\n",
    "4. **Evaluation**:\n",
    "    - Evaluate the trained model on a separate test dataset.\n",
    "    - Compute evaluation metrics such as relative L2 norm and R² score.\n",
    "    - Save and visualize the evaluation results.\n",
    "\n",
    "5. **Results Visualization**:\n",
    "    - Plot the training and validation loss curves.\n",
    "    - Optionally save the trained model and evaluation results.\n",
    "\n",
    "This notebook provides a comprehensive approach to developing a physics-informed neural network model for aerodynamic predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "import os\n",
    "import re\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SAVE_TRAINED_MODEL = False\n",
    "PLOT_RESULTS = False\n",
    "SAVE_RESULTS = False\n",
    "\n",
    "project_path = '/mnt/e/eVTOL_model/eVTOL-VehicleModel/'\n",
    "data_path = project_path + 'data/airfoil_data/'\n",
    "model_path = project_path + 'trained_models/models/airfoil/'\n",
    "save_path = project_path + 'result/airfoil_model/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "date = datetime.date.today()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Downsampling using average pooling\n",
    "\"\"\"\n",
    "Downsample the input array to 35 elements using interpolation.\n",
    "\"\"\"\n",
    "\n",
    "def downsample_to_35(input_array):\n",
    "    input_tensor = torch.tensor(input_array, dtype=torch.float32)\n",
    "    \n",
    "    # Reshape the input to be 1D (if it's not already)\n",
    "    if input_tensor.dim() == 1:\n",
    "        input_tensor = input_tensor.unsqueeze(0).unsqueeze(0)  # Shape (1, 1, original_length)\n",
    "    elif input_tensor.dim() == 2:\n",
    "        input_tensor = input_tensor.unsqueeze(0)  # Shape (1, original_channels, original_length)\n",
    "    \n",
    "    # Perform interpolation to downsample to 35 elements\n",
    "    downsampled_tensor = F.interpolate(input_tensor, size=35, mode='linear', align_corners=True)\n",
    "    \n",
    "    # Remove the unnecessary dimensions to return a 1D tensor\n",
    "    downsampled_array = downsampled_tensor.squeeze().numpy()\n",
    "    \n",
    "    return downsampled_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def prep_data(root, keyword=None):\n",
    "\n",
    "    airfoil_count = 0\n",
    "    # Initialization of arrays\n",
    "    # Coordinates\n",
    "    x_i = [] # Initial coordinates - before downsizing\n",
    "    y_i = []\n",
    "\n",
    "    # Polars\n",
    "    alphas = []\n",
    "    Cls = []\n",
    "    Cds = []\n",
    "    Cms = []\n",
    "\n",
    "    if keyword:\n",
    "        # lists of files in each dir\n",
    "        coord_files = [f for f in os.listdir(root) if f == (keyword+'_coordinates.dat')]\n",
    "        polar_files = [f for f in os.listdir(root) if f == ('xf-'+keyword+'-il-1000000.csv')]\n",
    "    else:\n",
    "        # lists of files in each dir\n",
    "        coord_files = [f for f in os.listdir(root) if f.endswith('_coordinates.dat')]\n",
    "        polar_files = [f for f in os.listdir(root) if f.endswith('.csv')]\n",
    "\n",
    "    # Extract base names from coordinate files\n",
    "    coord_bases = {re.sub(r'\\_coordinates.dat$', '', f) for f in coord_files}\n",
    "    polar_bases = {}\n",
    "    for polar_file in polar_files:\n",
    "        match = re.match(r'xf-(.*)-il-1000000\\.csv$', polar_file)\n",
    "        if match:\n",
    "            base_name = match.group(1)\n",
    "            polar_bases[base_name] = polar_file\n",
    "    # print(polar_bases)\n",
    "    for base_name in coord_bases:\n",
    "        if base_name in polar_bases:\n",
    "            coord_file = f\"{base_name}_coordinates.dat\"\n",
    "            polar_file = polar_bases[base_name]\n",
    "\n",
    "            coordinate_data = np.loadtxt(root+coord_file)\n",
    "            # polar_data = np.loadtxt(root+polar_file, skiprows=12)\n",
    "            polar_data = pd.read_csv(root+polar_file, skiprows=10)\n",
    "            polar_data = polar_data[(polar_data['Alpha'] >= -2) & (polar_data['Alpha'] <= 10)]\n",
    "            # print(len(polar_data))\n",
    "\n",
    "            # Coordinates\n",
    "            x = []\n",
    "            y = []\n",
    "\n",
    "            # Polars\n",
    "            alpha = polar_data['Alpha'].values\n",
    "            Cl = polar_data['Cl'].values\n",
    "            Cd = polar_data['Cd'].values\n",
    "            Cm = polar_data['Cm'].values\n",
    "\n",
    "            # print(alpha)\n",
    "\n",
    "            for i in range(0, len(coordinate_data)):\n",
    "                np.array(x.append(float(coordinate_data[i][0]))) \n",
    "                np.array(y.append(float(coordinate_data[i][1])))\n",
    "                \n",
    "            if len(x) >= 35:    # Only consider the files with more than 35 coordinates\n",
    "                x_i.append(x)\n",
    "                y_i.append(y)\n",
    "\n",
    "                alphas.append(alpha)\n",
    "\n",
    "                for num_val in range(len(Cl)):\n",
    "                    Cls.append(Cl[num_val])\n",
    "                    Cds.append(Cd[num_val])\n",
    "                    Cms.append(Cm[num_val])\n",
    "\n",
    "                airfoil_count += 1\n",
    "\n",
    "    print(f\"Number of airfoils: {airfoil_count}\")\n",
    "                        \n",
    "    return x_i, y_i, Cls, Cds, Cms, alphas\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "root_train = data_path + \"/training_database/\"\n",
    "x_i, y_i, Cls, Cds, Cms, alphas = prep_data(root_train)\n",
    "Cls = np.array(Cls, dtype=float)\n",
    "Cds = np.array(Cds, dtype=float)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Downsample to 35 elements\n",
    "x_f = [] # Final coordinates - after downsizing\n",
    "y_f = []\n",
    "for num_airfoil in range(0, len(x_i)):\n",
    "    downsampled_x = downsample_to_35(x_i[num_airfoil])\n",
    "    downsampled_y = downsample_to_35(y_i[num_airfoil])\n",
    "\n",
    "    x_f.append(downsampled_x)\n",
    "    y_f.append(downsampled_y)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Arrange the data in the form of elements\n",
    "* $E = [E_1, E_2, ....., E_n]$ \n",
    "* $E_1 = [x_1, y_1, x_2, y_2, \\alpha]$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Arange the input data in columns [x, y, alpha, Re, M]\n",
    "\n",
    "def organize_data(x_f, y_f, alphas):\n",
    "\n",
    "    Elements = []\n",
    "\n",
    "    # Loop through the polars\n",
    "    for n_file in range(len(x_f)):\n",
    "        x_temp = x_f[n_file]\n",
    "        y_temp = y_f[n_file]\n",
    "        alpha_temp = alphas[n_file]\n",
    "        \n",
    "        for j in range(len(alpha_temp)):\n",
    "            batch = []\n",
    "            # Loop through the coodrinates\n",
    "            for i in range(len(x_temp)-1):\n",
    "                element = np.array([x_temp[i], y_temp[i], x_temp[i+1], y_temp[i+1], alpha_temp[j]])\n",
    "                # Elements.append(element)\n",
    "                batch.append(element)\n",
    "            batch = np.array(batch)\n",
    "            batch = batch.flatten()\n",
    "            Elements.append(batch)\n",
    "\n",
    "    Elements = np.array(Elements)\n",
    "\n",
    "    return Elements\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Elements = organize_data(x_f, y_f, alphas)\n",
    "print(Elements.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Element Spatial Convolutional Neural Network model\n",
    "\n",
    "class ESCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ESCNN, self).__init__()\n",
    "        \n",
    "        # Conv1: Assume 1D Convolution\n",
    "        self.conv1 = nn.Conv1d(in_channels=1, out_channels=200, kernel_size=5, stride=5)\n",
    "        self.relu1 = nn.ReLU()\n",
    "\n",
    "        #conv2\n",
    "        self.conv2 = nn.Conv1d(in_channels=200, out_channels=200, kernel_size=1)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        \n",
    "        # Conv2\n",
    "        self.conv3 = nn.Conv1d(in_channels=200, out_channels=1, kernel_size=5, padding=2)\n",
    "        self.relu3 = nn.ReLU()\n",
    "        \n",
    "        # Final fully connected layer to output scalar\n",
    "        self.fc1 = nn.Linear(in_features=34, out_features=34)\n",
    "        self.relu4 = nn.ReLU()\n",
    "\n",
    "        self.fc2 = nn.Linear(in_features=34, out_features=1)\n",
    "\n",
    "        # Define learnable parameters for C_d0 and k\n",
    "        self.Cd0 = nn.Parameter(torch.tensor(0.02))  # Initialized zero-lift drag coefficient\n",
    "        self.k = nn.Parameter(torch.tensor(0.05))    # Initialized induced drag factor\n",
    "\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # Reshape input if necessary, ensure it's in the shape (batch_size, channels, elements)\n",
    "        x = x.view(-1, 1, 170)  # Reshape to (batch_size, channel=1, elements=170)\n",
    "        \n",
    "        x = self.conv1(x)  \n",
    "        x = self.relu1(x)\n",
    "        \n",
    "        x = self.conv2(x)  \n",
    "        x = self.relu2(x)\n",
    "\n",
    "        x = self.conv3(x)  \n",
    "        x = self.relu3(x)\n",
    "        \n",
    "        \n",
    "        x = torch.flatten(x, 1)\n",
    "        \n",
    "        x = self.fc1(x)  # (batch_size, 1)\n",
    "        x = self.relu4(x)\n",
    "\n",
    "        x = self.fc2(x)\n",
    "        \n",
    "        return x\n",
    "\n",
    "model = ESCNN()\n",
    "\n",
    "model.to(device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Orgaize the data for the NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data = Elements\n",
    "output_data = Cds\n",
    "print(output_data.shape)\n",
    "\n",
    "\n",
    "input_data_train, input_data_val, output_data_train, output_data_val = train_test_split(input_data, output_data, test_size=0.25, random_state=28)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to PyTorch tensors\n",
    "# And move the data to cuda\n",
    "\n",
    "input_data_train = torch.from_numpy(input_data_train).float().to(device)\n",
    "input_data_val = torch.from_numpy(input_data_val).float().to(device)\n",
    "\n",
    "output_data_train = torch.from_numpy(output_data_train).float().to(device)\n",
    "output_data_val = torch.from_numpy(output_data_val).float().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataLoader\n",
    "dataset_train = TensorDataset(input_data_train, output_data_train)\n",
    "dataset_val = TensorDataset(input_data_val, output_data_val)\n",
    "\n",
    "trainDataLoader = DataLoader(dataset_train, batch_size=128)\n",
    "valDataLoader = DataLoader(dataset_val, batch_size=128)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_loss(pred_cd, true_cd, cl_pred, model, criterion):\n",
    "    # MSE loss between predicted and true Cd\n",
    "    mse_loss = criterion(pred_cd, true_cd)\n",
    "    \n",
    "    # Physics-informed loss using the model's learnable Cd0 and k\n",
    "    phy_cd = model.Cd0 + model.k * cl_pred ** 2\n",
    "    drag_polar_loss = criterion(pred_cd, phy_cd)\n",
    "\n",
    "    # Total loss\n",
    "    total_loss = mse_loss + 0.3 * drag_polar_loss  # Adjust weight (0.1) as needed\n",
    "\n",
    "    return total_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ESCNN_Cl(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ESCNN_Cl, self).__init__()\n",
    "        \n",
    "        # Conv1: Assume 1D Convolution\n",
    "        self.conv1 = nn.Conv1d(in_channels=1, out_channels=200, kernel_size=5, stride=5)\n",
    "        self.relu1 = nn.ReLU()\n",
    "\n",
    "        #conv2\n",
    "        self.conv2 = nn.Conv1d(in_channels=200, out_channels=200, kernel_size=1)\n",
    "        self.relu2 = nn.ReLU()\n",
    "\n",
    "        # Conv3\n",
    "        self.conv3 = nn.Conv1d(in_channels=200, out_channels=100, kernel_size=1)\n",
    "        self.relu3 = nn.ReLU()\n",
    "        \n",
    "        # Conv4\n",
    "        self.conv4 = nn.Conv1d(in_channels=100, out_channels=1, kernel_size=5, padding=2)\n",
    "        self.relu4 = nn.ReLU()\n",
    "        \n",
    "        # Final fully connected layer to output scalar\n",
    "        self.fc1 = nn.Linear(in_features=34, out_features=34)\n",
    "        self.relu5 = nn.ReLU()\n",
    "\n",
    "        self.fc2 = nn.Linear(in_features=34, out_features=1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # Reshape input if necessary, ensure it's in the shape (batch_size, channels, elements)\n",
    "        x = x.view(-1, 1, 170)  # Reshape to (batch_size, channel=1, elements=170)\n",
    "        \n",
    "        x = self.conv1(x)  \n",
    "        x = self.relu1(x)\n",
    "        \n",
    "        x = self.conv2(x)  \n",
    "        x = self.relu2(x)\n",
    "\n",
    "        x = self.conv3(x)  \n",
    "        x = self.relu3(x)\n",
    "        \n",
    "        x = self.conv4(x)  \n",
    "        x = self.relu4(x)\n",
    "        \n",
    "        x = torch.flatten(x, 1)\n",
    "        \n",
    "        x = self.fc1(x)  \n",
    "        x = self.relu5(x)\n",
    "\n",
    "        x = self.fc2(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the model for Cl\n",
    "cl_model = ESCNN_Cl()\n",
    "cl_model.load_state_dict(torch.load('/mnt/e/eVTOL_model/eVTOL-AirfoilModel/trained_model/Cl_models/2024-11-18_model_Cl_ESCNN_lr1e-05_e1500_rbf170_convL4.pth'), strict=False)\n",
    "cl_model = cl_model.to(device)\n",
    "cl_model.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define loss function and optimizer\n",
    "criterion = nn.MSELoss()  # Mean Squared Error Loss\n",
    "lr = 5e-5\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "num_epochs = 250\n",
    "num_convL_layer = 3\n",
    "\n",
    "# initialize a dictionary to store training history\n",
    "H = {\n",
    "\t\"train_loss\": [],\n",
    "\t\"val_loss\": [],\n",
    "    \"Cd0_train\": [],\n",
    "    \"Cd0_val\": [],\n",
    "    \"k_train\": [],\n",
    "    \"k_val\": []\n",
    "\n",
    "}\n",
    "\n",
    "# measure how long training is going to take\n",
    "print(\"[INFO] training the network...\")\n",
    "startTime = time.time()\n",
    "\n",
    "\n",
    "# Training loop\n",
    "\n",
    "for e in range(0, num_epochs):\n",
    "    model.train()\n",
    "\n",
    "    totalTrainLoss = 0\n",
    "    totalValLoss = 0\n",
    "\n",
    "    for (ip, op) in trainDataLoader:\n",
    "        pred_cd = model(ip)\n",
    "        pred_cd = pred_cd.squeeze(1)\n",
    "\n",
    "        with torch.no_grad():  # Cl model is pre-trained and frozen\n",
    "            cl_pred = cl_model.forward(ip)\n",
    "            cl_pred = cl_pred.squeeze(1)\n",
    "\n",
    "        # Compute the custom loss (data + physics-informed loss)\n",
    "        loss = custom_loss(pred_cd, op, cl_pred, model, criterion)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        totalTrainLoss += loss.item()\n",
    "\n",
    "     # Store the values of Cd0 and k after each epoch\n",
    "    H[\"Cd0_train\"].append(model.Cd0.item())\n",
    "    H[\"k_train\"].append(model.k.item())\n",
    "\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "\n",
    "        for (ip, op) in valDataLoader:\n",
    "            pred_cd = model(ip)\n",
    "            pred_cd = pred_cd.squeeze(1)\n",
    "\n",
    "            cl_pred = cl_model.forward(ip)\n",
    "            cl_pred = cl_pred.squeeze(1)\n",
    "\n",
    "            val_loss = custom_loss(pred_cd, op, cl_pred, model, criterion)\n",
    "            totalValLoss += val_loss.item()\n",
    "\n",
    "         # Store the values of Cd0 and k after each epoch\n",
    "        H[\"Cd0_val\"].append(model.Cd0.item())\n",
    "        H[\"k_val\"].append(model.k.item())\n",
    "\n",
    "    avgTrainLoss = totalTrainLoss / len(trainDataLoader.dataset)\n",
    "    avgValLoss = totalValLoss / len(valDataLoader.dataset)\n",
    "\n",
    "    H[\"train_loss\"].append(avgTrainLoss)\n",
    "    H[\"val_loss\"].append(avgValLoss)\n",
    "\n",
    "    print(f\"Epoch: {e+1}/{num_epochs}, Train Loss: {avgTrainLoss:.8f}, Val Loss: {avgValLoss:.8f}\")\n",
    "\n",
    "print(\"Finished Training\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the results\n",
    "\n",
    "plt.figure()\n",
    "plt.figure(figsize=(10, 6), dpi=300)  # High-resolution plot\n",
    "\n",
    "plt.plot(np.log10(H[\"train_loss\"]), color='black', linewidth=1.5, label=\"Training loss\")\n",
    "plt.plot(np.log10(H[\"val_loss\"]), color='red', linewidth=1.5, label=\"Validation loss\")\n",
    "plt.title(\"Training Loss and Validation Loss\", fontsize=12)\n",
    "plt.grid(True, linestyle='--', linewidth=0.5)\n",
    "plt.xlabel(\"Epoch\", fontsize=10)\n",
    "plt.ylabel(\"Log(MSE Loss)\", fontsize=10)\n",
    "plt.legend(loc='upper right', fontsize=10)\n",
    "# plt.gca().set_aspect('equal', adjustable='box')  # Maintain correct aspect ratio\n",
    "# plt.savefig(\"airfoil_model_cd_loss_phy_e250.pdf\", format=\"pdf\", dpi=300, bbox_inches=\"tight\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model if needed\n",
    "if SAVE_TRAINED_MODEL:\n",
    "    save_path = model_path + '/{}_model_Cd_ESCNN_lr{}_e{}_convL{}.pth'.format(date, lr, num_epochs,num_convL_layer)\n",
    "\n",
    "    torch.save(model.state_dict(), save_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "\n",
    "root_test = data_path + \"/testing_database/\"\n",
    "\n",
    "coord_files = [f for f in os.listdir(root_test) if f.endswith('_coordinates.dat')]\n",
    "coord_bases = {re.sub(r'\\_coordinates.dat$', '', f) for f in coord_files}\n",
    "\n",
    "def mape(y_true, y_pred):\n",
    "    \"\"\"Compute Mean Absolute Percentage Error (MAPE)\"\"\"\n",
    "    mask = y_true != 0  # Avoid division by zero\n",
    "    return np.mean(np.abs((y_true[mask] - y_pred[mask]) / y_true[mask])) * 100\n",
    "\n",
    "def relative_l2_norm(y_true, y_pred):\n",
    "    \"\"\"Compute Relative L2 Norm Error (ε)\"\"\"\n",
    "    mask = y_true != 0  # Avoid division by zero\n",
    "    numerator = np.linalg.norm(y_pred[mask] - y_true[mask], ord=2)  # ||pred - true||_2\n",
    "    denominator = np.linalg.norm(y_true[mask], ord=2)  # ||true||_2\n",
    "    return (numerator / denominator) * 100\n",
    "\n",
    "SAVE_PATH = '/mnt/e/eVTOL_model/eVTOL-VehicleModel/result/airfoil_model/'\n",
    "\n",
    "# Initialize lists to store evaluation results\n",
    "l2_norm_cd_list = []\n",
    "r2_cd_list = []\n",
    "airfoil_names = []\n",
    "\n",
    "for keyword in coord_bases:\n",
    "    x_t, y_t, Cls_t, Cds_t, Cms_t, alphas_t = prep_data(root_test, keyword)\n",
    "    Cls_t = np.array(Cls_t, dtype=float)\n",
    "    Cds_t = np.array(Cds_t, dtype=float)\n",
    "    Cms_t = np.array(Cms_t, dtype=float)\n",
    "    \n",
    "    x_f_t = [] # Final coordinates - after downsizing\n",
    "    y_f_t = []\n",
    "    for num_airfoil in range(0, len(x_t)):\n",
    "        downsampled_x = downsample_to_35(x_t[num_airfoil])\n",
    "        downsampled_y = downsample_to_35(y_t[num_airfoil])\n",
    "\n",
    "        x_f_t.append(downsampled_x)\n",
    "        y_f_t.append(downsampled_y)\n",
    "        \n",
    "    Elements_t = organize_data(x_f_t, y_f_t, alphas_t)\n",
    "    # print(\"Elements: \",Elements_t.shape)\n",
    "    # print(\"Cds: \",Cds_t.shape)\n",
    "\n",
    "    if Elements_t.shape != (0,):\n",
    "        input_data_test = Elements_t\n",
    "\n",
    "        # Convert to PyTorch tensors\n",
    "        input_data_test = torch.tensor(input_data_test, dtype=torch.float32)\n",
    "\n",
    "        # Move data to GPU\n",
    "        input_data_test = input_data_test.to(device)\n",
    "\n",
    "        # Evaluate the model on test dataset\n",
    "        with torch.no_grad():\n",
    "            Cd_eval = model.forward(input_data_test)\n",
    "            # loss = criterion(Cl_eval, Cls_test[0])\n",
    "\n",
    "        # Calculate the evaluation metrics\n",
    "        Cd_eval = Cd_eval.cpu().numpy().flatten()\n",
    "        l2_norm_cd = relative_l2_norm(Cds_t, Cd_eval)\n",
    "        r2_cd = r2_score(Cds_t, Cd_eval)\n",
    "\n",
    "        l2_norm_cd_list.append(l2_norm_cd)\n",
    "        r2_cd_list.append(r2_cd)\n",
    "        airfoil_names.append(keyword)\n",
    "\n",
    "        print(f\"Airfoil: {keyword}, relative L2 Norm percentage Cd: {l2_norm_cd:.2f}%, R^2 Cd: {r2_cd:.4f}\")\n",
    "\n",
    "        # plt.figure()\n",
    "        # plt.plot(alphas_t[0], Cd_eval)\n",
    "        # plt.plot(alphas_t[0],Cds_t)\n",
    "\n",
    "        # plt.legend(['NN Model', 'UIUC database'])\n",
    "        # plt.title(r'$C_d$ vs $\\alpha$ for {} airfoil'.format(keyword))\n",
    "        # plt.xlabel(r'AOA [$\\alpha$]')\n",
    "        # plt.ylabel(r'$C_d$')\n",
    "\n",
    "    else:\n",
    "        continue\n",
    "\n",
    "# Save the evaluation results\n",
    "mean_l2_norm_cd = np.mean(l2_norm_cd_list)\n",
    "r2_cd_avg = np.mean(r2_cd_list)\n",
    "\n",
    "print(f\"Average MAPE Cd: {mean_l2_norm_cd:.2f}%, Average R^2 Cd: {r2_cd_avg:.4f}\")\n",
    "\n",
    "# Convert results to a DataFrame\n",
    "results_df = pd.DataFrame({\n",
    "    \"Airfoil\": airfoil_names,\n",
    "    \"Relative L2 Norm Cd (%)\": l2_norm_cd_list,\n",
    "    \"R² Cd\": r2_cd_list\n",
    "})\n",
    "\n",
    "# Append mean values to the DataFrame\n",
    "mean_row = pd.DataFrame({\n",
    "    \"Airfoil\": [\"Mean\"], \n",
    "    \"Relative L2 Norm Cd (%)\": [mean_l2_norm_cd], \n",
    "    \"R² Cd\": [r2_cd_avg]\n",
    "})\n",
    "\n",
    "# results_df = pd.concat([results_df, mean_row], ignore_index=True)\n",
    "\n",
    "# # Define CSV file path\n",
    "# csv_filename = os.path.join(SAVE_PATH, \"Cd_evaluation_results_lambda_0.3.csv\")\n",
    "\n",
    "# # Save to CSV\n",
    "# results_df.to_csv(csv_filename, index=False)\n",
    "\n",
    "# print(f\"Results (including mean values) saved to {csv_filename}\")\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vehicle_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
