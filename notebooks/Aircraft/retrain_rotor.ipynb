{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GATConv  - Parallel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import sys\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from scipy.fftpack import fft, ifft\n",
    "from scipy.interpolate import CubicSpline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if GPU is available\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append('/mnt/e/eVTOL_model/eVTOL-VehicleModel/src')\n",
    "\n",
    "\n",
    "# Import necessary functions\n",
    "from utility_functions import downsample_to_35\n",
    "from utility_functions import organize_data\n",
    "\n",
    "# Import all the models\n",
    "from af_escnn_cl import ESCNN_Cl\n",
    "from af_escnn_cd import ESCNN_Cd\n",
    "\n",
    "from af_rbf_cl import RBFLayer_cl, RBFNet_cl\n",
    "from af_rbf_cd import RBFLayer_cd, RBFNet_cd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Rotor Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from create_rotor_dataset import PropellerDataset, subdir_condition_rotor\n",
    "\n",
    "# Root directory where simulation subdirectories are stored\n",
    "# root_dir_rotor = '/mnt/e/Course_Materials/ROM/rotor_solver/FLOWUnsteady_simulations/train_data'\n",
    "root_dir_rotor = '/mnt/e/eVTOL_model/eVTOL-VehicleModel/FLOWUnsteady_simulations/aircraft_data/training_data'\n",
    "\n",
    "# dataset - Rotor L1\n",
    "dataset_rotor_L1 = PropellerDataset(root_dir_rotor,\n",
    "                           rotor_notation = 'L1',                       # Select: L1, L2, L3, L4, R1, R2, R3, R4\n",
    "                           subdir_condition=subdir_condition_rotor)\n",
    "inputs_rL1, outputs_rL1 = dataset_rotor_L1[0:]\n",
    "\n",
    "\n",
    "input_tensor_rL1 = inputs_rL1.squeeze(1)  # Reshaping\n",
    "print(\"Input shape (rotor - L1):\", input_tensor_rL1.shape) \n",
    "\n",
    "output_tensor_rL1 = outputs_rL1.squeeze(1)\n",
    "print(\"Output shape (rotor - L1):\",output_tensor_rL1.shape) \n",
    "\n",
    "\n",
    "# dataset - Rotor L2\n",
    "dataset_rotor_L2 = PropellerDataset(root_dir_rotor,\n",
    "                           rotor_notation = 'L2',                       # Select: L1, L2, L3, L4, R1, R2, R3, R4\n",
    "                           subdir_condition=subdir_condition_rotor)\n",
    "inputs_rL2, outputs_rL2 = dataset_rotor_L2[0:]\n",
    "\n",
    "\n",
    "input_tensor_rL2 = inputs_rL2.squeeze(1)  # Reshaping\n",
    "print(\"Input shape (rotor - L2):\", input_tensor_rL2.shape) \n",
    "\n",
    "output_tensor_rL2 = outputs_rL2.squeeze(1)\n",
    "print(\"Output shape (rotor - L2):\",output_tensor_rL2.shape) \n",
    "\n",
    "# dataset - Rotor L3\n",
    "dataset_rotor_L3 = PropellerDataset(root_dir_rotor,\n",
    "                           rotor_notation = 'L3',                       # Select: L1, L2, L3, L4, R1, R2, R3, R4\n",
    "                           subdir_condition=subdir_condition_rotor)\n",
    "inputs_rL3, outputs_rL3 = dataset_rotor_L3[0:]\n",
    "\n",
    "\n",
    "input_tensor_rL3 = inputs_rL3.squeeze(1)  # Reshaping\n",
    "print(\"Input shape (rotor - L3):\", input_tensor_rL3.shape) \n",
    "\n",
    "output_tensor_rL3 = outputs_rL3.squeeze(1)\n",
    "print(\"Output shape (rotor - L3):\",output_tensor_rL3.shape) \n",
    "\n",
    "# dataset - Rotor L4\n",
    "dataset_rotor_L4 = PropellerDataset(root_dir_rotor,\n",
    "                           rotor_notation = 'L4',                       # Select: L1, L2, L3, L4, R1, R2, R3, R4\n",
    "                           subdir_condition=subdir_condition_rotor)\n",
    "inputs_rL4, outputs_rL4 = dataset_rotor_L4[0:]\n",
    "\n",
    "\n",
    "input_tensor_rL4 = inputs_rL4.squeeze(1)  # Reshaping\n",
    "print(\"Input shape (rotor - L4):\", input_tensor_rL4.shape) \n",
    "\n",
    "output_tensor_rL4 = outputs_rL4.squeeze(1)\n",
    "print(\"Output shape (rotor - L4):\",output_tensor_rL4.shape) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset - Rotor R1\n",
    "dataset_rotor_R1 = PropellerDataset(root_dir_rotor,\n",
    "                           rotor_notation = 'R1',                       # Select: L1, L2, L3, L4, R1, R2, R3, R4\n",
    "                           subdir_condition=subdir_condition_rotor)\n",
    "inputs_rR1, outputs_rR1 = dataset_rotor_R1[0:]\n",
    "\n",
    "\n",
    "input_tensor_rR1 = inputs_rR1.squeeze(1)  # Reshaping\n",
    "print(\"Input shape (rotor - R1):\", input_tensor_rR1.shape) \n",
    "\n",
    "output_tensor_rR1 = outputs_rR1.squeeze(1)\n",
    "print(\"Output shape (rotor - R1):\",output_tensor_rR1.shape) \n",
    "\n",
    "\n",
    "# dataset - Rotor R2\n",
    "dataset_rotor_R2 = PropellerDataset(root_dir_rotor,\n",
    "                           rotor_notation = 'R2',                       # Select: L1, L2, L3, L4, R1, R2, R3, R4\n",
    "                           subdir_condition=subdir_condition_rotor)\n",
    "inputs_rR2, outputs_rR2 = dataset_rotor_R2[0:]\n",
    "\n",
    "\n",
    "input_tensor_rR2 = inputs_rR2.squeeze(1)  # Reshaping\n",
    "print(\"Input shape (rotor - R2):\", input_tensor_rR2.shape) \n",
    "\n",
    "output_tensor_rR2 = outputs_rR2.squeeze(1)\n",
    "print(\"Output shape (rotor - R2):\",output_tensor_rR2.shape) \n",
    "\n",
    "# dataset - Rotor R3\n",
    "dataset_rotor_R3 = PropellerDataset(root_dir_rotor,\n",
    "                           rotor_notation = 'R3',                       # Select: L1, L2, L3, L4, R1, R2, R3, R4\n",
    "                           subdir_condition=subdir_condition_rotor)\n",
    "inputs_rR3, outputs_rR3 = dataset_rotor_R3[0:]\n",
    "\n",
    "\n",
    "input_tensor_rR3 = inputs_rR3.squeeze(1)  # Reshaping\n",
    "print(\"Input shape (rotor - R3):\", input_tensor_rR3.shape) \n",
    "\n",
    "output_tensor_rR3 = outputs_rR3.squeeze(1)\n",
    "print(\"Output shape (rotor - R3):\",output_tensor_rR3.shape) \n",
    "\n",
    "# dataset - Rotor R4\n",
    "dataset_rotor_R4 = PropellerDataset(root_dir_rotor,\n",
    "                           rotor_notation = 'R4',                       # Select: L1, L2, L3, L4, R1, R2, R3, R4\n",
    "                           subdir_condition=subdir_condition_rotor)\n",
    "inputs_rR4, outputs_rR4 = dataset_rotor_R4[0:]\n",
    "\n",
    "\n",
    "input_tensor_rR4 = inputs_rR4.squeeze(1)  # Reshaping\n",
    "print(\"Input shape (rotor - R4):\", input_tensor_rR4.shape) \n",
    "\n",
    "output_tensor_rR4 = outputs_rR4.squeeze(1)\n",
    "print(\"Output shape (rotor - R4):\",output_tensor_rR4.shape) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_tensor_all_rotors = torch.cat((input_tensor_rL1, input_tensor_rL2, input_tensor_rL3, input_tensor_rL4), dim=0) \n",
    "                                        # input_tensor_rR1, input_tensor_rR2, input_tensor_rR3, input_tensor_rR4), dim=0)\n",
    "\n",
    "output_tensor_all_rotors = torch.cat((output_tensor_rL1, output_tensor_rL2, output_tensor_rL3, output_tensor_rL4), dim=0)\n",
    "                                        # output_tensor_rR1, output_tensor_rR2, output_tensor_rR3, output_tensor_rR4), dim=0)\n",
    "\n",
    "print(\"Input shape (all rotors):\", input_tensor_all_rotors.shape)\n",
    "print(\"Output shape (all rotors):\", output_tensor_all_rotors.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Rotor Model and Initialize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rotor_model import LSTMNet_rotor\n",
    "\n",
    "input_size_rotor = 10\n",
    "hidden_size_rotor = 100\n",
    "output_size_rotor = 2\n",
    "num_layers_rotor = 4\n",
    "\n",
    "class PropModel(LSTMNet_rotor):\n",
    "    def __init__(self):\n",
    "        super(PropModel, self).__init__(input_size_rotor, hidden_size_rotor, \n",
    "                                        output_size_rotor, num_layers_rotor)\n",
    "\n",
    "root_rotorModelsTrained = '/mnt/e/eVTOL_model/eVTOL-VehicleModel/trained_models/models/rotor/'\n",
    "root_rotorScalersTrained = '/mnt/e/eVTOL_model/eVTOL-VehicleModel/trained_models/scalers/rotor/'\n",
    "\n",
    "# Initialize the model\n",
    "prop_model = PropModel()\n",
    "# prop_model.load_state_dict(torch.load(root_rotorModelsTrained+'2024-10-04_propModel_lr0.005_e1500_nL2_numNN50.pth'))\n",
    "prop_model.load_state_dict(torch.load(root_rotorModelsTrained+'2025-01-30_modified_H26FpropModel_lr0.001_e2500_nL4_numNN100.pth'))\n",
    "prop_model = prop_model.to(device)\n",
    "# prop_model.eval()\n",
    "\n",
    "# Load the scaler\n",
    "# input_scaler_rotor = joblib.load(root_rotorScalersTrained+'2024-10-04_ipScaler_lr0.005_e1500_nL2_numNN50.pkl')\n",
    "# output_scaler_rotor = joblib.load(root_rotorScalersTrained+'2024-10-04_opScaler_lr0.005_e1500_nL2_numNN50.pkl')\n",
    "\n",
    "\n",
    "input_scaler_rotor = joblib.load(root_rotorScalersTrained+'2025-01-30_modified_H26F_ipScaler_lr0.001_e2500_nL4_numNN100.pkl')\n",
    "output_scaler_rotor = joblib.load(root_rotorScalersTrained+'2025-01-30_modified_H26F_opScaler_lr0.001_e2500_nL4_numNN100.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape data for scaling (flatten along the time dimension)\n",
    "inputs_reshaped = input_tensor_all_rotors.reshape(-1, input_size_rotor)\n",
    "outputs_reshaped = output_tensor_all_rotors.reshape(-1, output_size_rotor)\n",
    "\n",
    "# Fit and transform inputs and outputs\n",
    "inputs_all_rotors_normalized = input_scaler_rotor.transform(inputs_reshaped).reshape(input_tensor_all_rotors.shape)\n",
    "outputs_all_rotors_normalized = output_scaler_rotor.transform(outputs_reshaped).reshape(output_tensor_all_rotors.shape)\n",
    "\n",
    "print(\"Normalized input shape:\", inputs_all_rotors_normalized.shape)\n",
    "print(\"Normalized output shape:\", outputs_all_rotors_normalized.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates training and validation datasets\n",
    "class SimulationDataset(Dataset):\n",
    "    def __init__(self, inputs, outputs):\n",
    "        self.inputs = inputs\n",
    "        self.outputs = outputs\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.inputs)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return torch.tensor(self.inputs[idx], dtype=torch.float32), torch.tensor(self.outputs[idx], dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants\n",
    "EPOCHS = 1500\n",
    "BATCH_SIZE = 4\n",
    "LEARNING_RATE = 2e-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_percentage = 0.3   # Percentage of data to be used for testing\n",
    "\n",
    "train_dataset_num = len(input_tensor_all_rotors) - int(len(input_tensor_all_rotors)*val_percentage)    \n",
    "print(\"Number of datasets to be used for training:\", train_dataset_num)\n",
    "print(\"Number of datasets to be used for evaluation:\", len(input_tensor_all_rotors) - train_dataset_num)\n",
    "\n",
    "# Create the normalized dataset using the custom Dataset class\n",
    "train_dataset = SimulationDataset(inputs_all_rotors_normalized[:train_dataset_num], outputs_all_rotors_normalized[:train_dataset_num])    # First 70% for training\n",
    "val_dataset = SimulationDataset(inputs_all_rotors_normalized[train_dataset_num:], outputs_all_rotors_normalized[train_dataset_num:])      # Remaining for evaluation\n",
    "\n",
    "# Create DataLoaders\n",
    "trainDataLoader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)    # Shuffle training data\n",
    "valDataLoader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=True)        # Shuffle validation data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Ensure all parameters are trainable (for fine-tuning)\n",
    "for param in prop_model.parameters():\n",
    "    param.requires_grad = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def custom_loss(pred, target):\n",
    "#     pred_fft = torch.fft.fft(pred)\n",
    "#     target_fft = torch.fft.fft(target)\n",
    "\n",
    "#     fft_loss = torch.mean((torch.abs(pred_fft) - torch.abs(target_fft)) ** 2)\n",
    "\n",
    "#     return fft_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_loss(pred, target):\n",
    "    return torch.mean((pred - target) ** 2) + 0.5 * torch.mean(torch.abs(pred - target))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def amplitude_loss(pred, target):\n",
    "#     scale_factor = torch.abs(target).mean()  # Capture expected amplitude\n",
    "#     return torch.mean(((pred - target) / scale_factor) ** 2)  # Normalize amplitude errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# criterion = nn.MSELoss()\n",
    "criterion = custom_loss\n",
    "optimizer_fine_tune_rotor = torch.optim.AdamW(prop_model.parameters(), lr=LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_losses = []\n",
    "eval_losses = []\n",
    "\n",
    "print(\"[INFO] training the network...\")\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(EPOCHS):\n",
    "    prop_model.train()\n",
    "    running_loss = 0.0\n",
    "    \n",
    "    for inputs, targets in trainDataLoader:\n",
    "        inputs, targets = inputs.squeeze(1).to(device), targets.squeeze(1).to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = prop_model(inputs)\n",
    "        \n",
    "        loss = criterion(outputs, targets)\n",
    "        # Backward pass and optimization\n",
    "        optimizer_fine_tune_rotor.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer_fine_tune_rotor.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "\n",
    "    avg_train_loss = running_loss / len(trainDataLoader)\n",
    "    train_losses.append(avg_train_loss)\n",
    "\n",
    "\n",
    "    # Evaluation Loop\n",
    "    prop_model.eval()\n",
    "    eval_loss = 0.0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, targets in valDataLoader:\n",
    "            inputs, targets = inputs.squeeze(1).to(device), targets.squeeze(1).to(device)\n",
    "            \n",
    "            # Forward pass\n",
    "            outputs = prop_model(inputs)\n",
    "            # outputs, attention_weights = model(inputs)\n",
    "\n",
    "            loss = criterion(outputs, targets)\n",
    "            eval_loss += loss.item()\n",
    "\n",
    "        avg_eval_loss = eval_loss / len(valDataLoader)\n",
    "        eval_losses.append(avg_eval_loss)\n",
    "    \n",
    "    print(f'Epoch [{epoch+1}/{EPOCHS}],\\n Training Loss: {running_loss/len(trainDataLoader):.8f}')\n",
    "    print(f'Evaluation Loss: {eval_loss/len(valDataLoader):.8f}')\n",
    "\n",
    "\n",
    "print(\"[INFO] Finished training the network...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the training and evaluation losses\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot((train_losses), label='Training Loss')\n",
    "plt.plot((eval_losses), label='Evaluation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training and Evaluation Losses Over Epochs')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "date = datetime.date.today()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import datetime\n",
    "# date = datetime.date.today()\n",
    "\n",
    "save_path =  '/mnt/e/eVTOL_model/eVTOL-VehicleModel/trained_models/models/rotor/{}_modified_H26FpropModel_retrained_lr{}_e{}_nL{}_numNN{}.pth'.format(date, LEARNING_RATE, EPOCHS, num_layers_rotor, hidden_size_rotor)\n",
    "print(\"The model will be saved as the following:\\n {}\".format(save_path))\n",
    "\n",
    "\n",
    "torch.save(prop_model.state_dict(), save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# joblib.dump(input_scaler_rotor, '/mnt/e/eVTOL_model/eVTOL-VehicleModel/trained_models/scalers/rotor/{}_modified_H26F_retrained_ipScaler_lr{}_e{}_nL{}_numNN{}.pkl'.format(date, LEARNING_RATE, EPOCHS, num_layers_rotor, hidden_size_rotor))\n",
    "# joblib.dump(output_scaler_rotor, '/mnt/e/eVTOL_model/eVTOL-VehicleModel/trained_models/scalers/rotor/{}_modified_H26F_retrained_opScaler_lr{}_e{}_nL{}_numNN{}.pkl'.format(date, LEARNING_RATE, EPOCHS, num_layers_rotor, hidden_size_rotor))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " \n",
    "from sklearn.metrics import mean_squared_error \n",
    "\n",
    "root_test_base = '/mnt/e/eVTOL_model/eVTOL-VehicleModel/FLOWUnsteady_simulations/aircraft_data/testing_data/'\n",
    "batch_size_test = 1\n",
    "\n",
    "for simulation_case in os.listdir(root_test_base):\n",
    "\n",
    "    root_test_dir = root_test_base+simulation_case\n",
    "\n",
    "\n",
    "    # dataset - Rotor L1\n",
    "    dataset_rotor_L1_test = PropellerDataset(root_test_dir,\n",
    "                            rotor_notation = 'L1',                       # Select: L1, L2, L3, L4, R1, R2, R3, R4\n",
    "                            subdir_condition=subdir_condition_rotor)\n",
    "    inputs_rL1_test, outputs_rL1_test = dataset_rotor_L1_test[0:]\n",
    "\n",
    "    input_tensor_rL1_test = inputs_rL1_test.squeeze(1)  # Reshaping\n",
    "    # print(\"Input shape (rotor - L1):\", input_tensor_rL1.shape) \n",
    "    output_tensor_rL1_test = outputs_rL1_test.squeeze(1)\n",
    "    # print(\"Output shape (rotor - L1):\",output_tensor_rL1.shape)\n",
    "\n",
    "\n",
    "    # dataset - Rotor R1\n",
    "    dataset_rotor_R1_test = PropellerDataset(root_test_dir,\n",
    "                            rotor_notation = 'R1',                       # Select: L1, L2, L3, L4, R1, R2, R3, R4\n",
    "                            subdir_condition=subdir_condition_rotor)\n",
    "    inputs_rR1_test, outputs_rR1_test = dataset_rotor_R1_test[0:]\n",
    "\n",
    "    input_tensor_rR1_test = inputs_rR1_test.squeeze(1)  # Reshaping\n",
    "    # print(\"Input shape (rotor - R1):\", input_tensor_rR1.shape) \n",
    "    output_tensor_rR1_test = outputs_rR1_test.squeeze(1)\n",
    "    # print(\"Output shape (rotor - R1):\",output_tensor_rR1.shape) \n",
    "\n",
    "    # input_tensor_all_rotors_test = torch.cat((input_tensor_rL1_test, input_tensor_rR1_test), dim=0)\n",
    "    # output_tensor_all_rotors_test = torch.cat((output_tensor_rL1_test, output_tensor_rR1_test), dim=0)\n",
    "\n",
    "    datasets = [dataset_rotor_L1_test, dataset_rotor_R1_test]\n",
    "\n",
    "    for dataset_test in datasets:\n",
    "        inputs_test, outputs_test = dataset_test[0:]\n",
    "        input_tensor_test = inputs_test.squeeze(1)\n",
    "        output_tensor_test = outputs_test.squeeze(1)\n",
    "\n",
    "        inputs_test_reshaped = input_tensor_test.reshape(-1, input_size_rotor)\n",
    "\n",
    "        test_inputs_normalized = input_scaler_rotor.transform(inputs_test_reshaped.reshape(-1, input_size_rotor)).reshape(input_tensor_test.shape)\n",
    "\n",
    "        test_inputs_tensor = torch.tensor(test_inputs_normalized, dtype=torch.float32).to(device)\n",
    "    \n",
    "\n",
    "        prop_model.eval()  # Set the model to evaluation mode\n",
    "\n",
    "\n",
    "        with torch.no_grad():\n",
    "            predicted_outputs = prop_model(test_inputs_tensor)\n",
    "\n",
    "    \n",
    "        # Convert the predictions back to numpy and inverse scale the outputs\n",
    "        predicted_outputs = predicted_outputs.cpu().detach().numpy()  # Convert tensor to numpy array\n",
    "        predicted_outputs_original_scale = output_scaler_rotor.inverse_transform(predicted_outputs.reshape(-1, output_size_rotor))\n",
    "\n",
    "        # Reshape the predictions to match the original sequence structure if needed\n",
    "        predicted_outputs_original_scale = predicted_outputs_original_scale.reshape(input_tensor_test.shape[0], input_tensor_test.shape[1], output_size_rotor)\n",
    "        predicted_outputs_original_scale = predicted_outputs_original_scale[0]\n",
    "\n",
    "        # fft_ct_nn_real = predicted_outputs_original_scale[:,0]\n",
    "        # fft_cq_nn_real = predicted_outputs_original_scale[:,2]\n",
    "        \n",
    "        # fft_ct_nn_imag = predicted_outputs_original_scale[:,1]\n",
    "        # fft_cq_nn_imag = predicted_outputs_original_scale[:,3]\n",
    "\n",
    "        ct_test_NN = predicted_outputs_original_scale[:,0]\n",
    "        cq_test_NN = predicted_outputs_original_scale[:,1]\n",
    "\n",
    "        # Load timesteps, CT and CQ from FLOWUnsteady simualtions\n",
    "        time_steps = dataset_test.get_variable('time')\n",
    "\n",
    "        ct_test_flowuns = dataset_test.get_variable('CT')\n",
    "        cq_test_flowuns = dataset_test.get_variable('CQ')\n",
    "\n",
    "        # complex_ct_nn = fft_ct_nn_real +1j * fft_ct_nn_imag\n",
    "        # ct_test_NN = ifft(complex_ct_nn)\n",
    "\n",
    "        # complex_cq_nn = fft_cq_nn_real +1j * fft_cq_nn_imag\n",
    "        # cq_test_NN = ifft(complex_cq_nn)\n",
    "\n",
    "        plt.figure(figsize=(15, 5))\n",
    "        plt.subplot(1, 2, 1)\n",
    "        # plt.plot(time_steps[0], ct_test_NN, label = 'ct_NN')\n",
    "        # plt.plot(time_steps[0], (ct_test_flowuns[0]), label = 'ct_flowuns')\n",
    "        plt.plot(ct_test_NN, label = 'ct_NN')\n",
    "        plt.plot((ct_test_flowuns[0]), label = 'ct_flowuns')\n",
    "        plt.xlabel('Time [s]')\n",
    "        plt.ylabel('Thrust coefficient, $C_T$')\n",
    "        plt.title(simulation_case)\n",
    "        plt.legend()\n",
    "\n",
    "        # plt.figure()\n",
    "        plt.subplot(1, 2, 2)\n",
    "        # plt.plot(time_steps[0], cq_test_NN, label = 'cq_NN')\n",
    "        # plt.plot(time_steps[0], cq_test_flowuns[0], label = 'cq_flowuns')\n",
    "        plt.plot(cq_test_NN, label = 'cq_NN')\n",
    "        plt.plot(cq_test_flowuns[0], label = 'cq_flowuns')\n",
    "        plt.xlabel('Time [s]')\n",
    "        plt.ylabel('Torque coefficient, $C_Q$')\n",
    "        plt.title(simulation_case)\n",
    "        plt.legend()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vehicle_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
