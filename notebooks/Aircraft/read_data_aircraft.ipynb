{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import sys\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from scipy.fftpack import fft, ifft\n",
    "from scipy.interpolate import CubicSpline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "# Check if GPU is available\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append('/mnt/e/eVTOL_model/eVTOL-VehicleModel/src')\n",
    "\n",
    "\n",
    "# Import necessary functions\n",
    "from utility_functions import downsample_to_35\n",
    "from utility_functions import organize_data\n",
    "\n",
    "# Import all the models\n",
    "from af_escnn_cl import ESCNN_Cl\n",
    "from af_escnn_cd import ESCNN_Cd\n",
    "\n",
    "from af_rbf_cl import RBFLayer_cl, RBFNet_cl\n",
    "from af_rbf_cd import RBFLayer_cd, RBFNet_cd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize Airfoil Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2738139/829076333.py:7: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  af_model_ESCNN_Cl.load_state_dict(torch.load(root_airfoilModelsTrained + '2024-11-18_model_Cl_ESCNN_lr1e-05_e1500_rbf170_convL4.pth'))\n",
      "/tmp/ipykernel_2738139/829076333.py:13: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  af_model_ESCNN_Cd.load_state_dict(torch.load(root_airfoilModelsTrained + '2024-11-18_model_Cd_ESCNN_lr5e-05_e250_convL3.pth'))\n",
      "/tmp/ipykernel_2738139/829076333.py:21: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  kmeans_center_cl = torch.load(root_airfoilModelsTrained + '2024-11-19_airfoil_model_Cl_ESCNN_RBF_lr0.06_epoch200_rbfUnits4_RBFcenters.pth')\n",
      "/tmp/ipykernel_2738139/829076333.py:22: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  kmeans_center_cd = torch.load(root_airfoilModelsTrained + '2024-11-19_airfoil_model_Cd_ESCNN_RBF_lr0.025_epoch100_rbfUnits4_RBFcenters.pth')\n",
      "/tmp/ipykernel_2738139/829076333.py:37: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  airfoil_cl.load_state_dict(torch.load(root_airfoilModelsTrained + '2024-11-19_airfoil_model_Cl_ESCNN_RBF_lr0.06_epoch200_rbfUnits4.pth'))\n",
      "/tmp/ipykernel_2738139/829076333.py:40: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  airfoil_cd.load_state_dict(torch.load(root_airfoilModelsTrained + '2024-11-19_airfoil_model_Cd_ESCNN_RBF_lr0.025_epoch100_rbfUnits4.pth'))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "airfoilModel_cd(\n",
       "  (rbf): RBFLayer_cd()\n",
       "  (fc): Linear(in_features=4, out_features=4, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize airfoil models\n",
    "root_airfoilModelsTrained = '/mnt/e/eVTOL_model/eVTOL-VehicleModel/trained_models/models/airfoil/'\n",
    "# root_scalers = '/mnt/e/eVTOL_model/eVTOL-VehicleModel/trained_models/scalers/'\n",
    "\n",
    "# Load the model weights\n",
    "af_model_ESCNN_Cl = ESCNN_Cl()\n",
    "af_model_ESCNN_Cl.load_state_dict(torch.load(root_airfoilModelsTrained + '2024-11-18_model_Cl_ESCNN_lr1e-05_e1500_rbf170_convL4.pth'))\n",
    "af_model_ESCNN_Cl = af_model_ESCNN_Cl.to(device)\n",
    "af_model_ESCNN_Cl.eval()\n",
    "\n",
    "# Load the model weights\n",
    "af_model_ESCNN_Cd = ESCNN_Cd()\n",
    "af_model_ESCNN_Cd.load_state_dict(torch.load(root_airfoilModelsTrained + '2024-11-18_model_Cd_ESCNN_lr5e-05_e250_convL3.pth'))\n",
    "af_model_ESCNN_Cd = af_model_ESCNN_Cd.to(device)\n",
    "af_model_ESCNN_Cd.eval()\n",
    "\n",
    "input_size = 140\n",
    "output_size = 4\n",
    "num_rbf_units = 4\n",
    "\n",
    "kmeans_center_cl = torch.load(root_airfoilModelsTrained + '2024-11-19_airfoil_model_Cl_ESCNN_RBF_lr0.06_epoch200_rbfUnits4_RBFcenters.pth')\n",
    "kmeans_center_cd = torch.load(root_airfoilModelsTrained + '2024-11-19_airfoil_model_Cd_ESCNN_RBF_lr0.025_epoch100_rbfUnits4_RBFcenters.pth')\n",
    "\n",
    "\n",
    "class airfoilModel_cl(RBFNet_cl):\n",
    "    def __init__(self):\n",
    "        super(airfoilModel_cl, self).__init__(input_size, num_rbf_units, output_size, kmeans_center_cl)\n",
    "\n",
    "\n",
    "class airfoilModel_cd(RBFNet_cd):\n",
    "    def __init__(self):\n",
    "        super(airfoilModel_cd, self).__init__(input_size, num_rbf_units, output_size, kmeans_center_cd)\n",
    "\n",
    "\n",
    "# Initialize the model\n",
    "airfoil_cl = airfoilModel_cl()\n",
    "airfoil_cl.load_state_dict(torch.load(root_airfoilModelsTrained + '2024-11-19_airfoil_model_Cl_ESCNN_RBF_lr0.06_epoch200_rbfUnits4.pth'))\n",
    "\n",
    "airfoil_cd = airfoilModel_cd()\n",
    "airfoil_cd.load_state_dict(torch.load(root_airfoilModelsTrained + '2024-11-19_airfoil_model_Cd_ESCNN_RBF_lr0.025_epoch100_rbfUnits4.pth'))\n",
    "\n",
    "airfoil_cl = airfoil_cl.to(device)\n",
    "airfoil_cd = airfoil_cd.to(device)\n",
    "\n",
    "airfoil_cl.eval()\n",
    "airfoil_cd.eval()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Wing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape (Canard dataset): torch.Size([22, 277, 10])\n",
      "Output shape (Canard dataset): torch.Size([22, 277, 2])\n",
      "Input shape (Wing dataset): torch.Size([22, 277, 10])\n",
      "Output shape (Wing dataset): torch.Size([22, 277, 2])\n"
     ]
    }
   ],
   "source": [
    "from create_wing_dataset import WingDataset, subdir_condition_wing   # Make sure to reload the create wing dataset module manually after changes\n",
    "\n",
    "# root_dir_wing = '/mnt/e/Course_Materials/ROM/wing_model/FLOWUnsteady_simulations/eMO_dataset_train'\n",
    "root_dir_wing = '/mnt/e/eVTOL_model/eVTOL-VehicleModel/FLOWUnsteady_simulations'\n",
    "\n",
    "# Canard dataset\n",
    "dataset_canard = WingDataset(root_dir_wing, \n",
    "                                af_model_ESCNN_Cl=af_model_ESCNN_Cl, \n",
    "                                af_model_ESCNN_Cd=af_model_ESCNN_Cd,\n",
    "                                airfoil_cl=airfoil_cl, \n",
    "                                airfoil_cd=airfoil_cd, \n",
    "                                device=device,\n",
    "                                wing_name = 'Canard',     # select 'wing_main' or 'Canard'  \n",
    "                                subdir_condition=subdir_condition_wing)\n",
    "\n",
    "inputs_canard, outputs_canard = dataset_canard[0:]\n",
    "\n",
    "input_tensor_canard = inputs_canard\n",
    "input_tensor_canard = inputs_canard.squeeze(1)  # Reshaping\n",
    "print(\"Input shape (Canard dataset):\", input_tensor_canard.shape)\n",
    "\n",
    "output_tensor_canard = outputs_canard.squeeze(1)\n",
    "print(\"Output shape (Canard dataset):\",output_tensor_canard.shape) \n",
    "\n",
    "# Wing dataset\n",
    "dataset_wing = WingDataset(root_dir_wing, \n",
    "                            af_model_ESCNN_Cl=af_model_ESCNN_Cl, \n",
    "                            af_model_ESCNN_Cd=af_model_ESCNN_Cd,\n",
    "                            airfoil_cl=airfoil_cl, \n",
    "                            airfoil_cd=airfoil_cd, \n",
    "                            device=device,\n",
    "                            wing_name = 'wing_main',     # select 'wing_main' or 'Canard'  \n",
    "                            subdir_condition=subdir_condition_wing)\n",
    "\n",
    "inputs_wing, outputs_wing = dataset_wing[0:]\n",
    "\n",
    "input_tensor_wing = inputs_wing\n",
    "input_tensor_wing = inputs_wing.squeeze(1)  # Reshaping\n",
    "print(\"Input shape (Wing dataset):\", input_tensor_wing.shape)\n",
    "\n",
    "output_tensor_wing = outputs_wing.squeeze(1)\n",
    "print(\"Output shape (Wing dataset):\",output_tensor_wing.shape) \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Rotor Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape (rotor - L1): torch.Size([22, 280, 10])\n",
      "Output shape (rotor - L1): torch.Size([22, 280, 4])\n",
      "Input shape (rotor - L2): torch.Size([22, 280, 10])\n",
      "Output shape (rotor - L2): torch.Size([22, 280, 4])\n",
      "Input shape (rotor - L3): torch.Size([22, 280, 10])\n",
      "Output shape (rotor - L3): torch.Size([22, 280, 4])\n",
      "Input shape (rotor - L4): torch.Size([22, 280, 10])\n",
      "Output shape (rotor - L4): torch.Size([22, 280, 4])\n"
     ]
    }
   ],
   "source": [
    "from create_rotor_dataset import PropellerDataset, subdir_condition_rotor\n",
    "\n",
    "# Root directory where simulation subdirectories are stored\n",
    "# root_dir_rotor = '/mnt/e/Course_Materials/ROM/rotor_solver/FLOWUnsteady_simulations/train_data'\n",
    "root_dir_rotor = '/mnt/e/eVTOL_model/eVTOL-VehicleModel/FLOWUnsteady_simulations'\n",
    "\n",
    "# dataset - Rotor L1\n",
    "dataset_rotor_L1 = PropellerDataset(root_dir_rotor,\n",
    "                           rotor_notation = 'L1',                       # Select: L1, L2, L3, L4, R1, R2, R3, R4\n",
    "                           subdir_condition=subdir_condition_rotor)\n",
    "inputs_rL1, outputs_rL1 = dataset_rotor_L1[0:]\n",
    "\n",
    "\n",
    "input_tensor_rL1 = inputs_rL1.squeeze(1)  # Reshaping\n",
    "print(\"Input shape (rotor - L1):\", input_tensor_rL1.shape) \n",
    "\n",
    "output_tensor_rL1 = outputs_rL1.squeeze(1)\n",
    "print(\"Output shape (rotor - L1):\",output_tensor_rL1.shape) \n",
    "\n",
    "\n",
    "# dataset - Rotor L2\n",
    "dataset_rotor_L2 = PropellerDataset(root_dir_rotor,\n",
    "                           rotor_notation = 'L2',                       # Select: L1, L2, L3, L4, R1, R2, R3, R4\n",
    "                           subdir_condition=subdir_condition_rotor)\n",
    "inputs_rL2, outputs_rL2 = dataset_rotor_L2[0:]\n",
    "\n",
    "\n",
    "input_tensor_rL2 = inputs_rL2.squeeze(1)  # Reshaping\n",
    "print(\"Input shape (rotor - L2):\", input_tensor_rL2.shape) \n",
    "\n",
    "output_tensor_rL2 = outputs_rL2.squeeze(1)\n",
    "print(\"Output shape (rotor - L2):\",output_tensor_rL2.shape) \n",
    "\n",
    "# dataset - Rotor L3\n",
    "dataset_rotor_L3 = PropellerDataset(root_dir_rotor,\n",
    "                           rotor_notation = 'L3',                       # Select: L1, L2, L3, L4, R1, R2, R3, R4\n",
    "                           subdir_condition=subdir_condition_rotor)\n",
    "inputs_rL3, outputs_rL3 = dataset_rotor_L3[0:]\n",
    "\n",
    "\n",
    "input_tensor_rL3 = inputs_rL3.squeeze(1)  # Reshaping\n",
    "print(\"Input shape (rotor - L3):\", input_tensor_rL3.shape) \n",
    "\n",
    "output_tensor_rL3 = outputs_rL3.squeeze(1)\n",
    "print(\"Output shape (rotor - L3):\",output_tensor_rL3.shape) \n",
    "\n",
    "# dataset - Rotor L4\n",
    "dataset_rotor_L4 = PropellerDataset(root_dir_rotor,\n",
    "                           rotor_notation = 'L4',                       # Select: L1, L2, L3, L4, R1, R2, R3, R4\n",
    "                           subdir_condition=subdir_condition_rotor)\n",
    "inputs_rL4, outputs_rL4 = dataset_rotor_L4[0:]\n",
    "\n",
    "\n",
    "input_tensor_rL4 = inputs_rL4.squeeze(1)  # Reshaping\n",
    "print(\"Input shape (rotor - L4):\", input_tensor_rL4.shape) \n",
    "\n",
    "output_tensor_rL4 = outputs_rL4.squeeze(1)\n",
    "print(\"Output shape (rotor - L4):\",output_tensor_rL4.shape) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape (rotor - R1): torch.Size([22, 280, 10])\n",
      "Output shape (rotor - R1): torch.Size([22, 280, 4])\n",
      "Input shape (rotor - R2): torch.Size([22, 280, 10])\n",
      "Output shape (rotor - R2): torch.Size([22, 280, 4])\n",
      "Input shape (rotor - R3): torch.Size([22, 280, 10])\n",
      "Output shape (rotor - R3): torch.Size([22, 280, 4])\n",
      "Input shape (rotor - R4): torch.Size([22, 280, 10])\n",
      "Output shape (rotor - R4): torch.Size([22, 280, 4])\n"
     ]
    }
   ],
   "source": [
    "# dataset - Rotor R1\n",
    "dataset_rotor_R1 = PropellerDataset(root_dir_rotor,\n",
    "                           rotor_notation = 'R1',                       # Select: L1, L2, L3, L4, R1, R2, R3, R4\n",
    "                           subdir_condition=subdir_condition_rotor)\n",
    "inputs_rR1, outputs_rR1 = dataset_rotor_R1[0:]\n",
    "\n",
    "\n",
    "input_tensor_rR1 = inputs_rR1.squeeze(1)  # Reshaping\n",
    "print(\"Input shape (rotor - R1):\", input_tensor_rR1.shape) \n",
    "\n",
    "output_tensor_rR1 = outputs_rR1.squeeze(1)\n",
    "print(\"Output shape (rotor - R1):\",output_tensor_rR1.shape) \n",
    "\n",
    "\n",
    "# dataset - Rotor R2\n",
    "dataset_rotor_R2 = PropellerDataset(root_dir_rotor,\n",
    "                           rotor_notation = 'R2',                       # Select: L1, L2, L3, L4, R1, R2, R3, R4\n",
    "                           subdir_condition=subdir_condition_rotor)\n",
    "inputs_rR2, outputs_rR2 = dataset_rotor_R2[0:]\n",
    "\n",
    "\n",
    "input_tensor_rR2 = inputs_rR2.squeeze(1)  # Reshaping\n",
    "print(\"Input shape (rotor - R2):\", input_tensor_rR2.shape) \n",
    "\n",
    "output_tensor_rR2 = outputs_rR2.squeeze(1)\n",
    "print(\"Output shape (rotor - R2):\",output_tensor_rR2.shape) \n",
    "\n",
    "# dataset - Rotor R3\n",
    "dataset_rotor_R3 = PropellerDataset(root_dir_rotor,\n",
    "                           rotor_notation = 'R3',                       # Select: L1, L2, L3, L4, R1, R2, R3, R4\n",
    "                           subdir_condition=subdir_condition_rotor)\n",
    "inputs_rR3, outputs_rR3 = dataset_rotor_R3[0:]\n",
    "\n",
    "\n",
    "input_tensor_rR3 = inputs_rR3.squeeze(1)  # Reshaping\n",
    "print(\"Input shape (rotor - R3):\", input_tensor_rR3.shape) \n",
    "\n",
    "output_tensor_rR3 = outputs_rR3.squeeze(1)\n",
    "print(\"Output shape (rotor - R3):\",output_tensor_rR3.shape) \n",
    "\n",
    "# dataset - Rotor R4\n",
    "dataset_rotor_R4 = PropellerDataset(root_dir_rotor,\n",
    "                           rotor_notation = 'R4',                       # Select: L1, L2, L3, L4, R1, R2, R3, R4\n",
    "                           subdir_condition=subdir_condition_rotor)\n",
    "inputs_rR4, outputs_rR4 = dataset_rotor_R4[0:]\n",
    "\n",
    "\n",
    "input_tensor_rR4 = inputs_rR4.squeeze(1)  # Reshaping\n",
    "print(\"Input shape (rotor - R4):\", input_tensor_rR4.shape) \n",
    "\n",
    "output_tensor_rR4 = outputs_rR4.squeeze(1)\n",
    "print(\"Output shape (rotor - R4):\",output_tensor_rR4.shape) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Wing Model and Initialize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2738139/1761514772.py:19: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  wing_model_static.load_state_dict(torch.load(root_wingModelsTrained+'2024-11-19_LSTM_eMO_wingModel_static_lr0.002_e1200_nL3_numNN50.pth'))\n",
      "/mnt/e/eVTOL_model/eVTOL-VehicleModel/vehicle_env/lib/python3.11/site-packages/sklearn/base.py:380: InconsistentVersionWarning: Trying to unpickle estimator MinMaxScaler from version 1.5.2 when using version 1.6.0. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from wing_static import LSTMNet_static\n",
    "\n",
    "# Static Model\n",
    "input_size_wing_stat = 10           # Number of input features\n",
    "hidden_size_wing_stat = 50          # Hidden LSTM cells\n",
    "output_size_wing_stat = 2           # Number of output features\n",
    "num_layers_wing_stat = 3            # Number of LSTM layers\n",
    "\n",
    "class WingModel_static(LSTMNet_static):\n",
    "    def __init__(self):\n",
    "        super(WingModel_static, self).__init__(input_size_wing_stat, hidden_size_wing_stat, output_size_wing_stat, num_layers_wing_stat)\n",
    "\n",
    "# Initialize the model\n",
    "\n",
    "root_wingModelsTrained = '/mnt/e/eVTOL_model/eVTOL-VehicleModel/trained_models/models/wing/'\n",
    "root_wingScalersTrained = '/mnt/e/eVTOL_model/eVTOL-VehicleModel/trained_models/scalers/wing/'\n",
    "\n",
    "wing_model_static = WingModel_static()\n",
    "wing_model_static.load_state_dict(torch.load(root_wingModelsTrained+'2024-11-19_LSTM_eMO_wingModel_static_lr0.002_e1200_nL3_numNN50.pth'))\n",
    "wing_model_static = wing_model_static.to(device)\n",
    "wing_model_static.eval()\n",
    "\n",
    "# Load the scaler\n",
    "input_scaler_wing_stat = joblib.load(root_wingScalersTrained+'2024-11-19_LSTM_eMO_wingModel_static_ipScaler_lr0.002_e1200_nL3_numNN50.pkl')\n",
    "output_scaler_wing_stat = joblib.load(root_wingScalersTrained+'2024-11-19_LSTM_eMO_wingModel_static_opScaler_lr0.002_e1200_nL3_numNN50.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Rotor Model and Initialize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2738139/1019873830.py:17: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  prop_model.load_state_dict(torch.load(root_rotorModelsTrained+'2024-10-04_propModel_lr0.005_e1500_nL2_numNN50.pth'))\n"
     ]
    }
   ],
   "source": [
    "from rotor_model import LSTMNet_rotor\n",
    "\n",
    "input_size = 10\n",
    "hidden_size = 50\n",
    "output_size = 4\n",
    "num_layers = 2\n",
    "\n",
    "class PropModel(LSTMNet_rotor):\n",
    "    def __init__(self):\n",
    "        super(PropModel, self).__init__(input_size, hidden_size, output_size, num_layers)\n",
    "\n",
    "root_rotorModelsTrained = '/mnt/e/eVTOL_model/eVTOL-VehicleModel/trained_models/models/rotor/'\n",
    "root_rotorScalersTrained = '/mnt/e/eVTOL_model/eVTOL-VehicleModel/trained_models/scalers/rotor/'\n",
    "\n",
    "# Initialize the model\n",
    "prop_model = PropModel()\n",
    "prop_model.load_state_dict(torch.load(root_rotorModelsTrained+'2024-10-04_propModel_lr0.005_e1500_nL2_numNN50.pth'))\n",
    "prop_model = prop_model.to(device)\n",
    "prop_model.eval()\n",
    "\n",
    "# Load the scaler\n",
    "input_scaler = joblib.load(root_rotorScalersTrained+'2024-10-04_ipScaler_lr0.005_e1500_nL2_numNN50.pkl')\n",
    "output_scaler = joblib.load(root_rotorScalersTrained+'2024-10-04_opScaler_lr0.005_e1500_nL2_numNN50.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.interpolate import interp1d\n",
    "import numpy as np\n",
    "\n",
    "def align_timesteps(data, target_length):\n",
    "    original_length = data.shape[1]\n",
    "    x = np.linspace(0, 1, original_length)\n",
    "    x_new = np.linspace(0, 1, target_length)\n",
    "    interpolator = interp1d(x, data, axis=1, kind='linear')\n",
    "    return interpolator(x_new)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class AircraftDataset(Dataset):\n",
    "#     def __init__(self, wing_dataset, propeller_1_dataset, propeller_2_dataset, additional_data=None):\n",
    "#         \"\"\"\n",
    "#         Args:\n",
    "#             wing_dataset (WingDataset): Instance of WingDataset.\n",
    "#             propeller_dataset (PropellerDataset): Instance of PropellerDataset.\n",
    "#             additional_data (dict, optional): Any additional data to include in the dataset.\n",
    "#         \"\"\"\n",
    "#         self.wing_dataset = wing_dataset\n",
    "#         self.propeller_dataset_L1 = propeller_1_dataset\n",
    "#         self.propeller_dataset_R1 = propeller_2_dataset\n",
    "#         self.additional_data = additional_data or {}\n",
    "\n",
    "#         # Combine data from wing and propeller datasets\n",
    "#         self.data = []\n",
    "#         self.targets = []\n",
    "\n",
    "#         self._combine_data()\n",
    "\n",
    "#     def _combine_data(self):\n",
    "#         \"\"\"\n",
    "#         Combine input and target data from WingDataset and PropellerDataset.\n",
    "#         \"\"\"\n",
    "#         inputs_wing, target_wing = self.wing_dataset[0:]\n",
    "#         inputs_wing = inputs_wing.squeeze(1)\n",
    "#         target_wing = target_wing.squeeze(1)\n",
    "\n",
    "#         inputs_rotor_L1, target_rotor_L1 = self.propeller_dataset_L1[0:]\n",
    "#         inputs_rotor_L1 = inputs_rotor_L1.squeeze(1)\n",
    "#         target_rotor_L1 = target_rotor_L1.squeeze(1)\n",
    "\n",
    "#         inputs_rotor_R1, target_rotor_R1 = self.propeller_dataset_R1[0:]\n",
    "#         inputs_rotor_R1 = inputs_rotor_R1.squeeze(1)\n",
    "#         target_rotor_R1 = target_rotor_R1.squeeze(1)\n",
    "\n",
    "#         k = 0.1301                          # Scale factor\n",
    "        \n",
    "#         # Aircraft features - Constant\n",
    "#         or1_x = 0.36 * k                    # distance between rotor 1 and the origin\n",
    "#         or1_y = 3.842 * k\n",
    "#         or1_z = 0.5 * k\n",
    "\n",
    "#         # or2_x = 2.28 * k                    # distance between rotor 2 and the origin\n",
    "#         # or2_y = 3.842 * k\n",
    "#         # or2_z = 0.5 * k \n",
    "        \n",
    "#         # or3_x = 4.20 * k                    # distance between rotor 3 and the origin\n",
    "#         # or3_y = 3.842 * k\n",
    "#         # or3_z = 0.5 * k \n",
    "        \n",
    "#         # or4_x = 6.54 * k                    # distance between rotor 4 and the origin\n",
    "#         # or4_y = 3.842 * k\n",
    "#         # or4_z = 0.5 * k \n",
    "\n",
    "#         # r1r2_x = or2_x - or1_x              # distance between rotors 1 and 2\n",
    "#         # r2r3_x = or3_x - or2_x              # distance between rotors 2 and 3\n",
    "#         # r3r4_x = or4_x - or3_x              # distance between rotors 3 and 4\n",
    "        \n",
    "#         oc_x = 1.14 * k                     # distance between canard and the origin\n",
    "#         oc_y = 0.0\n",
    "#         oc_z = 0.35 * k\n",
    "        \n",
    "#         # ow_x = 4.505 * k                    # distance between wing and the origin\n",
    "#         # ow_y = 0.0\n",
    "#         # ow_z = -0.2 * k\n",
    "        \n",
    "#         # cw_x = ow_x - oc_x                  # distance between canard and wing \n",
    "\n",
    "#         cr1_x = oc_x - or1_x\n",
    "#         cr1_y = oc_y - or1_y\n",
    "#         cr1_z = oc_z - or1_z\n",
    "\n",
    "\n",
    "#         # Aircraft features - time varying\n",
    "#         # wing features\n",
    "#         T = inputs_wing[:,:,0]\n",
    "#         AOA = inputs_wing[:,:,1]    # Same for both rotors and wing\n",
    "#         v_inf = inputs_wing[:,:,2]\n",
    "#         # rotor features\n",
    "#         omega = inputs_rotor_L1[:,:,2]  # Assumption: All rotors have same rotational velocity\n",
    "#         omega = align_timesteps(omega, T.shape[1])\n",
    "#         omega = torch.tensor(omega, dtype=torch.float32)\n",
    "        \n",
    "#         ref_angle_L1 = inputs_rotor_L1[:,:,1]\n",
    "#         ref_angle_L1 = align_timesteps(ref_angle_L1, T.shape[1])\n",
    "#         ref_angle_L1 = torch.tensor(ref_angle_L1, dtype=torch.float32)\n",
    "\n",
    "#         ref_angle_R1 = inputs_rotor_R1[:,:,1]\n",
    "#         ref_angle_R1 = align_timesteps(ref_angle_R1, T.shape[1])\n",
    "#         ref_angle_R1 = torch.tensor(ref_angle_R1, dtype=torch.float32)\n",
    "        \n",
    "#         aircraft_input = torch.stack([T, AOA, v_inf, omega, ref_angle_L1, ref_angle_R1], dim=2)\n",
    "#         print(\"Inputs shape (Aircraft)\", aircraft_input.shape)\n",
    "\n",
    "\n",
    "#         # Aircraft level targets\n",
    "#         target_rotor_L1 = align_timesteps(target_rotor_L1, T.shape[1])\n",
    "#         target_rotor_L1 = torch.tensor(target_rotor_L1, dtype=torch.float32)\n",
    "\n",
    "#         target_rotor_R1 = align_timesteps(target_rotor_R1, T.shape[1])\n",
    "#         target_rotor_R1 = torch.tensor(target_rotor_R1, dtype=torch.float32)\n",
    "\n",
    "#         aircraft_target = torch.cat([target_wing, target_rotor_L1, target_rotor_R1], dim=2)\n",
    "#         print(\"Targets shape (Aircraft)\", aircraft_target.shape)\n",
    "\n",
    "\n",
    "#     def __len__(self):\n",
    "#         \"\"\"\n",
    "#         Returns the total number of sequences in the dataset.\n",
    "#         \"\"\"\n",
    "#         return len(self.data)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AircraftDataset(Dataset):\n",
    "    def __init__(self, wing_dataset, canard_dataset, propeller_1_dataset, propeller_2_dataset, \n",
    "                 propeller_3_dataset, propeller_4_dataset, propeller_5_dataset, propeller_6_dataset, propeller_7_dataset, propeller_8_dataset, additional_data=None):\n",
    "        super().__init__()\n",
    "        self.wing_dataset = wing_dataset\n",
    "        self.canard_dataset = canard_dataset\n",
    "        self.propeller_dataset_L1 = propeller_1_dataset\n",
    "        self.propeller_dataset_R1 = propeller_2_dataset\n",
    "        self.propeller_dataset_L2 = propeller_3_dataset\n",
    "        self.propeller_dataset_R2 = propeller_4_dataset\n",
    "        self.propeller_dataset_L3 = propeller_5_dataset\n",
    "        self.propeller_dataset_R3 = propeller_6_dataset\n",
    "        self.propeller_dataset_L4 = propeller_7_dataset\n",
    "        self.propeller_dataset_R4 = propeller_8_dataset\n",
    "        self.additional_data = additional_data or {}\n",
    "\n",
    "        # Constants\n",
    "        k = 0.1301\n",
    "        self.constants = {\n",
    "            \"or1_x\": 0.36 * k,\n",
    "            \"or1_y\": 3.842 * k,\n",
    "            \"or1_z\": 0.5 * k,\n",
    "            \"oc_x\": 1.14 * k,\n",
    "            \"oc_y\": 0.0,\n",
    "            \"oc_z\": 0.35 * k,\n",
    "            \"cr1_x\": 1.14 * k - 0.36 * k,\n",
    "            \"cr1_y\": 0.0 - 3.842 * k,\n",
    "            \"cr1_z\": 0.35 * k - 0.5 * k,\n",
    "        }\n",
    "\n",
    "        # Initialize data storage\n",
    "        self.data = {\n",
    "            \"time_varying_inputs\": None,\n",
    "            \"constant_inputs\": None,\n",
    "            \"node_data\": {},  # Store node-specific time-varying data\n",
    "        }\n",
    "        self.targets = None\n",
    "\n",
    "        # Combine datasets\n",
    "        self._combine_data()\n",
    "\n",
    "    def _combine_data(self):\n",
    "        # Load wing and rotor datasets\n",
    "        inputs_wing, target_wing = self.wing_dataset[0:]\n",
    "        inputs_wing = inputs_wing.squeeze(1)\n",
    "        target_wing = target_wing.squeeze(1)\n",
    "\n",
    "        inputs_canard, target_canard = self.canard_dataset[0:]\n",
    "        inputs_canard = inputs_canard.squeeze(1)\n",
    "        target_canard = target_canard.squeeze(1)\n",
    "        \n",
    "        inputs_rotor_L1, target_rotor_L1 = self.propeller_dataset_L1[0:]\n",
    "        inputs_rotor_L1 = inputs_rotor_L1.squeeze(1)\n",
    "        target_rotor_L1 = target_rotor_L1.squeeze(1)\n",
    "\n",
    "        inputs_rotor_R1, target_rotor_R1 = self.propeller_dataset_R1[0:]\n",
    "        inputs_rotor_R1 = inputs_rotor_R1.squeeze(1)\n",
    "        target_rotor_R1 = target_rotor_R1.squeeze(1)\n",
    "\n",
    "        inputs_rotor_L2, target_rotor_L2 = self.propeller_dataset_L2[0:]\n",
    "        inputs_rotor_L2 = inputs_rotor_L2.squeeze(1)\n",
    "        target_rotor_L2 = target_rotor_L2.squeeze(1)\n",
    "\n",
    "        inputs_rotor_R2, target_rotor_R2 = self.propeller_dataset_R2[0:]\n",
    "        inputs_rotor_R2 = inputs_rotor_R2.squeeze(1)\n",
    "        target_rotor_R2 = target_rotor_R2.squeeze(1)\n",
    "\n",
    "        inputs_rotor_L3, target_rotor_L3 = self.propeller_dataset_L3[0:]\n",
    "        inputs_rotor_L3 = inputs_rotor_L3.squeeze(1)\n",
    "        target_rotor_L3 = target_rotor_L3.squeeze(1)\n",
    "\n",
    "        inputs_rotor_R3, target_rotor_R3 = self.propeller_dataset_R3[0:]\n",
    "        inputs_rotor_R3 = inputs_rotor_R3.squeeze(1)\n",
    "        target_rotor_R3 = target_rotor_R3.squeeze(1)\n",
    "\n",
    "        inputs_rotor_L1, target_rotor_L1 = self.propeller_dataset_L1[0:]\n",
    "        inputs_rotor_L1 = inputs_rotor_L1.squeeze(1)\n",
    "        target_rotor_L1 = target_rotor_L1.squeeze(1)\n",
    "\n",
    "        inputs_rotor_R1, target_rotor_R1 = self.propeller_dataset_R1[0:]\n",
    "        inputs_rotor_R1 = inputs_rotor_R1.squeeze(1)\n",
    "        target_rotor_R1 = target_rotor_R1.squeeze(1)\n",
    "\n",
    "        # Time-varying features\n",
    "        T = inputs_wing[:, :, 0]\n",
    "        AOA = inputs_wing[:, :, 1]\n",
    "        v_inf = inputs_wing[:, :, 2]\n",
    "        omega = torch.tensor(align_timesteps(inputs_rotor_L1[:, :, 2], T.shape[1]), dtype=torch.float64)\n",
    "\n",
    "        # Resize the rotor inputs\n",
    "        inputs_resized_rotor_L1 = torch.tensor(align_timesteps(inputs_rotor_L1, T.shape[1]), dtype=torch.float32)\n",
    "        inputs_resized_rotor_R1 = torch.tensor(align_timesteps(inputs_rotor_R1, T.shape[1]), dtype=torch.float32)\n",
    "        \n",
    "        ref_angle_L1 = torch.tensor(align_timesteps(inputs_rotor_L1[:, :, 1], T.shape[1]), dtype=torch.float32)\n",
    "        ref_angle_R1 = torch.tensor(align_timesteps(inputs_rotor_R1[:, :, 1], T.shape[1]), dtype=torch.float32)\n",
    "        # omega_R1 = align_timesteps(inputs_rotor_R1[:, :, 2], T.shape[1])\n",
    "        \n",
    "\n",
    "        # Store time-varying inputs in self.data\n",
    "        self.data[\"time_varying_inputs\"] = torch.stack([T, AOA, v_inf, omega, ref_angle_L1, ref_angle_R1], dim=2)       # [22, 277, 6]\n",
    "        self.data[\"node_data\"][\"wing\"] = inputs_wing                    # [22, 277, 10]\n",
    "        self.data[\"node_data\"][\"rotor_1\"] = inputs_resized_rotor_L1     # [22, 277, 10]\n",
    "        self.data[\"node_data\"][\"rotor_2\"] = inputs_resized_rotor_R1     # [22, 277, 10]\n",
    "\n",
    "        # Store constant features\n",
    "        self.data[\"constant_inputs\"] = torch.tensor(list(self.constants.values()), dtype=torch.float32)\n",
    "\n",
    "        # Combine targets\n",
    "        target_rotor_L1 = torch.tensor(align_timesteps(target_rotor_L1, T.shape[1]), dtype=torch.float32)       # [22, 277, 4]\n",
    "        target_rotor_R1 = torch.tensor(align_timesteps(target_rotor_R1, T.shape[1]), dtype=torch.float32)       # [22, 277, 4]\n",
    "\n",
    "        self.targets = torch.cat([target_wing, target_rotor_L1, target_rotor_R1], dim=2)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data[\"time_varying_inputs\"])\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        inputs = {\n",
    "            \"node_data\": {\n",
    "                \"rotor_1\": self.data[\"node_data\"][\"rotor_1\"][idx],\n",
    "                \"rotor_2\": self.data[\"node_data\"][\"rotor_2\"][idx],\n",
    "                \"wing\": self.data[\"node_data\"][\"wing\"][idx]\n",
    "            },\n",
    "            \"constant_inputs\": self.data[\"constant_inputs\"],\n",
    "            \"time_varying_inputs\": self.data[\"time_varying_inputs\"][idx]\n",
    "        }\n",
    "        targets = self.targets[idx]\n",
    "        return inputs, targets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.data import Data\n",
    "\n",
    "def create_graph(inputs, targets):\n",
    "    \"\"\"\n",
    "    Create a graph structure from dataset inputs and targets.\n",
    "\n",
    "    Args:\n",
    "        inputs (dict): Includes node data and constant inputs.\n",
    "        targets (Tensor): The target outputs.\n",
    "\n",
    "    Returns:\n",
    "        Data: PyTorch Geometric Data object representing the graph.\n",
    "    \"\"\"\n",
    "    # print(\"Inputs in create_graph:\", inputs)\n",
    "    # print(\"Node Data:\", inputs.get(\"node_data\", \"Missing 'node_data'\"))\n",
    "    # Extract node features\n",
    "    node_features = torch.stack([\n",
    "        inputs[\"node_data\"][\"wing\"],            # Node 0: Wing features\n",
    "        inputs[\"node_data\"][\"rotor_1\"],         # Node 1: Rotor 1 features\n",
    "        inputs[\"node_data\"][\"rotor_2\"]          # Node 2: Rotor 2 features\n",
    "        \n",
    "    ], dim=0)  # Shape: (num_nodes, timesteps, features)\n",
    "\n",
    "    source = [0, 1, 0, 2]\n",
    "    target = [1, 0, 2, 0]\n",
    "    \n",
    "    # Define edge index (connectivity)\n",
    "    edge_index = torch.tensor([source, target], dtype=torch.long)\n",
    "\n",
    "\n",
    "    cr1_x = inputs[\"constant_inputs\"][6]\n",
    "    cr1_y = inputs[\"constant_inputs\"][7]\n",
    "    cr1_z = inputs[\"constant_inputs\"][8]\n",
    "\n",
    "    edge_attr = torch.tensor([[cr1_x, cr1_y, cr1_z]] * len(source), dtype=torch.float32)  # Same for all edges\n",
    "\n",
    "\n",
    "    # Create graph data object\n",
    "    graph = Data(\n",
    "        x=node_features,          # Node features\n",
    "        edge_index=edge_index,    # Edge connectivity\n",
    "        edge_attr=edge_attr,      # Edge features\n",
    "        y=targets                 # Targets\n",
    "    )\n",
    "    return graph\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_graph_aircraft(inputs, targets):\n",
    "    \"\"\"\n",
    "    Create a graph structure from dataset inputs and targets.\n",
    "\n",
    "    Args:\n",
    "        inputs (dict): Includes node data and constant inputs.\n",
    "        targets (Tensor): The target outputs.\n",
    "\n",
    "    Returns:\n",
    "        Data: PyTorch Geometric Data object representing the graph.\n",
    "    \"\"\"\n",
    "    # print(\"Inputs in create_graph:\", inputs)\n",
    "    # print(\"Node Data:\", inputs.get(\"node_data\", \"Missing 'node_data'\"))\n",
    "    # Extract node features\n",
    "    node_features = torch.stack([\n",
    "        inputs[\"node_data\"][\"wing\"],            # Node 0: Wing features\n",
    "        inputs[\"node_data\"][\"rotor_1\"],         # Node 1: Rotor 1 features\n",
    "        inputs[\"node_data\"][\"rotor_2\"]          # Node 2: Rotor 2 features\n",
    "        \n",
    "    ], dim=0)  # Shape: (num_nodes, timesteps, features)\n",
    "\n",
    "    source = [0, 1, 0, 2, 0, 3, 0, 6, 0, 7, 1, 4, 1, 5, 1, 8, 1, 9, 2, 3, 4, 6, 7, 8]\n",
    "    target = [1, 0, 2, 0, 3, 0, 6, 0, 7, 0, 4, 1, 5, 1, 8, 1, 9, 1, 3, 4, 5, 7, 8, 9]\n",
    "    \n",
    "    # Define edge index (connectivity)\n",
    "    edge_index = torch.tensor([source, target], dtype=torch.long)\n",
    "\n",
    "\n",
    "    cr1_x = inputs[\"constant_inputs\"][6]\n",
    "    cr1_y = inputs[\"constant_inputs\"][7]\n",
    "    cr1_z = inputs[\"constant_inputs\"][8]\n",
    "\n",
    "    edge_attr = torch.tensor([[cr1_x, cr1_y, cr1_z]] * len(source), dtype=torch.float32)  # Same for all edges\n",
    "\n",
    "\n",
    "    # Create graph data object\n",
    "    graph = Data(\n",
    "        x=node_features,          # Node features\n",
    "        edge_index=edge_index,    # Edge connectivity\n",
    "        edge_attr=edge_attr,      # Edge features\n",
    "        y=targets                 # Targets\n",
    "    )\n",
    "    return graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def create_graph_batch(inputs_batch, targets_batch):\n",
    "#     graphs = []\n",
    "#     for input, target in zip(inputs_batch, targets_batch):\n",
    "#         print(\"Inputs-iter:\", type(input))\n",
    "#         print(\"Targets-iter:\", type(target))\n",
    "\n",
    "#         print(\"Inputs-provided:\", type(inputs_batch))\n",
    "#         print(\"Targets-provided:\", type(targets_batch))\n",
    "        \n",
    "#         # Ensure each input is processed correctly\n",
    "#     #     if not isinstance(inputs, dict):\n",
    "#     #         raise ValueError(f\"Expected inputs to be a dict, got {type(inputs)}\")\n",
    "#     #     graph = create_graph(inputs, targets)  # Create graph for each input/target pair\n",
    "#     #     graphs.append(graph)\n",
    "    # return graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.loader import DataLoader\n",
    "\n",
    "class CombinedDataset:\n",
    "    \"\"\"\n",
    "    A combined dataset that returns both raw data and graph representation.\n",
    "    \"\"\"\n",
    "    def __init__(self, dataset):\n",
    "        self.dataset = dataset\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Get raw inputs and targets\n",
    "        inputs, targets = self.dataset[idx]\n",
    "        # Create graph representation\n",
    "        graph = create_graph(inputs, targets)\n",
    "        return inputs, targets, graph  # Return raw and graph data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "from torch_geometric.utils import to_networkx\n",
    "\n",
    "def visualize_graph(graph):\n",
    "    \"\"\"\n",
    "    Visualize a PyTorch Geometric graph using NetworkX.\n",
    "    \n",
    "    Args:\n",
    "        graph (torch_geometric.data.Data): The graph to visualize.\n",
    "    \"\"\"\n",
    "    # Convert PyTorch Geometric Data object to NetworkX graph\n",
    "    nx_graph = to_networkx(graph, edge_attrs=[\"edge_attr\"], to_undirected=True)\n",
    "\n",
    "    # Plot the graph\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    pos = nx.spring_layout(nx_graph)  # Use spring layout for positioning\n",
    "    nx.draw(\n",
    "        nx_graph,\n",
    "        pos,\n",
    "        with_labels=True,\n",
    "        node_color=\"skyblue\",\n",
    "        node_size=500,\n",
    "        edge_color=\"gray\",\n",
    "        font_weight=\"bold\"\n",
    "    )\n",
    "\n",
    "    # Annotate edge attributes\n",
    "    edge_labels = nx.get_edge_attributes(nx_graph, \"edge_attr\")\n",
    "    edge_labels = {k: tuple(round(x, 2) for x in v) for k, v in edge_labels.items()}  # Round for readability\n",
    "    nx.draw_networkx_edge_labels(nx_graph, pos, edge_labels=edge_labels, font_size=10)\n",
    "\n",
    "    plt.title(\"Graph Structure\")\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch_geometric.nn import GCNConv\n",
    "\n",
    "class CompositeGNN(nn.Module):\n",
    "    def __init__(self, pretrained_wing, pretrained_rotor1, pretrained_rotor2, \n",
    "                 global_input_dim, edge_input_dim, hidden_dim, output_dim):\n",
    "        super(CompositeGNN, self).__init__()\n",
    "        \n",
    "        # Pre-trained models for the nodes\n",
    "        self.pretrained_wing = pretrained_wing\n",
    "        self.pretrained_rotor1 = pretrained_rotor1\n",
    "        self.pretrained_rotor2 = pretrained_rotor2\n",
    "\n",
    "        # Linear layers to ensure all node outputs match hidden_dim\n",
    "        self.wing_transform = nn.Linear(2, hidden_dim)  # Transform wing output\n",
    "        self.rotor1_transform = nn.Linear(4, hidden_dim)  # Transform rotor 1 output\n",
    "        self.rotor2_transform = nn.Linear(4, hidden_dim)  # Transform rotor 2 output\n",
    "\n",
    "        # GNN layers\n",
    "        self.conv1 = GCNConv(hidden_dim + global_input_dim, hidden_dim)\n",
    "        self.conv2 = GCNConv(hidden_dim, hidden_dim)\n",
    "\n",
    "        # Fully connected layer for output\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, node_inputs, edge_index, edge_attr, global_inputs):\n",
    "        \"\"\"\n",
    "        Forward pass of the Composite GNN.\n",
    "        \"\"\"\n",
    "        # Process node-specific inputs through pre-trained models\n",
    "        node_embeddings = []\n",
    "        node_embeddings.append(self.wing_transform(self.pretrained_wing(node_inputs[0])))  # Wing\n",
    "        node_embeddings.append(self.rotor1_transform(self.pretrained_rotor1(node_inputs[1])))  # Rotor 1\n",
    "        node_embeddings.append(self.rotor2_transform(self.pretrained_rotor2(node_inputs[2])))  # Rotor 2\n",
    "\n",
    "        # Stack node embeddings (num_nodes, hidden_dim)\n",
    "        x = torch.stack(node_embeddings, dim=0)\n",
    "\n",
    "        # Ensure global_inputs has the correct shape\n",
    "        # if global_inputs.ndim == 1:\n",
    "        #     global_inputs = global_inputs.unsqueeze(0)  # Shape: [1, global_input_dim]\n",
    "        # elif global_inputs.ndim > 2:\n",
    "        #     raise ValueError(f\"Unexpected shape for global_inputs: {global_inputs.shape}\")\n",
    "\n",
    "\n",
    "        # # Print shapes for debugging\n",
    "        # print(\"Node embeddings shape (x):\", x.shape)\n",
    "        # print(\"Global inputs shape (global_inputs):\", global_inputs.shape)\n",
    "\n",
    "        # Ensure the time steps in global_inputs match the nodes in x\n",
    "        assert global_inputs.shape[1] == x.shape[1], \"Time steps in global_inputs and node embeddings do not match!\"\n",
    "\n",
    "        # Repeat global inputs for each node\n",
    "        global_inputs_repeated = global_inputs.permute(0, 2, 1)  # Shape: [batch_size, global_input_dim, time_steps]\n",
    "\n",
    "\n",
    "        # # Repeat global inputs for each node\n",
    "        # global_inputs_repeated = global_inputs.repeat(x.shape[0], 1)  # Shape: [num_nodes, global_input_dim]\n",
    "\n",
    "        # Concatenate global inputs to each node's embeddings\n",
    "        # global_inputs_repeated = global_inputs.repeat(x.shape[0], 1)  # Broadcast global inputs\n",
    "        x = torch.cat([x, global_inputs_repeated], dim=-1)  # Concatenate along feature dimension\n",
    "\n",
    "        # Pass through GNN layers\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = torch.relu(x)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        x = torch.relu(x)\n",
    "\n",
    "        # Fully connected layer for output\n",
    "        out = self.fc(x)\n",
    "        return out\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the dataset\n",
    "dataset_aircraft = AircraftDataset(dataset_canard,\n",
    "                        dataset_rotor_L1,\n",
    "                        dataset_rotor_R1)\n",
    "\n",
    "# # Example: Create a graph for a specific sample\n",
    "# inputs, targets = dataset_aircraft[0]\n",
    "\n",
    "# print(inputs[\"time_varying_inputs\"].shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from torch.utils.data import DataLoader\n",
    "\n",
    "# dataloader = DataLoader(dataset, batch_size=4, shuffle=True)\n",
    "\n",
    "# graphs = []\n",
    "# for batch_inputs, batch_targets in dataloader:\n",
    "#     for inputs, targets in zip(batch_inputs, batch_targets):\n",
    "#         graph = create_graph(inputs, targets)\n",
    "#         graphs.append(graph)\n",
    "\n",
    "# inputs, targets = dataset[2]\n",
    "# graph = create_graph(inputs, targets)\n",
    "# visualize_graph(graph)\n",
    "# print(graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants\n",
    "EPOCHS = 50\n",
    "BATCH_SIZE = 2\n",
    "LEARNING_RATE = 1e-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_dataset = CombinedDataset(dataset_aircraft)\n",
    "dataloader = DataLoader(combined_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "pretrained_wing = wing_model_static\n",
    "pretrained_rotor1 = prop_model\n",
    "pretrained_rotor2 = prop_model\n",
    "\n",
    "# Ensure all parameters are trainable (for fine-tuning)\n",
    "for param in pretrained_wing.parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "for param in pretrained_rotor1.parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "for param in pretrained_rotor2.parameters():\n",
    "    param.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_dim = 128\n",
    "global_input_dim = dataset_aircraft.data[\"time_varying_inputs\"].shape[-1]\n",
    "edge_input_dim = dataset_aircraft.data[\"constant_inputs\"][6:].shape[-1]\n",
    "output_dim = dataset_aircraft.targets.shape[-1]\n",
    "\n",
    "composite_model = CompositeGNN(pretrained_wing, pretrained_rotor1, pretrained_rotor2,\n",
    "                                global_input_dim, edge_input_dim, hidden_dim, output_dim).to(device)\n",
    "\n",
    "# Define optimizer and loss function\n",
    "optimizer = torch.optim.Adam(composite_model.parameters(), lr=LEARNING_RATE)\n",
    "criterion = nn.MSELoss()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Sizes of tensors must match except in dimension 2. Expected size 3 but got size 2 for tensor number 1 in the list.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[188], line 26\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;66;03m# Forward pass\u001b[39;00m\n\u001b[1;32m     25\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m---> 26\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mcomposite_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnode_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_attr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mglobal_inputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;66;03m# Compute loss\u001b[39;00m\n\u001b[1;32m     29\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(outputs, targets_batch)\n",
      "File \u001b[0;32m/mnt/e/eVTOL_model/eVTOL-VehicleModel/vehicle_env/lib/python3.11/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/mnt/e/eVTOL_model/eVTOL-VehicleModel/vehicle_env/lib/python3.11/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "Cell \u001b[0;32mIn[186], line 63\u001b[0m, in \u001b[0;36mCompositeGNN.forward\u001b[0;34m(self, node_inputs, edge_index, edge_attr, global_inputs)\u001b[0m\n\u001b[1;32m     55\u001b[0m global_inputs_repeated \u001b[38;5;241m=\u001b[39m global_inputs\u001b[38;5;241m.\u001b[39mpermute(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m1\u001b[39m)  \u001b[38;5;66;03m# Shape: [batch_size, global_input_dim, time_steps]\u001b[39;00m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;66;03m# # Repeat global inputs for each node\u001b[39;00m\n\u001b[1;32m     59\u001b[0m \u001b[38;5;66;03m# global_inputs_repeated = global_inputs.repeat(x.shape[0], 1)  # Shape: [num_nodes, global_input_dim]\u001b[39;00m\n\u001b[1;32m     60\u001b[0m \n\u001b[1;32m     61\u001b[0m \u001b[38;5;66;03m# Concatenate global inputs to each node's embeddings\u001b[39;00m\n\u001b[1;32m     62\u001b[0m \u001b[38;5;66;03m# global_inputs_repeated = global_inputs.repeat(x.shape[0], 1)  # Broadcast global inputs\u001b[39;00m\n\u001b[0;32m---> 63\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mglobal_inputs_repeated\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Concatenate along feature dimension\u001b[39;00m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;66;03m# Pass through GNN layers\u001b[39;00m\n\u001b[1;32m     66\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv1(x, edge_index)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Sizes of tensors must match except in dimension 2. Expected size 3 but got size 2 for tensor number 1 in the list."
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "for epoch in range(EPOCHS):\n",
    "    composite_model.train()\n",
    "    epoch_loss = 0.0\n",
    "    \n",
    "    for batch in dataloader:\n",
    "        inputs_batch, targets_batch, graph_batch = batch\n",
    "\n",
    "        # Extract node inputs, edge index, and global inputs\n",
    "        # node_inputs = torch.tensor[inputs_batch[\"node_data\"][\"wing\"], \n",
    "        #                                 inputs_batch[\"node_data\"][\"rotor_1\"], \n",
    "        #                                 inputs_batch[\"node_data\"][\"rotor_2\"]]\n",
    "        \n",
    "        node_inputs = graph_batch.x\n",
    "        edge_index = graph_batch.edge_index\n",
    "        edge_attr = graph_batch.edge_attr\n",
    "        global_inputs = inputs_batch[\"time_varying_inputs\"]\n",
    "\n",
    "        node_inputs = node_inputs.to(device)\n",
    "        edge_index = edge_index.to(device)\n",
    "        edge_attr = edge_attr.to(device)\n",
    "        global_inputs = global_inputs.to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        optimizer.zero_grad()\n",
    "        outputs = composite_model(node_inputs, edge_index, edge_attr, global_inputs)\n",
    "\n",
    "        # Compute loss\n",
    "        loss = criterion(outputs, targets_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_loss += loss.item()\n",
    "    \n",
    "    # print(f\"Epoch {epoch+1}/{EPOCHS}, Loss: {epoch_loss/len(dataloader)}\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vehicle_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
