{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GATConv  - Parallel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import sys\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from scipy.fftpack import fft, ifft\n",
    "from scipy.interpolate import CubicSpline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if GPU is available\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append('/mnt/e/eVTOL_model/eVTOL-VehicleModel/src')\n",
    "\n",
    "\n",
    "# Import necessary functions\n",
    "from utility_functions import downsample_to_35\n",
    "from utility_functions import organize_data\n",
    "\n",
    "# Import all the models\n",
    "from af_escnn_cl import ESCNN_Cl\n",
    "from af_escnn_cd import ESCNN_Cd\n",
    "\n",
    "from af_rbf_cl import RBFLayer_cl, RBFNet_cl\n",
    "from af_rbf_cd import RBFLayer_cd, RBFNet_cd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize Airfoil Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize airfoil models\n",
    "root_airfoilModelsTrained = '/mnt/e/eVTOL_model/eVTOL-VehicleModel/trained_models/models/airfoil/'\n",
    "# root_scalers = '/mnt/e/eVTOL_model/eVTOL-VehicleModel/trained_models/scalers/'\n",
    "\n",
    "# Load the model weights\n",
    "af_model_ESCNN_Cl = ESCNN_Cl()\n",
    "af_model_ESCNN_Cl.load_state_dict(torch.load(root_airfoilModelsTrained + '2024-11-18_model_Cl_ESCNN_lr1e-05_e1500_rbf170_convL4.pth'))\n",
    "af_model_ESCNN_Cl = af_model_ESCNN_Cl.to(device)\n",
    "af_model_ESCNN_Cl.eval()\n",
    "\n",
    "# Load the model weights\n",
    "af_model_ESCNN_Cd = ESCNN_Cd()\n",
    "af_model_ESCNN_Cd.load_state_dict(torch.load(root_airfoilModelsTrained + '2024-11-18_model_Cd_ESCNN_lr5e-05_e250_convL3.pth'))\n",
    "af_model_ESCNN_Cd = af_model_ESCNN_Cd.to(device)\n",
    "af_model_ESCNN_Cd.eval()\n",
    "\n",
    "input_size = 140\n",
    "output_size = 4\n",
    "num_rbf_units = 4\n",
    "\n",
    "kmeans_center_cl = torch.load(root_airfoilModelsTrained + '2024-11-19_airfoil_model_Cl_ESCNN_RBF_lr0.06_epoch200_rbfUnits4_RBFcenters.pth')\n",
    "kmeans_center_cd = torch.load(root_airfoilModelsTrained + '2024-11-19_airfoil_model_Cd_ESCNN_RBF_lr0.025_epoch100_rbfUnits4_RBFcenters.pth')\n",
    "\n",
    "\n",
    "class airfoilModel_cl(RBFNet_cl):\n",
    "    def __init__(self):\n",
    "        super(airfoilModel_cl, self).__init__(input_size, num_rbf_units, output_size, kmeans_center_cl)\n",
    "\n",
    "\n",
    "class airfoilModel_cd(RBFNet_cd):\n",
    "    def __init__(self):\n",
    "        super(airfoilModel_cd, self).__init__(input_size, num_rbf_units, output_size, kmeans_center_cd)\n",
    "\n",
    "\n",
    "# Initialize the model\n",
    "airfoil_cl = airfoilModel_cl()\n",
    "airfoil_cl.load_state_dict(torch.load(root_airfoilModelsTrained + '2024-11-19_airfoil_model_Cl_ESCNN_RBF_lr0.06_epoch200_rbfUnits4.pth'))\n",
    "\n",
    "airfoil_cd = airfoilModel_cd()\n",
    "airfoil_cd.load_state_dict(torch.load(root_airfoilModelsTrained + '2024-11-19_airfoil_model_Cd_ESCNN_RBF_lr0.025_epoch100_rbfUnits4.pth'))\n",
    "\n",
    "airfoil_cl = airfoil_cl.to(device)\n",
    "airfoil_cd = airfoil_cd.to(device)\n",
    "\n",
    "airfoil_cl.eval()\n",
    "airfoil_cd.eval()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Wing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from create_wing_dataset import WingDataset, subdir_condition_wing   # Make sure to reload the create wing dataset module manually after changes\n",
    "\n",
    "# root_dir_wing = '/mnt/e/Course_Materials/ROM/wing_model/FLOWUnsteady_simulations/eMO_dataset_train'\n",
    "root_dir_wing = '/mnt/e/eVTOL_model/eVTOL-VehicleModel/FLOWUnsteady_simulations/aircraft_data/training_data'\n",
    "\n",
    "# Canard dataset\n",
    "dataset_canard = WingDataset(root_dir_wing, \n",
    "                                af_model_ESCNN_Cl=af_model_ESCNN_Cl, \n",
    "                                af_model_ESCNN_Cd=af_model_ESCNN_Cd,\n",
    "                                airfoil_cl=airfoil_cl, \n",
    "                                airfoil_cd=airfoil_cd, \n",
    "                                device=device,\n",
    "                                wing_name = 'Canard',     # select 'wing_main' or 'Canard'  \n",
    "                                subdir_condition=subdir_condition_wing)\n",
    "\n",
    "inputs_canard, outputs_canard = dataset_canard[0:]\n",
    "\n",
    "input_tensor_canard = inputs_canard\n",
    "input_tensor_canard = inputs_canard.squeeze(1)  # Reshaping\n",
    "print(\"Input shape (Canard dataset):\", input_tensor_canard.shape)\n",
    "\n",
    "output_tensor_canard = outputs_canard.squeeze(1)\n",
    "print(\"Output shape (Canard dataset):\",output_tensor_canard.shape) \n",
    "\n",
    "# Wing dataset\n",
    "dataset_wing = WingDataset(root_dir_wing, \n",
    "                            af_model_ESCNN_Cl=af_model_ESCNN_Cl, \n",
    "                            af_model_ESCNN_Cd=af_model_ESCNN_Cd,\n",
    "                            airfoil_cl=airfoil_cl, \n",
    "                            airfoil_cd=airfoil_cd, \n",
    "                            device=device,\n",
    "                            wing_name = 'wing_main',     # select 'wing_main' or 'Canard'  \n",
    "                            subdir_condition=subdir_condition_wing)\n",
    "\n",
    "inputs_wing, outputs_wing = dataset_wing[0:]\n",
    "\n",
    "input_tensor_wing = inputs_wing\n",
    "input_tensor_wing = inputs_wing.squeeze(1)  # Reshaping\n",
    "print(\"Input shape (Wing dataset):\", input_tensor_wing.shape)\n",
    "\n",
    "output_tensor_wing = outputs_wing.squeeze(1)\n",
    "print(\"Output shape (Wing dataset):\",output_tensor_wing.shape) \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_tensor_all_wing = torch.cat((input_tensor_canard, input_tensor_wing), dim=0)\n",
    "output_tensor_all_wing = torch.cat((output_tensor_canard, output_tensor_wing), dim=0)\n",
    "\n",
    "print(\"Input shape (All wing dataset):\", input_tensor_all_wing.shape)\n",
    "print(\"Output shape (All wing dataset):\",output_tensor_all_wing.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Wing Model and Initialize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from wing_static_attention import LSTMNetWithAttention\n",
    "\n",
    "# Static Model\n",
    "input_size_wing_stat = 10           # Number of input features\n",
    "hidden_size_wing_stat = 50          # Hidden LSTM cells\n",
    "output_size_wing_stat = 2           # Number of output features\n",
    "num_layers_wing_stat = 2            # Number of LSTM layers\n",
    "\n",
    "class WingModel_static(LSTMNetWithAttention):\n",
    "    def __init__(self):\n",
    "        super(WingModel_static, self).__init__(input_size_wing_stat, hidden_size_wing_stat, output_size_wing_stat, num_layers_wing_stat)\n",
    "\n",
    "# Initialize the model\n",
    "\n",
    "root_wingModelsTrained = '/mnt/e/eVTOL_model/eVTOL-VehicleModel/trained_models/models/wing/'\n",
    "root_wingScalersTrained = '/mnt/e/eVTOL_model/eVTOL-VehicleModel/trained_models/scalers/wing/'\n",
    "\n",
    "\n",
    "wing_model_static = WingModel_static()\n",
    "# wing_model_static.load_state_dict(torch.load(root_wingModelsTrained+'2024-11-19_LSTM_eMO_wingModel_static_lr0.002_e1200_nL3_numNN50.pth'))\n",
    "wing_model_static.load_state_dict(torch.load(root_wingModelsTrained+'2025-01-09_LSTM_eMO_wingModel_static_lr0.001_e2000_nL2_numNN50.pth'))\n",
    "wing_model_static = wing_model_static.to(device)\n",
    "# wing_model_static.eval()\n",
    "\n",
    "# Load the scaler\n",
    "# input_scaler_wing_stat = joblib.load(root_wingScalersTrained+'2024-11-19_LSTM_eMO_wingModel_static_ipScaler_lr0.002_e1200_nL3_numNN50.pkl')\n",
    "# output_scaler_wing_stat = joblib.load(root_wingScalersTrained+'2024-11-19_LSTM_eMO_wingModel_static_opScaler_lr0.002_e1200_nL3_numNN50.pkl')\n",
    "\n",
    "input_scaler_wing_stat = joblib.load(root_wingScalersTrained+'2025-01-09_LSTM_eMO_wingModel_static_ipScaler_lr0.001_e2000_nL2_numNN50.pkl')\n",
    "output_scaler_wing_stat = joblib.load(root_wingScalersTrained+'2025-01-09_LSTM_eMO_wingModel_static_opScaler_lr0.001_e2000_nL2_numNN50.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates training and validation datasets\n",
    "class SimulationDataset(Dataset):\n",
    "    def __init__(self, inputs, outputs):\n",
    "        self.inputs = inputs\n",
    "        self.outputs = outputs\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.inputs)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return torch.tensor(self.inputs[idx], dtype=torch.float32), torch.tensor(self.outputs[idx], dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape data for scaling (flatten along the time dimension)\n",
    "inputs_reshaped = input_tensor_all_wing.reshape(-1, input_size_wing_stat)\n",
    "outputs_reshaped = output_tensor_all_wing.reshape(-1, output_size_wing_stat)\n",
    "\n",
    "# Fit and transform inputs and outputs\n",
    "inputs_all_wing_normalized = input_scaler_wing_stat.transform(inputs_reshaped).reshape(input_tensor_all_wing.shape)\n",
    "outputs_all_wing_normalized = output_scaler_wing_stat.transform(outputs_reshaped).reshape(output_tensor_all_wing.shape)\n",
    "\n",
    "print(\"Normalized input shape:\", inputs_all_wing_normalized.shape)\n",
    "print(\"Normalized output shape:\", outputs_all_wing_normalized.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants\n",
    "EPOCHS = 1500\n",
    "BATCH_SIZE = 1\n",
    "LEARNING_RATE = 1e-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_percentage = 0.3   # Percentage of data to be used for testing\n",
    "\n",
    "train_dataset_num = len(input_tensor_all_wing) - int(len(input_tensor_all_wing)*val_percentage)    \n",
    "print(\"Number of datasets to be used for training:\", train_dataset_num)\n",
    "print(\"Number of datasets to be used for evaluation:\", len(input_tensor_all_wing) - train_dataset_num)\n",
    "\n",
    "# Create the normalized dataset using the custom Dataset class\n",
    "train_dataset = SimulationDataset(inputs_all_wing_normalized[:train_dataset_num], outputs_all_wing_normalized[:train_dataset_num])    # First 70% for training\n",
    "val_dataset = SimulationDataset(inputs_all_wing_normalized[train_dataset_num:], outputs_all_wing_normalized[train_dataset_num:])      # Remaining for evaluation\n",
    "\n",
    "# Create DataLoaders\n",
    "trainDataLoader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)    # Shuffle training data\n",
    "valDataLoader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Ensure all parameters are trainable (for fine-tuning)\n",
    "for param in wing_model_static.parameters():\n",
    "    param.requires_grad = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Optimizer for fine-tuning pre-trained models\n",
    "# fine_tune_params_wing = list(pretrained_wing.fc2.parameters())\n",
    "# fine_tune_params_rotor = list(pretrained_rotor1.fc.parameters()) + \\\n",
    "#                             list(pretrained_rotor2.fc.parameters())\n",
    "\n",
    "# # optimizer_fine_tune_wing = torch.optim.Adam(fine_tune_params_wing, lr=2e-3)\n",
    "# optimizer_fine_tune_rotor = torch.optim.Adam(fine_tune_params_rotor, lr=5e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.MSELoss()\n",
    "# criterion = custom_loss\n",
    "optimizer_fine_tune_wing = torch.optim.AdamW(wing_model_static.parameters(), lr=LEARNING_RATE, weight_decay=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_losses = []\n",
    "eval_losses = []\n",
    "\n",
    "print(\"[INFO] training the network...\")\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(EPOCHS):\n",
    "    wing_model_static.train()\n",
    "    running_loss = 0.0\n",
    "    \n",
    "    for inputs, targets in trainDataLoader:\n",
    "        inputs, targets = inputs.squeeze(1).to(device), targets.squeeze(1).to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = wing_model_static(inputs)\n",
    "        \n",
    "        loss = criterion(outputs, targets)\n",
    "        # Backward pass and optimization\n",
    "        optimizer_fine_tune_wing.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer_fine_tune_wing.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "\n",
    "    avg_train_loss = running_loss / len(trainDataLoader)\n",
    "    train_losses.append(avg_train_loss)\n",
    "\n",
    "\n",
    "    # Evaluation Loop\n",
    "    wing_model_static.eval()\n",
    "    eval_loss = 0.0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, targets in valDataLoader:\n",
    "            inputs, targets = inputs.squeeze(1).to(device), targets.squeeze(1).to(device)\n",
    "            \n",
    "            # Forward pass\n",
    "            outputs = wing_model_static(inputs)\n",
    "            # outputs, attention_weights = model(inputs)\n",
    "\n",
    "            loss = criterion(outputs, targets)\n",
    "            eval_loss += loss.item()\n",
    "\n",
    "        avg_eval_loss = eval_loss / len(valDataLoader)\n",
    "        eval_losses.append(avg_eval_loss)\n",
    "    \n",
    "    print(f'Epoch [{epoch+1}/{EPOCHS}],\\n Training Loss: {running_loss/len(trainDataLoader):.8f}')\n",
    "    print(f'Evaluation Loss: {eval_loss/len(valDataLoader):.8f}')\n",
    "\n",
    "\n",
    "print(\"[INFO] Finished training the network...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the training and evaluation losses\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot((train_losses), label='Training Loss')\n",
    "plt.plot((eval_losses), label='Evaluation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training and Evaluation Losses Over Epochs')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " \n",
    "from sklearn.metrics import mean_squared_error \n",
    "\n",
    "root_test_base = '/mnt/e/eVTOL_model/eVTOL-VehicleModel/FLOWUnsteady_simulations/aircraft_data/testing_data/'\n",
    "batch_size_test = 1\n",
    "\n",
    "for simulation_case in os.listdir(root_test_base):\n",
    "\n",
    "    root_test_dir = root_test_base+simulation_case\n",
    "\n",
    "    # Canard dataset\n",
    "    dataset_canard_test = WingDataset(root_test_dir, \n",
    "                                    af_model_ESCNN_Cl=af_model_ESCNN_Cl, \n",
    "                                    af_model_ESCNN_Cd=af_model_ESCNN_Cd,\n",
    "                                    airfoil_cl=airfoil_cl, \n",
    "                                    airfoil_cd=airfoil_cd, \n",
    "                                    device=device,\n",
    "                                    wing_name = 'Canard',     # select 'wing_main' or 'Canard'  \n",
    "                                    subdir_condition=subdir_condition_wing)\n",
    "\n",
    "    inputs_canard_test, outputs_canard_test = dataset_canard_test[0:]\n",
    "\n",
    "    input_tensor_canard_test = inputs_canard_test\n",
    "    input_tensor_canard_test = inputs_canard_test.squeeze(1)  # Reshaping\n",
    "    # print(\"Input shape (Canard dataset):\", input_tensor_canard.shape)\n",
    "    output_tensor_canard_test = outputs_canard_test.squeeze(1)\n",
    "    # print(\"Output shape (Canard dataset):\",output_tensor_canard.shape)\n",
    "     \n",
    "    # Wing dataset\n",
    "    dataset_wing_test = WingDataset(root_test_dir, \n",
    "                                    af_model_ESCNN_Cl=af_model_ESCNN_Cl, \n",
    "                                    af_model_ESCNN_Cd=af_model_ESCNN_Cd,\n",
    "                                    airfoil_cl=airfoil_cl, \n",
    "                                    airfoil_cd=airfoil_cd, \n",
    "                                    device=device,\n",
    "                                    wing_name = 'wing_main',     # select 'wing_main' or 'Canard'  \n",
    "                                    subdir_condition=subdir_condition_wing)\n",
    "\n",
    "    inputs_wing_test, outputs_wing_test = dataset_wing_test[0:]\n",
    "\n",
    "    input_tensor_wing_test = inputs_wing_test\n",
    "    input_tensor_wing_test = inputs_wing_test.squeeze(1)  # Reshaping\n",
    "    # print(\"Input shape (Canard dataset):\", input_tensor_canard.shape)\n",
    "    output_tensor_wing_test = outputs_wing_test.squeeze(1)\n",
    "    # print(\"Output shape (Canard dataset):\",output_tensor_canard.shape) \n",
    "\n",
    "\n",
    "    datasets = [dataset_canard_test, dataset_wing_test]\n",
    "\n",
    "    for dataset_test in datasets:\n",
    "\n",
    "        inputs_test, outputs_test = dataset_test[0:]\n",
    "        input_tensor_test = inputs_test.squeeze(1)\n",
    "        output_tensor_test = outputs_test.squeeze(1)\n",
    "\n",
    "        inputs_test_reshaped = input_tensor_test.reshape(-1, input_size_wing_stat)\n",
    "\n",
    "        test_inputs_normalized = input_scaler_wing_stat.transform(inputs_test_reshaped.reshape(-1, input_size_wing_stat)).reshape(input_tensor_test.shape)\n",
    "\n",
    "        test_inputs_tensor = torch.tensor(test_inputs_normalized, dtype=torch.float32).to(device)\n",
    "    \n",
    "\n",
    "        wing_model_static.eval()  # Set the model to evaluation mode\n",
    "\n",
    "        with torch.no_grad():\n",
    "            predicted_outputs = wing_model_static(test_inputs_tensor)\n",
    "\n",
    "        # Convert the predictions back to numpy and inverse scale the outputs\n",
    "        predicted_outputs = predicted_outputs.cpu().detach().numpy()  # Convert tensor to numpy array\n",
    "        predicted_outputs_original_scale = output_scaler_wing_stat.inverse_transform(predicted_outputs.reshape(-1, output_size_wing_stat))\n",
    "\n",
    "        # Reshape the predictions to match the original sequence structure if needed\n",
    "        predicted_outputs_original_scale = predicted_outputs_original_scale.reshape(input_tensor_test.shape[0], input_tensor_test.shape[1], output_size_wing_stat)\n",
    "        predicted_outputs_original_scale = predicted_outputs_original_scale[0]\n",
    "\n",
    "        cl_test_NN = predicted_outputs_original_scale[:,0]\n",
    "        cd_test_NN = predicted_outputs_original_scale[:,1]\n",
    "\n",
    "        # Load timesteps, CT and CQ from FLOWUnsteady simualtions\n",
    "        time_steps = dataset_test.get_variable('time')\n",
    "\n",
    "        cl_test_flowuns = dataset_test.get_variable('CL')\n",
    "        cd_test_flowuns = dataset_test.get_variable('CD')\n",
    "\n",
    "        # plt.figure()\n",
    "        plt.figure(figsize=(15, 5))\n",
    "        plt.subplot(1, 2, 1)\n",
    "        # plt.plot(time_steps[0], ct_test_NN, label = 'ct_NN')\n",
    "        # plt.plot(time_steps[0], (ct_test_flowuns[0]), label = 'ct_flowuns')\n",
    "        plt.plot(cl_test_NN, label = 'cl_NN')\n",
    "        plt.plot((cl_test_flowuns[0]), label = 'cl_flowuns')\n",
    "        plt.xlabel('Time [s]')\n",
    "        plt.ylabel('Lift coefficient, $C_T$')\n",
    "        plt.title(simulation_case)\n",
    "        plt.legend()\n",
    "\n",
    "        # plt.figure()\n",
    "        plt.subplot(1, 2, 2)\n",
    "        # plt.plot(time_steps[0], cq_test_NN, label = 'cq_NN')\n",
    "        # plt.plot(time_steps[0], cq_test_flowuns[0], label = 'cq_flowuns')\n",
    "        plt.plot(cd_test_NN, label = 'cd_NN')\n",
    "        plt.plot(cd_test_flowuns[0], label = 'cd_flowuns')\n",
    "        plt.xlabel('Time [s]')\n",
    "        plt.ylabel('Drag coefficient, $C_Q$')\n",
    "        plt.title(simulation_case)\n",
    "        plt.legend()\n",
    "    \n",
    "\n",
    "    \n",
    "\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vehicle_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
