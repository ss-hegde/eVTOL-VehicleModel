{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GATConv  - Parallel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rotor output - Ct/Cq "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import sys\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset\n",
    "from scipy.fftpack import fft, ifft\n",
    "from scipy.interpolate import CubicSpline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "# Check if GPU is available\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append('/mnt/e/eVTOL_model/eVTOL-VehicleModel/src')\n",
    "\n",
    "\n",
    "# Import necessary functions\n",
    "from utility_functions import downsample_to_35\n",
    "from utility_functions import organize_data\n",
    "\n",
    "# Import all the models\n",
    "from af_escnn_cl import ESCNN_Cl\n",
    "from af_escnn_cd import ESCNN_Cd\n",
    "\n",
    "from af_rbf_cl import RBFLayer_cl, RBFNet_cl\n",
    "from af_rbf_cd import RBFLayer_cd, RBFNet_cd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize Airfoil Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_108998/829076333.py:7: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  af_model_ESCNN_Cl.load_state_dict(torch.load(root_airfoilModelsTrained + '2024-11-18_model_Cl_ESCNN_lr1e-05_e1500_rbf170_convL4.pth'))\n",
      "/tmp/ipykernel_108998/829076333.py:13: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  af_model_ESCNN_Cd.load_state_dict(torch.load(root_airfoilModelsTrained + '2024-11-18_model_Cd_ESCNN_lr5e-05_e250_convL3.pth'))\n",
      "/tmp/ipykernel_108998/829076333.py:21: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  kmeans_center_cl = torch.load(root_airfoilModelsTrained + '2024-11-19_airfoil_model_Cl_ESCNN_RBF_lr0.06_epoch200_rbfUnits4_RBFcenters.pth')\n",
      "/tmp/ipykernel_108998/829076333.py:22: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  kmeans_center_cd = torch.load(root_airfoilModelsTrained + '2024-11-19_airfoil_model_Cd_ESCNN_RBF_lr0.025_epoch100_rbfUnits4_RBFcenters.pth')\n",
      "/tmp/ipykernel_108998/829076333.py:37: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  airfoil_cl.load_state_dict(torch.load(root_airfoilModelsTrained + '2024-11-19_airfoil_model_Cl_ESCNN_RBF_lr0.06_epoch200_rbfUnits4.pth'))\n",
      "/tmp/ipykernel_108998/829076333.py:40: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  airfoil_cd.load_state_dict(torch.load(root_airfoilModelsTrained + '2024-11-19_airfoil_model_Cd_ESCNN_RBF_lr0.025_epoch100_rbfUnits4.pth'))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "airfoilModel_cd(\n",
       "  (rbf): RBFLayer_cd()\n",
       "  (fc): Linear(in_features=4, out_features=4, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize airfoil models\n",
    "root_airfoilModelsTrained = '/mnt/e/eVTOL_model/eVTOL-VehicleModel/trained_models/models/airfoil/'\n",
    "# root_scalers = '/mnt/e/eVTOL_model/eVTOL-VehicleModel/trained_models/scalers/'\n",
    "\n",
    "# Load the model weights\n",
    "af_model_ESCNN_Cl = ESCNN_Cl()\n",
    "af_model_ESCNN_Cl.load_state_dict(torch.load(root_airfoilModelsTrained + '2024-11-18_model_Cl_ESCNN_lr1e-05_e1500_rbf170_convL4.pth'))\n",
    "af_model_ESCNN_Cl = af_model_ESCNN_Cl.to(device)\n",
    "af_model_ESCNN_Cl.eval()\n",
    "\n",
    "# Load the model weights\n",
    "af_model_ESCNN_Cd = ESCNN_Cd()\n",
    "af_model_ESCNN_Cd.load_state_dict(torch.load(root_airfoilModelsTrained + '2024-11-18_model_Cd_ESCNN_lr5e-05_e250_convL3.pth'))\n",
    "af_model_ESCNN_Cd = af_model_ESCNN_Cd.to(device)\n",
    "af_model_ESCNN_Cd.eval()\n",
    "\n",
    "input_size = 140\n",
    "output_size = 4\n",
    "num_rbf_units = 4\n",
    "\n",
    "kmeans_center_cl = torch.load(root_airfoilModelsTrained + '2024-11-19_airfoil_model_Cl_ESCNN_RBF_lr0.06_epoch200_rbfUnits4_RBFcenters.pth')\n",
    "kmeans_center_cd = torch.load(root_airfoilModelsTrained + '2024-11-19_airfoil_model_Cd_ESCNN_RBF_lr0.025_epoch100_rbfUnits4_RBFcenters.pth')\n",
    "\n",
    "\n",
    "class airfoilModel_cl(RBFNet_cl):\n",
    "    def __init__(self):\n",
    "        super(airfoilModel_cl, self).__init__(input_size, num_rbf_units, output_size, kmeans_center_cl)\n",
    "\n",
    "\n",
    "class airfoilModel_cd(RBFNet_cd):\n",
    "    def __init__(self):\n",
    "        super(airfoilModel_cd, self).__init__(input_size, num_rbf_units, output_size, kmeans_center_cd)\n",
    "\n",
    "\n",
    "# Initialize the model\n",
    "airfoil_cl = airfoilModel_cl()\n",
    "airfoil_cl.load_state_dict(torch.load(root_airfoilModelsTrained + '2024-11-19_airfoil_model_Cl_ESCNN_RBF_lr0.06_epoch200_rbfUnits4.pth'))\n",
    "\n",
    "airfoil_cd = airfoilModel_cd()\n",
    "airfoil_cd.load_state_dict(torch.load(root_airfoilModelsTrained + '2024-11-19_airfoil_model_Cd_ESCNN_RBF_lr0.025_epoch100_rbfUnits4.pth'))\n",
    "\n",
    "airfoil_cl = airfoil_cl.to(device)\n",
    "airfoil_cd = airfoil_cd.to(device)\n",
    "\n",
    "airfoil_cl.eval()\n",
    "airfoil_cd.eval()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Wing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "create_wing_dataset module loaded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/e/eVTOL_model/eVTOL-VehicleModel/src/create_wing_dataset.py:376: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:278.)\n",
      "  return torch.tensor(inputs, dtype=torch.float32), torch.tensor(targets, dtype=torch.float32)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape (Canard dataset): torch.Size([39, 277, 10])\n",
      "Output shape (Canard dataset): torch.Size([39, 277, 2])\n",
      "Input shape (Wing dataset): torch.Size([39, 277, 10])\n",
      "Output shape (Wing dataset): torch.Size([39, 277, 2])\n"
     ]
    }
   ],
   "source": [
    "from create_wing_dataset import WingDataset, subdir_condition_wing   # Make sure to reload the create wing dataset module manually after changes\n",
    "\n",
    "# root_dir_wing = '/mnt/e/Course_Materials/ROM/wing_model/FLOWUnsteady_simulations/eMO_dataset_train'\n",
    "root_dir_wing = '/mnt/e/eVTOL_model/eVTOL-VehicleModel/FLOWUnsteady_simulations/aircraft_data/training_data'\n",
    "\n",
    "# Canard dataset\n",
    "dataset_canard = WingDataset(root_dir_wing, \n",
    "                                af_model_ESCNN_Cl=af_model_ESCNN_Cl, \n",
    "                                af_model_ESCNN_Cd=af_model_ESCNN_Cd,\n",
    "                                airfoil_cl=airfoil_cl, \n",
    "                                airfoil_cd=airfoil_cd, \n",
    "                                device=device,\n",
    "                                wing_name = 'Canard',     # select 'wing_main' or 'Canard'  \n",
    "                                subdir_condition=subdir_condition_wing)\n",
    "\n",
    "inputs_canard, outputs_canard = dataset_canard[0:]\n",
    "\n",
    "input_tensor_canard = inputs_canard\n",
    "input_tensor_canard = inputs_canard.squeeze(1)  # Reshaping\n",
    "print(\"Input shape (Canard dataset):\", input_tensor_canard.shape)\n",
    "\n",
    "output_tensor_canard = outputs_canard.squeeze(1)\n",
    "print(\"Output shape (Canard dataset):\",output_tensor_canard.shape) \n",
    "\n",
    "# Wing dataset\n",
    "dataset_wing = WingDataset(root_dir_wing, \n",
    "                            af_model_ESCNN_Cl=af_model_ESCNN_Cl, \n",
    "                            af_model_ESCNN_Cd=af_model_ESCNN_Cd,\n",
    "                            airfoil_cl=airfoil_cl, \n",
    "                            airfoil_cd=airfoil_cd, \n",
    "                            device=device,\n",
    "                            wing_name = 'wing_main',     # select 'wing_main' or 'Canard'  \n",
    "                            subdir_condition=subdir_condition_wing)\n",
    "\n",
    "inputs_wing, outputs_wing = dataset_wing[0:]\n",
    "\n",
    "input_tensor_wing = inputs_wing\n",
    "input_tensor_wing = inputs_wing.squeeze(1)  # Reshaping\n",
    "print(\"Input shape (Wing dataset):\", input_tensor_wing.shape)\n",
    "\n",
    "output_tensor_wing = outputs_wing.squeeze(1)\n",
    "print(\"Output shape (Wing dataset):\",output_tensor_wing.shape) \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Rotor Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape (rotor - L1): torch.Size([39, 280, 10])\n",
      "Output shape (rotor - L1): torch.Size([39, 280, 2])\n",
      "Input shape (rotor - L2): torch.Size([39, 280, 10])\n",
      "Output shape (rotor - L2): torch.Size([39, 280, 2])\n",
      "Input shape (rotor - L3): torch.Size([39, 280, 10])\n",
      "Output shape (rotor - L3): torch.Size([39, 280, 2])\n",
      "Input shape (rotor - L4): torch.Size([39, 280, 10])\n",
      "Output shape (rotor - L4): torch.Size([39, 280, 2])\n"
     ]
    }
   ],
   "source": [
    "from create_rotor_dataset import PropellerDataset, subdir_condition_rotor\n",
    "\n",
    "# Root directory where simulation subdirectories are stored\n",
    "# root_dir_rotor = '/mnt/e/Course_Materials/ROM/rotor_solver/FLOWUnsteady_simulations/train_data'\n",
    "root_dir_rotor = '/mnt/e/eVTOL_model/eVTOL-VehicleModel/FLOWUnsteady_simulations/aircraft_data/training_data'\n",
    "\n",
    "# dataset - Rotor L1\n",
    "dataset_rotor_L1 = PropellerDataset(root_dir_rotor,\n",
    "                           rotor_notation = 'L1',                       # Select: L1, L2, L3, L4, R1, R2, R3, R4\n",
    "                           subdir_condition=subdir_condition_rotor)\n",
    "inputs_rL1, outputs_rL1 = dataset_rotor_L1[0:]\n",
    "\n",
    "\n",
    "input_tensor_rL1 = inputs_rL1.squeeze(1)  # Reshaping\n",
    "print(\"Input shape (rotor - L1):\", input_tensor_rL1.shape) \n",
    "\n",
    "output_tensor_rL1 = outputs_rL1.squeeze(1)\n",
    "print(\"Output shape (rotor - L1):\",output_tensor_rL1.shape) \n",
    "\n",
    "\n",
    "# dataset - Rotor L2\n",
    "dataset_rotor_L2 = PropellerDataset(root_dir_rotor,\n",
    "                           rotor_notation = 'L2',                       # Select: L1, L2, L3, L4, R1, R2, R3, R4\n",
    "                           subdir_condition=subdir_condition_rotor)\n",
    "inputs_rL2, outputs_rL2 = dataset_rotor_L2[0:]\n",
    "\n",
    "\n",
    "input_tensor_rL2 = inputs_rL2.squeeze(1)  # Reshaping\n",
    "print(\"Input shape (rotor - L2):\", input_tensor_rL2.shape) \n",
    "\n",
    "output_tensor_rL2 = outputs_rL2.squeeze(1)\n",
    "print(\"Output shape (rotor - L2):\",output_tensor_rL2.shape) \n",
    "\n",
    "# dataset - Rotor L3\n",
    "dataset_rotor_L3 = PropellerDataset(root_dir_rotor,\n",
    "                           rotor_notation = 'L3',                       # Select: L1, L2, L3, L4, R1, R2, R3, R4\n",
    "                           subdir_condition=subdir_condition_rotor)\n",
    "inputs_rL3, outputs_rL3 = dataset_rotor_L3[0:]\n",
    "\n",
    "\n",
    "input_tensor_rL3 = inputs_rL3.squeeze(1)  # Reshaping\n",
    "print(\"Input shape (rotor - L3):\", input_tensor_rL3.shape) \n",
    "\n",
    "output_tensor_rL3 = outputs_rL3.squeeze(1)\n",
    "print(\"Output shape (rotor - L3):\",output_tensor_rL3.shape) \n",
    "\n",
    "# dataset - Rotor L4\n",
    "dataset_rotor_L4 = PropellerDataset(root_dir_rotor,\n",
    "                           rotor_notation = 'L4',                       # Select: L1, L2, L3, L4, R1, R2, R3, R4\n",
    "                           subdir_condition=subdir_condition_rotor)\n",
    "inputs_rL4, outputs_rL4 = dataset_rotor_L4[0:]\n",
    "\n",
    "\n",
    "input_tensor_rL4 = inputs_rL4.squeeze(1)  # Reshaping\n",
    "print(\"Input shape (rotor - L4):\", input_tensor_rL4.shape) \n",
    "\n",
    "output_tensor_rL4 = outputs_rL4.squeeze(1)\n",
    "print(\"Output shape (rotor - L4):\",output_tensor_rL4.shape) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape (rotor - R1): torch.Size([39, 280, 10])\n",
      "Output shape (rotor - R1): torch.Size([39, 280, 2])\n",
      "Input shape (rotor - R2): torch.Size([39, 280, 10])\n",
      "Output shape (rotor - R2): torch.Size([39, 280, 2])\n",
      "Input shape (rotor - R3): torch.Size([39, 280, 10])\n",
      "Output shape (rotor - R3): torch.Size([39, 280, 2])\n",
      "Input shape (rotor - R4): torch.Size([39, 280, 10])\n",
      "Output shape (rotor - R4): torch.Size([39, 280, 2])\n"
     ]
    }
   ],
   "source": [
    "# dataset - Rotor R1\n",
    "dataset_rotor_R1 = PropellerDataset(root_dir_rotor,\n",
    "                           rotor_notation = 'R1',                       # Select: L1, L2, L3, L4, R1, R2, R3, R4\n",
    "                           subdir_condition=subdir_condition_rotor)\n",
    "inputs_rR1, outputs_rR1 = dataset_rotor_R1[0:]\n",
    "\n",
    "\n",
    "input_tensor_rR1 = inputs_rR1.squeeze(1)  # Reshaping\n",
    "print(\"Input shape (rotor - R1):\", input_tensor_rR1.shape) \n",
    "\n",
    "output_tensor_rR1 = outputs_rR1.squeeze(1)\n",
    "print(\"Output shape (rotor - R1):\",output_tensor_rR1.shape) \n",
    "\n",
    "\n",
    "# dataset - Rotor R2\n",
    "dataset_rotor_R2 = PropellerDataset(root_dir_rotor,\n",
    "                           rotor_notation = 'R2',                       # Select: L1, L2, L3, L4, R1, R2, R3, R4\n",
    "                           subdir_condition=subdir_condition_rotor)\n",
    "inputs_rR2, outputs_rR2 = dataset_rotor_R2[0:]\n",
    "\n",
    "\n",
    "input_tensor_rR2 = inputs_rR2.squeeze(1)  # Reshaping\n",
    "print(\"Input shape (rotor - R2):\", input_tensor_rR2.shape) \n",
    "\n",
    "output_tensor_rR2 = outputs_rR2.squeeze(1)\n",
    "print(\"Output shape (rotor - R2):\",output_tensor_rR2.shape) \n",
    "\n",
    "# dataset - Rotor R3\n",
    "dataset_rotor_R3 = PropellerDataset(root_dir_rotor,\n",
    "                           rotor_notation = 'R3',                       # Select: L1, L2, L3, L4, R1, R2, R3, R4\n",
    "                           subdir_condition=subdir_condition_rotor)\n",
    "inputs_rR3, outputs_rR3 = dataset_rotor_R3[0:]\n",
    "\n",
    "\n",
    "input_tensor_rR3 = inputs_rR3.squeeze(1)  # Reshaping\n",
    "print(\"Input shape (rotor - R3):\", input_tensor_rR3.shape) \n",
    "\n",
    "output_tensor_rR3 = outputs_rR3.squeeze(1)\n",
    "print(\"Output shape (rotor - R3):\",output_tensor_rR3.shape) \n",
    "\n",
    "# dataset - Rotor R4\n",
    "dataset_rotor_R4 = PropellerDataset(root_dir_rotor,\n",
    "                           rotor_notation = 'R4',                       # Select: L1, L2, L3, L4, R1, R2, R3, R4\n",
    "                           subdir_condition=subdir_condition_rotor)\n",
    "inputs_rR4, outputs_rR4 = dataset_rotor_R4[0:]\n",
    "\n",
    "\n",
    "input_tensor_rR4 = inputs_rR4.squeeze(1)  # Reshaping\n",
    "print(\"Input shape (rotor - R4):\", input_tensor_rR4.shape) \n",
    "\n",
    "output_tensor_rR4 = outputs_rR4.squeeze(1)\n",
    "print(\"Output shape (rotor - R4):\",output_tensor_rR4.shape) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Wing Model and Initialize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_108998/1761514772.py:19: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  wing_model_static.load_state_dict(torch.load(root_wingModelsTrained+'2024-11-19_LSTM_eMO_wingModel_static_lr0.002_e1200_nL3_numNN50.pth'))\n",
      "/mnt/e/eVTOL_model/eVTOL-VehicleModel/vehicle_env/lib/python3.11/site-packages/sklearn/base.py:380: InconsistentVersionWarning: Trying to unpickle estimator MinMaxScaler from version 1.5.2 when using version 1.6.0. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from wing_static import LSTMNet_static\n",
    "\n",
    "# Static Model\n",
    "input_size_wing_stat = 10           # Number of input features\n",
    "hidden_size_wing_stat = 50          # Hidden LSTM cells\n",
    "output_size_wing_stat = 2           # Number of output features\n",
    "num_layers_wing_stat = 3            # Number of LSTM layers\n",
    "\n",
    "class WingModel_static(LSTMNet_static):\n",
    "    def __init__(self):\n",
    "        super(WingModel_static, self).__init__(input_size_wing_stat, hidden_size_wing_stat, output_size_wing_stat, num_layers_wing_stat)\n",
    "\n",
    "# Initialize the model\n",
    "\n",
    "root_wingModelsTrained = '/mnt/e/eVTOL_model/eVTOL-VehicleModel/trained_models/models/wing/'\n",
    "root_wingScalersTrained = '/mnt/e/eVTOL_model/eVTOL-VehicleModel/trained_models/scalers/wing/'\n",
    "\n",
    "wing_model_static = WingModel_static()\n",
    "wing_model_static.load_state_dict(torch.load(root_wingModelsTrained+'2024-11-19_LSTM_eMO_wingModel_static_lr0.002_e1200_nL3_numNN50.pth'))\n",
    "wing_model_static = wing_model_static.to(device)\n",
    "wing_model_static.eval()\n",
    "\n",
    "# Load the scaler\n",
    "input_scaler_wing_stat = joblib.load(root_wingScalersTrained+'2024-11-19_LSTM_eMO_wingModel_static_ipScaler_lr0.002_e1200_nL3_numNN50.pkl')\n",
    "output_scaler_wing_stat = joblib.load(root_wingScalersTrained+'2024-11-19_LSTM_eMO_wingModel_static_opScaler_lr0.002_e1200_nL3_numNN50.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Rotor Model and Initialize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_108998/1461338884.py:19: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  prop_model.load_state_dict(torch.load(root_rotorModelsTrained+'2025-01-30_modified_H26FpropModel_lr0.001_e2500_nL4_numNN100.pth'))\n"
     ]
    }
   ],
   "source": [
    "from rotor_model import LSTMNet_rotor\n",
    "\n",
    "input_size = 10\n",
    "hidden_size = 100\n",
    "output_size = 2\n",
    "num_layers = 4\n",
    "\n",
    "class PropModel(LSTMNet_rotor):\n",
    "    def __init__(self):\n",
    "        super(PropModel, self).__init__(input_size, hidden_size, output_size, num_layers)\n",
    "\n",
    "root_rotorModelsTrained = '/mnt/e/eVTOL_model/eVTOL-VehicleModel/trained_models/models/rotor/'\n",
    "root_rotorScalersTrained = '/mnt/e/eVTOL_model/eVTOL-VehicleModel/trained_models/scalers/rotor/'\n",
    "\n",
    "# Initialize the model\n",
    "prop_model = PropModel()\n",
    "# /mnt/e/eVTOL_model/eVTOL-VehicleModel/trained_models/models/rotor/2025-01-30_modified_H26FpropModel_retrained_lr0.0002_e1500_nL4_numNN100.pth\n",
    "# prop_model.load_state_dict(torch.load(root_rotorModelsTrained+'2024-10-04_propModel_lr0.005_e1500_nL2_numNN50.pth'))\n",
    "prop_model.load_state_dict(torch.load(root_rotorModelsTrained+'2025-01-30_modified_H26FpropModel_lr0.001_e2500_nL4_numNN100.pth'))\n",
    "prop_model = prop_model.to(device)\n",
    "prop_model.eval()\n",
    "\n",
    "# Load the scaler\n",
    "# input_scaler_rotor = joblib.load(root_rotorScalersTrained+'2024-10-04_ipScaler_lr0.005_e1500_nL2_numNN50.pkl')\n",
    "# output_scaler_rotor = joblib.load(root_rotorScalersTrained+'2024-10-04_opScaler_lr0.005_e1500_nL2_numNN50.pkl')\n",
    "\n",
    "input_scaler_rotor = joblib.load(root_rotorScalersTrained+'2025-01-30_modified_H26F_ipScaler_lr0.001_e2500_nL4_numNN100.pkl')\n",
    "output_scaler_rotor = joblib.load(root_rotorScalersTrained+'2025-01-30_modified_H26F_opScaler_lr0.001_e2500_nL4_numNN100.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.interpolate import interp1d\n",
    "import numpy as np\n",
    "\n",
    "def align_timesteps(data, target_length):\n",
    "    original_length = data.shape[1]\n",
    "    x = np.linspace(0, 1, original_length)\n",
    "    x_new = np.linspace(0, 1, target_length)\n",
    "    interpolator = interp1d(x, data, axis=1, kind='linear')\n",
    "    return interpolator(x_new)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AircraftDataset(Dataset):\n",
    "    def __init__(self, wing_dataset, propeller_1_dataset, propeller_2_dataset,\n",
    "                 wing_ip_scaler, rotor_ip_scaler, wing_op_scaler, rotor_op_scaler,\n",
    "                  additional_data=None):\n",
    "        super().__init__()\n",
    "        self.wing_dataset = wing_dataset\n",
    "        self.propeller_dataset_L1 = propeller_1_dataset\n",
    "        self.propeller_dataset_R1 = propeller_2_dataset\n",
    "        self.additional_data = additional_data or {}\n",
    "        self.wing_ip_scaler = wing_ip_scaler\n",
    "        self.wing_op_scaler = wing_op_scaler\n",
    "        self.rotor_ip_scaler = rotor_ip_scaler\n",
    "        self.rotor_op_scaler = rotor_op_scaler\n",
    "\n",
    "        # Constants\n",
    "        k = 0.1301\n",
    "        self.constants = {\n",
    "            \"or1_x\": 0.36 * k,\n",
    "            \"or1_y\": 3.842 * k,\n",
    "            \"or1_z\": 0.5 * k,\n",
    "            \"oc_x\": 1.14 * k,\n",
    "            \"oc_y\": 0.0,\n",
    "            \"oc_z\": 0.35 * k,\n",
    "            \"cr1_x\": 1.14 * k - 0.36 * k,\n",
    "            \"cr1_y\": 0.0 - 3.842 * k,\n",
    "            \"cr1_z\": 0.35 * k - 0.5 * k,\n",
    "        }\n",
    "\n",
    "        # Initialize data storage\n",
    "        self.data = {\n",
    "            \"time_varying_inputs\": None,\n",
    "            \"constant_inputs\": None,\n",
    "            \"node_data\": {},  # Store node-specific time-varying data\n",
    "        }\n",
    "        self.targets = None\n",
    "\n",
    "        # Combine datasets\n",
    "        self._combine_data()\n",
    "\n",
    "    def _combine_data(self):\n",
    "        # Load wing and rotor datasets\n",
    "        inputs_wing, target_wing = self.wing_dataset[0:]\n",
    "        inputs_wing = inputs_wing.squeeze(1)\n",
    "        target_wing = target_wing.squeeze(1)\n",
    "        \n",
    "        inputs_rotor_L1, target_rotor_L1 = self.propeller_dataset_L1[0:]\n",
    "        inputs_rotor_L1 = inputs_rotor_L1.squeeze(1)\n",
    "        target_rotor_L1 = target_rotor_L1.squeeze(1)\n",
    "\n",
    "        inputs_rotor_R1, target_rotor_R1 = self.propeller_dataset_R1[0:]\n",
    "        inputs_rotor_R1 = inputs_rotor_R1.squeeze(1)\n",
    "        \n",
    "        target_rotor_R1 = target_rotor_R1.squeeze(1)\n",
    "\n",
    "        # Normalize the wing inputs\n",
    "        inputs_wing_reshaped = inputs_wing.reshape(-1, 10)\n",
    "        inputs_wing_normalized = self.wing_ip_scaler.transform(inputs_wing_reshaped.reshape(-1, 10)).reshape(inputs_wing.shape)\n",
    "        inputs_wing_normalized = torch.tensor(inputs_wing_normalized, dtype=torch.float32)\n",
    "\n",
    "        # Time-varying features\n",
    "        T = inputs_wing_normalized[:, :, 0]\n",
    "        AOA = inputs_wing_normalized[:, :, 1]\n",
    "        v_inf = inputs_wing_normalized[:, :, 2]\n",
    "\n",
    "\n",
    "        # Resize the rotor inputs\n",
    "        inputs_resized_rotor_L1 = torch.tensor(align_timesteps(inputs_rotor_L1, T.shape[1]), dtype=torch.float32)\n",
    "        inputs_resized_rotor_R1 = torch.tensor(align_timesteps(inputs_rotor_R1, T.shape[1]), dtype=torch.float32)\n",
    "        \n",
    "        # Normalize the rotor inputs\n",
    "        inputs_rotor_L1_reshaped = inputs_resized_rotor_L1.reshape(-1, 10)\n",
    "        inputs_rotor_L1_normalized = self.rotor_ip_scaler.transform(inputs_rotor_L1_reshaped.reshape(-1, 10)).reshape(inputs_resized_rotor_L1.shape)\n",
    "        inputs_rotor_L1_normalized = torch.tensor(inputs_rotor_L1_normalized, dtype=torch.float32)\n",
    "\n",
    "        inputs_rotor_R1_reshaped = inputs_resized_rotor_R1.reshape(-1, 10)\n",
    "        inputs_rotor_R1_normalized = self.rotor_ip_scaler.transform(inputs_rotor_R1_reshaped.reshape(-1, 10)).reshape(inputs_resized_rotor_R1.shape)\n",
    "        inputs_rotor_R1_normalized = torch.tensor(inputs_rotor_R1_normalized, dtype=torch.float32)\n",
    "\n",
    "        \n",
    "        # omega = torch.tensor(align_timesteps(inputs_rotor_L1[:, :, 2], T.shape[1]), dtype=torch.float64)\n",
    "        # ref_angle_L1 = torch.tensor(align_timesteps(inputs_rotor_L1[:, :, 1], T.shape[1]), dtype=torch.float32)\n",
    "        # ref_angle_R1 = torch.tensor(align_timesteps(inputs_rotor_R1[:, :, 1], T.shape[1]), dtype=torch.float32)\n",
    "        omega = inputs_rotor_L1_normalized[:, :, 1]\n",
    "        sine_component = inputs_rotor_L1_normalized[:, :, 4]\n",
    "        cos_component = inputs_rotor_L1_normalized[:, :, 5]\n",
    "        # ref_angle_L1 = inputs_rotor_L1_normalized[:, :, 1]\n",
    "        # ref_angle_R1 = inputs_rotor_R1_normalized[:, :, 1]\n",
    "\n",
    "        # Store time-varying inputs in self.data\n",
    "        self.data[\"time_varying_inputs\"] = torch.stack([T, AOA, v_inf, omega], dim=2)       # [22, 277, 6]\n",
    "        self.data[\"node_data\"][\"wing\"] = inputs_wing_normalized                    # [22, 277, 10]\n",
    "        self.data[\"node_data\"][\"rotor_1\"] = inputs_rotor_L1_normalized     # [22, 277, 10]\n",
    "        self.data[\"node_data\"][\"rotor_2\"] = inputs_rotor_R1_normalized     # [22, 277, 10]\n",
    "\n",
    "        # Store constant features\n",
    "        self.data[\"constant_inputs\"] = torch.tensor(list(self.constants.values()), dtype=torch.float32)\n",
    "\n",
    "        # Combine targets\n",
    "        target_rotor_L1 = torch.tensor(align_timesteps(target_rotor_L1, T.shape[1]), dtype=torch.float32)       # [22, 277, 4]\n",
    "        target_rotor_R1 = torch.tensor(align_timesteps(target_rotor_R1, T.shape[1]), dtype=torch.float32)       # [22, 277, 4]\n",
    "\n",
    "        target_wing_reshaped = target_wing.reshape(-1, 2)\n",
    "        target_wing_normalized = self.wing_op_scaler.transform(target_wing_reshaped.reshape(-1, 2)).reshape(target_wing.shape)\n",
    "        target_wing_normalized = torch.tensor(target_wing_normalized, dtype=torch.float32)\n",
    "\n",
    "        target_rotor_L1_reshaped = target_rotor_L1.reshape(-1, 2)\n",
    "        target_rotor_L1_normalized = self.rotor_op_scaler.transform(target_rotor_L1_reshaped.reshape(-1, 2)).reshape(target_rotor_L1.shape)\n",
    "        target_rotor_L1_normalized = torch.tensor(target_rotor_L1_normalized, dtype=torch.float32)\n",
    "\n",
    "        target_rotor_R1_reshaped = target_rotor_R1.reshape(-1, 2)\n",
    "        target_rotor_R1_normalized = self.rotor_op_scaler.transform(target_rotor_R1_reshaped.reshape(-1, 2)).reshape(target_rotor_R1.shape)\n",
    "        target_rotor_R1_normalized = torch.tensor(target_rotor_R1_normalized, dtype=torch.float32)\n",
    "\n",
    "        self.targets = torch.cat([target_rotor_L1_normalized, target_rotor_R1_normalized, target_wing_normalized], dim=2)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data[\"time_varying_inputs\"])\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        inputs = {\n",
    "            \"node_data\": {\n",
    "                \"rotor_1\": self.data[\"node_data\"][\"rotor_1\"][idx],\n",
    "                \"rotor_2\": self.data[\"node_data\"][\"rotor_2\"][idx],\n",
    "                \"wing\": self.data[\"node_data\"][\"wing\"][idx]\n",
    "            },\n",
    "            \"constant_inputs\": self.data[\"constant_inputs\"],\n",
    "            \"time_varying_inputs\": self.data[\"time_varying_inputs\"][idx]\n",
    "        }\n",
    "        targets = self.targets[idx]\n",
    "        return inputs, targets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.data import Data\n",
    "\n",
    "def create_graph(inputs, targets):\n",
    "    \"\"\"\n",
    "    Create a graph structure from dataset inputs and targets.\n",
    "\n",
    "    Args:\n",
    "        inputs (dict): Includes node data and constant inputs.\n",
    "        targets (Tensor): The target outputs.\n",
    "\n",
    "    Returns:\n",
    "        Data: PyTorch Geometric Data object representing the graph.\n",
    "    \"\"\"\n",
    "    # print(\"Inputs in create_graph:\", inputs)\n",
    "    # print(\"Node Data:\", inputs.get(\"node_data\", \"Missing 'node_data'\"))\n",
    "    # Extract node features\n",
    "    node_features = torch.stack([\n",
    "        inputs[\"node_data\"][\"wing\"],            # Node 0: Wing features\n",
    "        inputs[\"node_data\"][\"rotor_1\"],         # Node 1: Rotor 1 features\n",
    "        inputs[\"node_data\"][\"rotor_2\"]          # Node 2: Rotor 2 features\n",
    "        \n",
    "    ], dim=0)  # Shape: (num_nodes, timesteps, features)\n",
    "\n",
    "    source = [0, 1, 0, 2]\n",
    "    target = [1, 0, 2, 0]\n",
    "    \n",
    "    # Define edge index (connectivity)\n",
    "    edge_index = torch.tensor([source, target], dtype=torch.long)\n",
    "\n",
    "\n",
    "    cr1_x = inputs[\"constant_inputs\"][6]\n",
    "    cr1_y = inputs[\"constant_inputs\"][7]\n",
    "    cr1_z = inputs[\"constant_inputs\"][8]\n",
    "\n",
    "    edge_attr = torch.tensor([[cr1_x, cr1_y, cr1_z]] * len(source), dtype=torch.float32)  # Same for all edges\n",
    "\n",
    "    global_inputs = torch.stack([inputs[\"time_varying_inputs\"]])\n",
    "    global_targets = torch.stack([targets])\n",
    "\n",
    "\n",
    "    # Create graph data object\n",
    "    graph = Data(\n",
    "        x=node_features,                # Node features\n",
    "        edge_index=edge_index,          # Edge connectivity\n",
    "        edge_attr=edge_attr,            # Edge features\n",
    "        global_input = global_inputs,   # Aircraft-level inputs\n",
    "        y=global_targets                       # Targets\n",
    "    )\n",
    "    return graph\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def create_graph_batch(inputs_batch, targets_batch):\n",
    "#     graphs = []\n",
    "#     for input, target in zip(inputs_batch, targets_batch):\n",
    "#         print(\"Inputs-iter:\", type(input))\n",
    "#         print(\"Targets-iter:\", type(target))\n",
    "\n",
    "#         print(\"Inputs-provided:\", type(inputs_batch))\n",
    "#         print(\"Targets-provided:\", type(targets_batch))\n",
    "        \n",
    "#         # Ensure each input is processed correctly\n",
    "#     #     if not isinstance(inputs, dict):\n",
    "#     #         raise ValueError(f\"Expected inputs to be a dict, got {type(inputs)}\")\n",
    "#     #     graph = create_graph(inputs, targets)  # Create graph for each input/target pair\n",
    "#     #     graphs.append(graph)\n",
    "    # return graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.loader import DataLoader\n",
    "\n",
    "class GraphDataset(Dataset):\n",
    "    def __init__(self, dataset):\n",
    "        \"\"\"\n",
    "        Initialize the dataset with a list of inputs and targets.\n",
    "        \n",
    "        Args:\n",
    "            dataset (list): A list of dictionaries, each containing 'inputs' and 'targets'.\n",
    "        \"\"\"\n",
    "        self.dataset = dataset\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        inputs, targets = self.dataset[idx]\n",
    "        graph = create_graph(inputs, targets)\n",
    "        return graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "from torch_geometric.utils import to_networkx\n",
    "\n",
    "def visualize_graph(graph):\n",
    "    \"\"\"\n",
    "    Visualize a PyTorch Geometric graph using NetworkX.\n",
    "    \n",
    "    Args:\n",
    "        graph (torch_geometric.data.Data): The graph to visualize.\n",
    "    \"\"\"\n",
    "    # Convert PyTorch Geometric Data object to NetworkX graph\n",
    "    nx_graph = to_networkx(graph, edge_attrs=[\"edge_attr\"], to_undirected=True)\n",
    "\n",
    "    # Plot the graph\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    pos = nx.spring_layout(nx_graph)  # Use spring layout for positioning\n",
    "    nx.draw(\n",
    "        nx_graph,\n",
    "        pos,\n",
    "        with_labels=True,\n",
    "        node_color=\"skyblue\",\n",
    "        node_size=500,\n",
    "        edge_color=\"gray\",\n",
    "        font_weight=\"bold\"\n",
    "    )\n",
    "\n",
    "    # Annotate edge attributes\n",
    "    edge_labels = nx.get_edge_attributes(nx_graph, \"edge_attr\")\n",
    "    edge_labels = {k: tuple(round(x, 2) for x in v) for k, v in edge_labels.items()}  # Round for readability\n",
    "    nx.draw_networkx_edge_labels(nx_graph, pos, edge_labels=edge_labels, font_size=10)\n",
    "\n",
    "    plt.title(\"Graph Structure\")\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "# import torch.nn as nn\n",
    "# from torch_geometric.nn import GCNConv\n",
    "# from torch_geometric.nn import GATConv\n",
    "\n",
    "# class CompositeGNN(nn.Module):\n",
    "#     def __init__(self, pretrained_wing, pretrained_rotor1, pretrained_rotor2, \n",
    "#                  global_input_dim, edge_input_dim, hidden_dim, output_dim, heads=4, dropout=0.3):\n",
    "#         super(CompositeGNN, self).__init__()\n",
    "\n",
    "#         #\n",
    "#         self.hidden_dim = hidden_dim\n",
    "#         self.global_input_dim = global_input_dim\n",
    "#         self.output_dim = output_dim\n",
    "        \n",
    "#         # Pre-trained models for the nodes\n",
    "#         self.pretrained_wing = pretrained_wing\n",
    "#         self.pretrained_rotor1 = pretrained_rotor1\n",
    "#         self.pretrained_rotor2 = pretrained_rotor2\n",
    "\n",
    "#         # Linear layers to ensure all node outputs match hidden_dim\n",
    "#         self.wing_transform = nn.Linear(2, hidden_dim)  # Transform wing output\n",
    "#         self.rotor1_transform = nn.Linear(2, hidden_dim)  # Transform rotor 1 output\n",
    "#         self.rotor2_transform = nn.Linear(2, hidden_dim)  # Transform rotor 2 output\n",
    "#         self.global_inputs_transform = nn.Linear(global_input_dim, hidden_dim)\n",
    "\n",
    "#         # Dropout layer\n",
    "#         self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "\n",
    "#         self.gat1 = GATConv(hidden_dim + global_input_dim, hidden_dim, heads=heads, concat=True)\n",
    "#         # self.gat1 = GATConv(hidden_dim, hidden_dim, heads=heads, concat=True)\n",
    "#         self.gat2 = GATConv(hidden_dim * heads, hidden_dim, heads=2, concat=False)\n",
    "\n",
    "#         # Fully connected layer for output\n",
    "#         self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "#     def forward(self, node_inputs, targets, edge_index, edge_attr, global_inputs, batch_size, num_nodes):\n",
    "#         \"\"\"\n",
    "#         Forward pass of the Composite GNN.\n",
    "#         \"\"\"\n",
    "#         # Process node-specific inputs through pre-trained models\n",
    "#         # node_embeddings = []\n",
    "        \n",
    "#         # Create masks to extract node inputs by type\n",
    "#         # wing_indices = torch.arange(0, batch_size) * num_nodes  # Select nodes 0 and 3\n",
    "#         rotor1_indices = torch.arange(0, batch_size) * num_nodes + 1  # Select nodes 1 and 4\n",
    "#         rotor2_indices = torch.arange(0, batch_size) * num_nodes + 2  # Select nodes 2 and 5\n",
    "\n",
    "#         # node_embeddings_wing = self.wing_transform(self.pretrained_wing(node_inputs[wing_indices]))  # Wing\n",
    "#         node_embeddings_rotor1 = self.rotor1_transform(self.pretrained_rotor1(node_inputs[rotor1_indices]))  # Rotor 1\n",
    "#         node_embeddings_rotor2 = self.rotor2_transform(self.pretrained_rotor2(node_inputs[rotor2_indices]))  # Rotor 2\n",
    "\n",
    "#         node_embeddings_wing = self.wing_transform((targets[:,:,0:2]))  # Wing\n",
    "#         # node_embeddings_rotor1 = self.rotor1_transform((targets[:,:,2:6]))  # Rotor 1\n",
    "#         # node_embeddings_rotor2 = self.rotor2_transform((targets[:,:,6:10]))  # Rotor 2\n",
    "\n",
    "#         # print(\"Node Embeddings Wing:\", node_embeddings_wing.shape)\n",
    "\n",
    "#         # # Apply dropout\n",
    "#         # node_embeddings_wing = self.dropout(node_embeddings_wing)\n",
    "#         # node_embeddings_rotor1 = self.dropout(node_embeddings_rotor1)\n",
    "#         # node_embeddings_rotor2 = self.dropout(node_embeddings_rotor2)\n",
    "\n",
    "        \n",
    "#         x_cat = torch.cat([node_embeddings_wing, node_embeddings_rotor1, node_embeddings_rotor2], dim=0)\n",
    "\n",
    "#         global_inputs_expanded = torch.cat([global_inputs, global_inputs, global_inputs], dim=0)\n",
    "\n",
    "#         # Concatenate global inputs to each node's embeddings\n",
    "#         x = torch.cat([x_cat, global_inputs_expanded], dim=-1)  # Concatenate along feature dimension\n",
    "#         # x = x_cat.reshape(-1, self.hidden_dim)\n",
    "#         x = x.reshape(-1, self.hidden_dim+self.global_input_dim)\n",
    "\n",
    "#         # Ensure x and edge_index have the correct dtypes\n",
    "#         x = x.float()  # Convert x to torch.float32\n",
    "#         edge_index = edge_index.long()  # Ensure edge_index is torch.long\n",
    "\n",
    "\n",
    "#         x = self.gat1(x, edge_index)\n",
    "#         x = torch.relu((x))\n",
    "#         x = self.gat2(x, edge_index)\n",
    "#         x = torch.relu((x))\n",
    "\n",
    "#         # Fully connected layer for output\n",
    "#         out = self.fc(x)\n",
    "\n",
    "        \n",
    "\n",
    "#         out = out.reshape(batch_size*num_nodes, -1, self.output_dim)\n",
    "#         print(\"Output Shape:\", out.shape)\n",
    "#         # reshaped_outputs = out.view(batch_size, num_nodes, 277, self.output_dim)\n",
    "\n",
    "#         graph_outputs = out\n",
    "#         # graph_outputs = reshaped_outputs.mean(dim=1)\n",
    "\n",
    "#         return graph_outputs\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GATConv\n",
    "\n",
    "class CompositeGNN(nn.Module):\n",
    "    def __init__(self, pretrained_wing, pretrained_rotor1, pretrained_rotor2, \n",
    "                 global_input_dim, edge_input_dim, hidden_dim, output_dim, heads=4, dropout=0.3):\n",
    "        super(CompositeGNN, self).__init__()\n",
    "\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.global_input_dim = global_input_dim\n",
    "        self.output_dim = output_dim\n",
    "\n",
    "        # Pre-trained models for the nodes\n",
    "        self.pretrained_wing = pretrained_wing\n",
    "        self.pretrained_rotor1 = pretrained_rotor1\n",
    "        self.pretrained_rotor2 = pretrained_rotor2\n",
    "\n",
    "        # Transforming pre-trained model outputs to match hidden_dim\n",
    "        self.wing_transform = nn.Linear(2, hidden_dim)\n",
    "        self.rotor1_transform = nn.Linear(2, hidden_dim)\n",
    "        self.rotor2_transform = nn.Linear(2, hidden_dim)\n",
    "\n",
    "        # Transforming global inputs to match hidden_dim\n",
    "        self.global_inputs_transform = nn.Linear(global_input_dim, hidden_dim)\n",
    "\n",
    "        # Dropout layer for regularization\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "        # Graph Attention Layers (with edge features)\n",
    "        self.gat1 = GATConv(hidden_dim + global_input_dim, hidden_dim, heads=heads, concat=True, edge_dim=edge_input_dim)\n",
    "        self.gat2 = GATConv(hidden_dim * heads, hidden_dim, heads=2, concat=False, edge_dim=edge_input_dim)\n",
    "\n",
    "        # Normalization for stable training\n",
    "        self.norm1 = nn.LayerNorm(hidden_dim * heads)\n",
    "        self.norm2 = nn.LayerNorm(hidden_dim)\n",
    "\n",
    "        # Fully connected output layer\n",
    "        self.fc = nn.Linear(hidden_dim, 2)\n",
    "\n",
    "    def forward(self, node_inputs, targets, edge_index, edge_attr, global_inputs, batch_size, num_nodes):\n",
    "        \"\"\"\n",
    "        Forward pass of the Composite GNN.\n",
    "        \"\"\"\n",
    "        # Compute batch indices for node types\n",
    "        batch_indices = torch.arange(batch_size).to(node_inputs.device) * num_nodes\n",
    "        wing_indices = batch_indices  # Wing at index 0 in each batch\n",
    "        rotor1_indices = batch_indices + 1  # Rotor 1 at index 1 in each batch\n",
    "        rotor2_indices = batch_indices + 2  # Rotor 2 at index 2 in each batch\n",
    "\n",
    "        # Process node-specific inputs through pre-trained models\n",
    "        node_embeddings_wing = ((targets[:,:,0:2]))  # Wing\n",
    "        # node_embeddings_wing = self.pretrained_wing(node_inputs[wing_indices])  # Shape: [2, 277, 2]\n",
    "        node_embeddings_rotor1 = self.pretrained_rotor1(node_inputs[rotor1_indices])  # Shape: [2, 277, 2]\n",
    "        node_embeddings_rotor2 = self.pretrained_rotor2(node_inputs[rotor2_indices])  # Shape: [2, 277, 2]\n",
    "\n",
    "        # Transform to hidden_dim\n",
    "        node_embeddings_wing = self.wing_transform(node_embeddings_wing)  # Shape: [2, 277, hidden_dim]\n",
    "        node_embeddings_rotor1 = self.rotor1_transform(node_embeddings_rotor1)  # Shape: [2, 277, hidden_dim]\n",
    "        node_embeddings_rotor2 = self.rotor2_transform(node_embeddings_rotor2)  # Shape: [2, 277, hidden_dim]\n",
    "\n",
    "        # Concatenate across the batch dimension\n",
    "        x = torch.cat([node_embeddings_rotor1, node_embeddings_rotor2, node_embeddings_wing], dim=0)\n",
    "        # print(\"X Shape:\", x.shape)  \n",
    "        # Shape: [6, 277, hidden_dim] (merged across all nodes)\n",
    "\n",
    "        # Expand global inputs correctly\n",
    "        global_inputs_expanded = global_inputs.repeat_interleave(num_nodes, dim=0)  # Shape: [6, 277, global_input_dim]\n",
    "        # print(\"Global Inputs Expanded Shape:\", global_inputs_expanded.shape)\n",
    "\n",
    "        # Concatenate global inputs\n",
    "        x = torch.cat([x, global_inputs_expanded], dim=-1)  # Shape: [6, 277, hidden_dim + global_input_dim]\n",
    "        x = x.reshape(-1, self.hidden_dim+self.global_input_dim)\n",
    "        # print(\"X Shape:\", x.shape)\n",
    "\n",
    "        # Convert tensor types\n",
    "        x = x.float()  # Ensure float precision\n",
    "        edge_index = edge_index.long()  # Ensure edge_index is of type long\n",
    "\n",
    "        # Apply GAT layers with edge attributes\n",
    "        x = self.gat1(x, edge_index, edge_attr)\n",
    "        x = self.norm1(F.relu(x))  # Normalization for stable gradients\n",
    "\n",
    "        x = self.gat2(x, edge_index, edge_attr)\n",
    "        x = self.norm2(F.relu(x))\n",
    "\n",
    "        # Fully connected layer for final predictions\n",
    "        out = self.fc(x)  # Shape: [6, 277, 2]\n",
    "\n",
    "        # Reshape back to match expected shape: [batch_size, timesteps, total_output_dim]\n",
    "        out = out.view(batch_size, num_nodes, 277, -1)  # Shape: [2, 3, 277, 2]\n",
    "        # print(\"Output Shape:\", out.shape)\n",
    "\n",
    "        # Merge node outputs across feature dimension\n",
    "        out = out.permute(0, 2, 1, 3).reshape(batch_size, 277, -1)  # Shape: [2, 277, 6]\n",
    "\n",
    "        return out  # Final shape [2, 277, 6]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the dataset\n",
    "dataset_aircraft = AircraftDataset(dataset_canard,\n",
    "                        dataset_rotor_L1,\n",
    "                        dataset_rotor_R1,\n",
    "                        input_scaler_wing_stat,\n",
    "                        input_scaler_rotor,\n",
    "                        output_scaler_wing_stat,\n",
    "                        output_scaler_rotor)\n",
    "\n",
    "# # Example: Create a graph for a specific sample\n",
    "# inputs, targets = dataset_aircraft[0]\n",
    "\n",
    "# print(inputs[\"time_varying_inputs\"].shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from torch.utils.data import DataLoader\n",
    "\n",
    "# dataloader = DataLoader(dataset, batch_size=4, shuffle=True)\n",
    "\n",
    "# graphs = []\n",
    "# for batch_inputs, batch_targets in dataloader:\n",
    "#     for inputs, targets in zip(batch_inputs, batch_targets):\n",
    "#         graph = create_graph(inputs, targets)\n",
    "#         graphs.append(graph)\n",
    "\n",
    "# inputs, targets = dataset[2]\n",
    "# graph = create_graph(inputs, targets)\n",
    "# visualize_graph(graph)\n",
    "# print(graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants\n",
    "EPOCHS = 2500\n",
    "BATCH_SIZE = 1\n",
    "LEARNING_RATE = 1e-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_dataset = GraphDataset(dataset_aircraft)\n",
    "\n",
    "\n",
    "pretrained_wing = wing_model_static\n",
    "pretrained_rotor1 = prop_model\n",
    "pretrained_rotor2 = prop_model\n",
    "\n",
    "# Ensure all parameters are trainable (for fine-tuning)\n",
    "for param in pretrained_wing.parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "for param in pretrained_rotor1.parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "for param in pretrained_rotor2.parameters():\n",
    "    param.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Optimizer for fine-tuning pre-trained models\n",
    "# fine_tune_params_wing = list(pretrained_wing.fc2.parameters())\n",
    "# fine_tune_params_rotor = list(pretrained_rotor1.fc.parameters()) + \\\n",
    "#                             list(pretrained_rotor2.fc.parameters())\n",
    "\n",
    "# # optimizer_fine_tune_wing = torch.optim.Adam(fine_tune_params_wing, lr=2e-3)\n",
    "# optimizer_fine_tune_rotor = torch.optim.Adam(fine_tune_params_rotor, lr=5e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Dataset Size: 27\n",
      "Validation Dataset Size: 12\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import random_split\n",
    "# Define the split ratio\n",
    "train_ratio = 0.7\n",
    "val_ratio = 1-train_ratio\n",
    "\n",
    "# Calculate split sizes\n",
    "dataset_size = len(graph_dataset)\n",
    "train_size = int(train_ratio * dataset_size)\n",
    "val_size = dataset_size - train_size\n",
    "\n",
    "# Perform the split\n",
    "train_dataset_aircraft, val_dataset_aircraft = random_split(graph_dataset, [train_size, val_size])\n",
    "\n",
    "print(\"Train Dataset Size:\", len(train_dataset_aircraft))\n",
    "print(\"Validation Dataset Size:\", len(val_dataset_aircraft))\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset_aircraft, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_dataloader = DataLoader(val_dataset_aircraft, batch_size=BATCH_SIZE, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_loss(pred, target):\n",
    "    return torch.mean((pred - target) ** 2) + 0.8 * torch.mean(torch.abs(pred - target))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_dim = 100\n",
    "global_input_dim = dataset_aircraft.data[\"time_varying_inputs\"].shape[-1]\n",
    "edge_input_dim = dataset_aircraft.data[\"constant_inputs\"][6:].shape[-1]\n",
    "output_dim = dataset_aircraft.targets.shape[-1]\n",
    "\n",
    "composite_model = CompositeGNN(pretrained_wing, pretrained_rotor1, pretrained_rotor2,\n",
    "                                global_input_dim, edge_input_dim, hidden_dim, output_dim).to(device)\n",
    "\n",
    "# Define optimizer and loss function\n",
    "optimizer_composite = torch.optim.Adam(composite_model.parameters(), lr=LEARNING_RATE)\n",
    "# criterion = nn.MSELoss()\n",
    "criterion = custom_loss\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] training the network...\n",
      "Epoch [1/2500],\n",
      " Training Loss: 0.64642697\n",
      "Evaluation Loss: 0.31500615\n",
      "Epoch [2/2500],\n",
      " Training Loss: 0.45526281\n",
      "Evaluation Loss: 0.37779415\n",
      "Epoch [3/2500],\n",
      " Training Loss: 0.40697421\n",
      "Evaluation Loss: 0.29963019\n",
      "Epoch [4/2500],\n",
      " Training Loss: 0.39410716\n",
      "Evaluation Loss: 0.25851795\n",
      "Epoch [5/2500],\n",
      " Training Loss: 0.35889627\n",
      "Evaluation Loss: 0.24027994\n",
      "Epoch [6/2500],\n",
      " Training Loss: 0.37828199\n",
      "Evaluation Loss: 0.29810924\n",
      "Epoch [7/2500],\n",
      " Training Loss: 0.35342900\n",
      "Evaluation Loss: 0.25409303\n",
      "Epoch [8/2500],\n",
      " Training Loss: 0.39827783\n",
      "Evaluation Loss: 0.26784315\n",
      "Epoch [9/2500],\n",
      " Training Loss: 0.41316569\n",
      "Evaluation Loss: 0.27870564\n",
      "Epoch [10/2500],\n",
      " Training Loss: 0.36425991\n",
      "Evaluation Loss: 0.26517275\n",
      "Epoch [11/2500],\n",
      " Training Loss: 0.35590504\n",
      "Evaluation Loss: 0.24159358\n",
      "Epoch [12/2500],\n",
      " Training Loss: 0.32433080\n",
      "Evaluation Loss: 0.24513075\n",
      "Epoch [13/2500],\n",
      " Training Loss: 0.32088888\n",
      "Evaluation Loss: 0.24041145\n",
      "Epoch [14/2500],\n",
      " Training Loss: 0.34892072\n",
      "Evaluation Loss: 0.23695415\n",
      "Epoch [15/2500],\n",
      " Training Loss: 0.29992312\n",
      "Evaluation Loss: 0.20017865\n",
      "Epoch [16/2500],\n",
      " Training Loss: 0.31511121\n",
      "Evaluation Loss: 0.21542716\n",
      "Epoch [17/2500],\n",
      " Training Loss: 0.31456787\n",
      "Evaluation Loss: 0.28123331\n",
      "Epoch [18/2500],\n",
      " Training Loss: 0.34720956\n",
      "Evaluation Loss: 0.27468675\n",
      "Epoch [19/2500],\n",
      " Training Loss: 0.33086134\n",
      "Evaluation Loss: 0.28315046\n",
      "Epoch [20/2500],\n",
      " Training Loss: 0.30763589\n",
      "Evaluation Loss: 0.29419199\n",
      "Epoch [21/2500],\n",
      " Training Loss: 0.30469306\n",
      "Evaluation Loss: 0.25799673\n",
      "Epoch [22/2500],\n",
      " Training Loss: 0.28994881\n",
      "Evaluation Loss: 0.22884545\n",
      "Epoch [23/2500],\n",
      " Training Loss: 0.33420112\n",
      "Evaluation Loss: 0.27315257\n",
      "Epoch [24/2500],\n",
      " Training Loss: 0.27830378\n",
      "Evaluation Loss: 0.26679865\n",
      "Epoch [25/2500],\n",
      " Training Loss: 0.33573337\n",
      "Evaluation Loss: 0.31023435\n",
      "Epoch [26/2500],\n",
      " Training Loss: 0.33748793\n",
      "Evaluation Loss: 0.30104648\n",
      "Epoch [27/2500],\n",
      " Training Loss: 0.28739993\n",
      "Evaluation Loss: 0.21781732\n",
      "Epoch [28/2500],\n",
      " Training Loss: 0.30293705\n",
      "Evaluation Loss: 0.22848818\n",
      "Epoch [29/2500],\n",
      " Training Loss: 0.30975087\n",
      "Evaluation Loss: 0.20917997\n",
      "Epoch [30/2500],\n",
      " Training Loss: 0.29373804\n",
      "Evaluation Loss: 0.23633806\n",
      "Epoch [31/2500],\n",
      " Training Loss: 0.29542239\n",
      "Evaluation Loss: 0.23309206\n",
      "Epoch [32/2500],\n",
      " Training Loss: 0.27188617\n",
      "Evaluation Loss: 0.21179873\n",
      "Epoch [33/2500],\n",
      " Training Loss: 0.30691501\n",
      "Evaluation Loss: 0.22132674\n",
      "Epoch [34/2500],\n",
      " Training Loss: 0.29386287\n",
      "Evaluation Loss: 0.20546965\n",
      "Epoch [35/2500],\n",
      " Training Loss: 0.26135989\n",
      "Evaluation Loss: 0.20966023\n",
      "Epoch [36/2500],\n",
      " Training Loss: 0.26060604\n",
      "Evaluation Loss: 0.21433914\n",
      "Epoch [37/2500],\n",
      " Training Loss: 0.25946166\n",
      "Evaluation Loss: 0.26150665\n",
      "Epoch [38/2500],\n",
      " Training Loss: 0.28808671\n",
      "Evaluation Loss: 0.23600253\n",
      "Epoch [39/2500],\n",
      " Training Loss: 0.26953664\n",
      "Evaluation Loss: 0.23747151\n",
      "Epoch [40/2500],\n",
      " Training Loss: 0.25230360\n",
      "Evaluation Loss: 0.21339065\n",
      "Epoch [41/2500],\n",
      " Training Loss: 0.25810809\n",
      "Evaluation Loss: 0.26536635\n",
      "Epoch [42/2500],\n",
      " Training Loss: 0.32154009\n",
      "Evaluation Loss: 0.21295187\n",
      "Epoch [43/2500],\n",
      " Training Loss: 0.27132386\n",
      "Evaluation Loss: 0.24975721\n",
      "Epoch [44/2500],\n",
      " Training Loss: 0.26382019\n",
      "Evaluation Loss: 0.23544154\n",
      "Epoch [45/2500],\n",
      " Training Loss: 0.25574086\n",
      "Evaluation Loss: 0.23096303\n",
      "Epoch [46/2500],\n",
      " Training Loss: 0.29106232\n",
      "Evaluation Loss: 0.21299208\n",
      "Epoch [47/2500],\n",
      " Training Loss: 0.25745307\n",
      "Evaluation Loss: 0.22872506\n",
      "Epoch [48/2500],\n",
      " Training Loss: 0.30369898\n",
      "Evaluation Loss: 0.23060799\n",
      "Epoch [49/2500],\n",
      " Training Loss: 0.29225656\n",
      "Evaluation Loss: 0.19949744\n",
      "Epoch [50/2500],\n",
      " Training Loss: 0.26079670\n",
      "Evaluation Loss: 0.25202156\n",
      "Epoch [51/2500],\n",
      " Training Loss: 0.32558978\n",
      "Evaluation Loss: 0.21941541\n",
      "Epoch [52/2500],\n",
      " Training Loss: 0.27431367\n",
      "Evaluation Loss: 0.23629135\n",
      "Epoch [53/2500],\n",
      " Training Loss: 0.25566789\n",
      "Evaluation Loss: 0.21094676\n",
      "Epoch [54/2500],\n",
      " Training Loss: 0.24534408\n",
      "Evaluation Loss: 0.23022501\n",
      "Epoch [55/2500],\n",
      " Training Loss: 0.25734236\n",
      "Evaluation Loss: 0.23031687\n",
      "Epoch [56/2500],\n",
      " Training Loss: 0.27561886\n",
      "Evaluation Loss: 0.21666737\n",
      "Epoch [57/2500],\n",
      " Training Loss: 0.30642531\n",
      "Evaluation Loss: 0.21165518\n",
      "Epoch [58/2500],\n",
      " Training Loss: 0.26150400\n",
      "Evaluation Loss: 0.20513453\n",
      "Epoch [59/2500],\n",
      " Training Loss: 0.25224233\n",
      "Evaluation Loss: 0.22888258\n",
      "Epoch [60/2500],\n",
      " Training Loss: 0.24259033\n",
      "Evaluation Loss: 0.22798266\n",
      "Epoch [61/2500],\n",
      " Training Loss: 0.25181176\n",
      "Evaluation Loss: 0.27649174\n",
      "Epoch [62/2500],\n",
      " Training Loss: 0.28033841\n",
      "Evaluation Loss: 0.21572673\n",
      "Epoch [63/2500],\n",
      " Training Loss: 0.29745006\n",
      "Evaluation Loss: 0.22200046\n",
      "Epoch [64/2500],\n",
      " Training Loss: 0.31016833\n",
      "Evaluation Loss: 0.25036372\n",
      "Epoch [65/2500],\n",
      " Training Loss: 0.29247239\n",
      "Evaluation Loss: 0.20787844\n",
      "Epoch [66/2500],\n",
      " Training Loss: 0.24633280\n",
      "Evaluation Loss: 0.20884502\n",
      "Epoch [67/2500],\n",
      " Training Loss: 0.25000250\n",
      "Evaluation Loss: 0.26794197\n",
      "Epoch [68/2500],\n",
      " Training Loss: 0.26708270\n",
      "Evaluation Loss: 0.22234993\n",
      "Epoch [69/2500],\n",
      " Training Loss: 0.25225894\n",
      "Evaluation Loss: 0.21006700\n",
      "Epoch [70/2500],\n",
      " Training Loss: 0.24104503\n",
      "Evaluation Loss: 0.20543909\n",
      "Epoch [71/2500],\n",
      " Training Loss: 0.23225731\n",
      "Evaluation Loss: 0.21949999\n",
      "Epoch [72/2500],\n",
      " Training Loss: 0.24724163\n",
      "Evaluation Loss: 0.22014794\n",
      "Epoch [73/2500],\n",
      " Training Loss: 0.24612364\n",
      "Evaluation Loss: 0.22012664\n",
      "Epoch [74/2500],\n",
      " Training Loss: 0.23878792\n",
      "Evaluation Loss: 0.21178426\n",
      "Epoch [75/2500],\n",
      " Training Loss: 0.27510489\n",
      "Evaluation Loss: 0.21354242\n",
      "Epoch [76/2500],\n",
      " Training Loss: 0.25264390\n",
      "Evaluation Loss: 0.22412413\n",
      "Epoch [77/2500],\n",
      " Training Loss: 0.24522336\n",
      "Evaluation Loss: 0.22660582\n",
      "Epoch [78/2500],\n",
      " Training Loss: 0.25896150\n",
      "Evaluation Loss: 0.24994343\n",
      "Epoch [79/2500],\n",
      " Training Loss: 0.25429636\n",
      "Evaluation Loss: 0.20632494\n",
      "Epoch [80/2500],\n",
      " Training Loss: 0.23891778\n",
      "Evaluation Loss: 0.21956617\n",
      "Epoch [81/2500],\n",
      " Training Loss: 0.24188589\n",
      "Evaluation Loss: 0.23213677\n",
      "Epoch [82/2500],\n",
      " Training Loss: 0.24415168\n",
      "Evaluation Loss: 0.22318480\n",
      "Epoch [83/2500],\n",
      " Training Loss: 0.24331810\n",
      "Evaluation Loss: 0.22970212\n",
      "Epoch [84/2500],\n",
      " Training Loss: 0.23870813\n",
      "Evaluation Loss: 0.22826267\n",
      "Epoch [85/2500],\n",
      " Training Loss: 0.21913729\n",
      "Evaluation Loss: 0.23395421\n",
      "Epoch [86/2500],\n",
      " Training Loss: 0.25193504\n",
      "Evaluation Loss: 0.22756533\n",
      "Epoch [87/2500],\n",
      " Training Loss: 0.22816413\n",
      "Evaluation Loss: 0.21975415\n",
      "Epoch [88/2500],\n",
      " Training Loss: 0.24628829\n",
      "Evaluation Loss: 0.23718597\n",
      "Epoch [89/2500],\n",
      " Training Loss: 0.25564436\n",
      "Evaluation Loss: 0.22899698\n",
      "Epoch [90/2500],\n",
      " Training Loss: 0.25000917\n",
      "Evaluation Loss: 0.23883585\n",
      "Epoch [91/2500],\n",
      " Training Loss: 0.23229984\n",
      "Evaluation Loss: 0.22207445\n",
      "Epoch [92/2500],\n",
      " Training Loss: 0.22204768\n",
      "Evaluation Loss: 0.23277939\n",
      "Epoch [93/2500],\n",
      " Training Loss: 0.28323618\n",
      "Evaluation Loss: 0.23971503\n",
      "Epoch [94/2500],\n",
      " Training Loss: 0.31202315\n",
      "Evaluation Loss: 0.22582458\n",
      "Epoch [95/2500],\n",
      " Training Loss: 0.25433821\n",
      "Evaluation Loss: 0.21284945\n",
      "Epoch [96/2500],\n",
      " Training Loss: 0.23197921\n",
      "Evaluation Loss: 0.22530345\n",
      "Epoch [97/2500],\n",
      " Training Loss: 0.22709549\n",
      "Evaluation Loss: 0.23157251\n",
      "Epoch [98/2500],\n",
      " Training Loss: 0.24192078\n",
      "Evaluation Loss: 0.23431061\n",
      "Epoch [99/2500],\n",
      " Training Loss: 0.26742253\n",
      "Evaluation Loss: 0.23408407\n",
      "Epoch [100/2500],\n",
      " Training Loss: 0.23594310\n",
      "Evaluation Loss: 0.21825058\n",
      "Epoch [101/2500],\n",
      " Training Loss: 0.24100907\n",
      "Evaluation Loss: 0.23679568\n",
      "Epoch [102/2500],\n",
      " Training Loss: 0.23081986\n",
      "Evaluation Loss: 0.24210655\n",
      "Epoch [103/2500],\n",
      " Training Loss: 0.25009135\n",
      "Evaluation Loss: 0.21865422\n",
      "Epoch [104/2500],\n",
      " Training Loss: 0.23523956\n",
      "Evaluation Loss: 0.23015552\n",
      "Epoch [105/2500],\n",
      " Training Loss: 0.23593903\n",
      "Evaluation Loss: 0.22018475\n",
      "Epoch [106/2500],\n",
      " Training Loss: 0.24583274\n",
      "Evaluation Loss: 0.22116047\n",
      "Epoch [107/2500],\n",
      " Training Loss: 0.22951168\n",
      "Evaluation Loss: 0.22517958\n",
      "Epoch [108/2500],\n",
      " Training Loss: 0.24368823\n",
      "Evaluation Loss: 0.22318158\n",
      "Epoch [109/2500],\n",
      " Training Loss: 0.22570973\n",
      "Evaluation Loss: 0.22814177\n",
      "Epoch [110/2500],\n",
      " Training Loss: 0.23993304\n",
      "Evaluation Loss: 0.22296732\n",
      "Epoch [111/2500],\n",
      " Training Loss: 0.26755763\n",
      "Evaluation Loss: 0.23112412\n",
      "Epoch [112/2500],\n",
      " Training Loss: 0.25442466\n",
      "Evaluation Loss: 0.20810570\n",
      "Epoch [113/2500],\n",
      " Training Loss: 0.23073266\n",
      "Evaluation Loss: 0.23268260\n",
      "Epoch [114/2500],\n",
      " Training Loss: 0.24259220\n",
      "Evaluation Loss: 0.21245609\n",
      "Epoch [115/2500],\n",
      " Training Loss: 0.23466206\n",
      "Evaluation Loss: 0.23515675\n",
      "Epoch [116/2500],\n",
      " Training Loss: 0.21725158\n",
      "Evaluation Loss: 0.21698039\n",
      "Epoch [117/2500],\n",
      " Training Loss: 0.24735798\n",
      "Evaluation Loss: 0.21860384\n",
      "Epoch [118/2500],\n",
      " Training Loss: 0.23213046\n",
      "Evaluation Loss: 0.22764677\n",
      "Epoch [119/2500],\n",
      " Training Loss: 0.26307808\n",
      "Evaluation Loss: 0.20900835\n",
      "Epoch [120/2500],\n",
      " Training Loss: 0.26743634\n",
      "Evaluation Loss: 0.22404858\n",
      "Epoch [121/2500],\n",
      " Training Loss: 0.23150147\n",
      "Evaluation Loss: 0.20490494\n",
      "Epoch [122/2500],\n",
      " Training Loss: 0.22802196\n",
      "Evaluation Loss: 0.21691727\n",
      "Epoch [123/2500],\n",
      " Training Loss: 0.22247211\n",
      "Evaluation Loss: 0.22783879\n",
      "Epoch [124/2500],\n",
      " Training Loss: 0.21203965\n",
      "Evaluation Loss: 0.22480227\n",
      "Epoch [125/2500],\n",
      " Training Loss: 0.25467447\n",
      "Evaluation Loss: 0.20711359\n",
      "Epoch [126/2500],\n",
      " Training Loss: 0.24953911\n",
      "Evaluation Loss: 0.21447157\n",
      "Epoch [127/2500],\n",
      " Training Loss: 0.23244493\n",
      "Evaluation Loss: 0.21397307\n",
      "Epoch [128/2500],\n",
      " Training Loss: 0.21817424\n",
      "Evaluation Loss: 0.20539992\n",
      "Epoch [129/2500],\n",
      " Training Loss: 0.21963329\n",
      "Evaluation Loss: 0.21704062\n",
      "Epoch [130/2500],\n",
      " Training Loss: 0.22089326\n",
      "Evaluation Loss: 0.21505196\n",
      "Epoch [131/2500],\n",
      " Training Loss: 0.22246528\n",
      "Evaluation Loss: 0.23015671\n",
      "Epoch [132/2500],\n",
      " Training Loss: 0.22349609\n",
      "Evaluation Loss: 0.21376466\n",
      "Epoch [133/2500],\n",
      " Training Loss: 0.22730380\n",
      "Evaluation Loss: 0.21625895\n",
      "Epoch [134/2500],\n",
      " Training Loss: 0.23681006\n",
      "Evaluation Loss: 0.19972788\n",
      "Epoch [135/2500],\n",
      " Training Loss: 0.25322795\n",
      "Evaluation Loss: 0.21006628\n",
      "Epoch [136/2500],\n",
      " Training Loss: 0.22913589\n",
      "Evaluation Loss: 0.20225013\n",
      "Epoch [137/2500],\n",
      " Training Loss: 0.21429651\n",
      "Evaluation Loss: 0.21514222\n",
      "Epoch [138/2500],\n",
      " Training Loss: 0.22954744\n",
      "Evaluation Loss: 0.20550101\n",
      "Epoch [139/2500],\n",
      " Training Loss: 0.22565458\n",
      "Evaluation Loss: 0.20123682\n",
      "Epoch [140/2500],\n",
      " Training Loss: 0.24864082\n",
      "Evaluation Loss: 0.20648113\n",
      "Epoch [141/2500],\n",
      " Training Loss: 0.22050226\n",
      "Evaluation Loss: 0.21483347\n",
      "Epoch [142/2500],\n",
      " Training Loss: 0.21863446\n",
      "Evaluation Loss: 0.22059043\n",
      "Epoch [143/2500],\n",
      " Training Loss: 0.23453532\n",
      "Evaluation Loss: 0.25183973\n",
      "Epoch [144/2500],\n",
      " Training Loss: 0.21539907\n",
      "Evaluation Loss: 0.22211628\n",
      "Epoch [145/2500],\n",
      " Training Loss: 0.22878296\n",
      "Evaluation Loss: 0.24232764\n",
      "Epoch [146/2500],\n",
      " Training Loss: 0.22009262\n",
      "Evaluation Loss: 0.22131995\n",
      "Epoch [147/2500],\n",
      " Training Loss: 0.21606209\n",
      "Evaluation Loss: 0.21788317\n",
      "Epoch [148/2500],\n",
      " Training Loss: 0.23079867\n",
      "Evaluation Loss: 0.21734064\n",
      "Epoch [149/2500],\n",
      " Training Loss: 0.25266960\n",
      "Evaluation Loss: 0.26368287\n",
      "Epoch [150/2500],\n",
      " Training Loss: 0.26300379\n",
      "Evaluation Loss: 0.21831397\n",
      "Epoch [151/2500],\n",
      " Training Loss: 0.23546525\n",
      "Evaluation Loss: 0.22471421\n",
      "Epoch [152/2500],\n",
      " Training Loss: 0.23773063\n",
      "Evaluation Loss: 0.21006984\n",
      "Epoch [153/2500],\n",
      " Training Loss: 0.24735200\n",
      "Evaluation Loss: 0.21751620\n",
      "Epoch [154/2500],\n",
      " Training Loss: 0.23237614\n",
      "Evaluation Loss: 0.19923119\n",
      "Epoch [155/2500],\n",
      " Training Loss: 0.23600232\n",
      "Evaluation Loss: 0.20419537\n",
      "Epoch [156/2500],\n",
      " Training Loss: 0.23692144\n",
      "Evaluation Loss: 0.20361198\n",
      "Epoch [157/2500],\n",
      " Training Loss: 0.23474325\n",
      "Evaluation Loss: 0.20537166\n",
      "Epoch [158/2500],\n",
      " Training Loss: 0.22633370\n",
      "Evaluation Loss: 0.19834812\n",
      "Epoch [159/2500],\n",
      " Training Loss: 0.21579891\n",
      "Evaluation Loss: 0.22149110\n",
      "Epoch [160/2500],\n",
      " Training Loss: 0.22385566\n",
      "Evaluation Loss: 0.20729776\n",
      "Epoch [161/2500],\n",
      " Training Loss: 0.22125259\n",
      "Evaluation Loss: 0.20878891\n",
      "Epoch [162/2500],\n",
      " Training Loss: 0.21291231\n",
      "Evaluation Loss: 0.20976920\n",
      "Epoch [163/2500],\n",
      " Training Loss: 0.24236206\n",
      "Evaluation Loss: 0.20833436\n",
      "Epoch [164/2500],\n",
      " Training Loss: 0.21193443\n",
      "Evaluation Loss: 0.20993215\n",
      "Epoch [165/2500],\n",
      " Training Loss: 0.21898088\n",
      "Evaluation Loss: 0.20253120\n",
      "Epoch [166/2500],\n",
      " Training Loss: 0.22080611\n",
      "Evaluation Loss: 0.20675485\n",
      "Epoch [167/2500],\n",
      " Training Loss: 0.23825168\n",
      "Evaluation Loss: 0.19964745\n",
      "Epoch [168/2500],\n",
      " Training Loss: 0.22479642\n",
      "Evaluation Loss: 0.20570940\n",
      "Epoch [169/2500],\n",
      " Training Loss: 0.22043356\n",
      "Evaluation Loss: 0.20538773\n",
      "Epoch [170/2500],\n",
      " Training Loss: 0.22125367\n",
      "Evaluation Loss: 0.20084274\n",
      "Epoch [171/2500],\n",
      " Training Loss: 0.22737394\n",
      "Evaluation Loss: 0.21768305\n",
      "Epoch [172/2500],\n",
      " Training Loss: 0.22783747\n",
      "Evaluation Loss: 0.20762210\n",
      "Epoch [173/2500],\n",
      " Training Loss: 0.21954430\n",
      "Evaluation Loss: 0.21195319\n",
      "Epoch [174/2500],\n",
      " Training Loss: 0.21839585\n",
      "Evaluation Loss: 0.20269202\n",
      "Epoch [175/2500],\n",
      " Training Loss: 0.21654602\n",
      "Evaluation Loss: 0.21900000\n",
      "Epoch [176/2500],\n",
      " Training Loss: 0.23806612\n",
      "Evaluation Loss: 0.21280269\n",
      "Epoch [177/2500],\n",
      " Training Loss: 0.21148166\n",
      "Evaluation Loss: 0.18677284\n",
      "Epoch [178/2500],\n",
      " Training Loss: 0.22162499\n",
      "Evaluation Loss: 0.21863786\n",
      "Epoch [179/2500],\n",
      " Training Loss: 0.24180536\n",
      "Evaluation Loss: 0.20844689\n",
      "Epoch [180/2500],\n",
      " Training Loss: 0.22069275\n",
      "Evaluation Loss: 0.20190509\n",
      "Epoch [181/2500],\n",
      " Training Loss: 0.24133599\n",
      "Evaluation Loss: 0.17996069\n",
      "Epoch [182/2500],\n",
      " Training Loss: 0.22530880\n",
      "Evaluation Loss: 0.20100627\n",
      "Epoch [183/2500],\n",
      " Training Loss: 0.23460561\n",
      "Evaluation Loss: 0.18411218\n",
      "Epoch [184/2500],\n",
      " Training Loss: 0.23462445\n",
      "Evaluation Loss: 0.20179152\n",
      "Epoch [185/2500],\n",
      " Training Loss: 0.21584391\n",
      "Evaluation Loss: 0.19150542\n",
      "Epoch [186/2500],\n",
      " Training Loss: 0.22968058\n",
      "Evaluation Loss: 0.18288504\n",
      "Epoch [187/2500],\n",
      " Training Loss: 0.21653791\n",
      "Evaluation Loss: 0.21099576\n",
      "Epoch [188/2500],\n",
      " Training Loss: 0.20457294\n",
      "Evaluation Loss: 0.20010230\n",
      "Epoch [189/2500],\n",
      " Training Loss: 0.19109992\n",
      "Evaluation Loss: 0.18688643\n",
      "Epoch [190/2500],\n",
      " Training Loss: 0.24811265\n",
      "Evaluation Loss: 0.22698514\n",
      "Epoch [191/2500],\n",
      " Training Loss: 0.21740533\n",
      "Evaluation Loss: 0.22071321\n",
      "Epoch [192/2500],\n",
      " Training Loss: 0.20709892\n",
      "Evaluation Loss: 0.20024347\n",
      "Epoch [193/2500],\n",
      " Training Loss: 0.20869763\n",
      "Evaluation Loss: 0.19209944\n",
      "Epoch [194/2500],\n",
      " Training Loss: 0.21643763\n",
      "Evaluation Loss: 0.21915818\n",
      "Epoch [195/2500],\n",
      " Training Loss: 0.22203230\n",
      "Evaluation Loss: 0.21782110\n",
      "Epoch [196/2500],\n",
      " Training Loss: 0.25700555\n",
      "Evaluation Loss: 0.20696334\n",
      "Epoch [197/2500],\n",
      " Training Loss: 0.21249872\n",
      "Evaluation Loss: 0.18436408\n",
      "Epoch [198/2500],\n",
      " Training Loss: 0.20341879\n",
      "Evaluation Loss: 0.18484418\n",
      "Epoch [199/2500],\n",
      " Training Loss: 0.20313028\n",
      "Evaluation Loss: 0.19362278\n",
      "Epoch [200/2500],\n",
      " Training Loss: 0.20182191\n",
      "Evaluation Loss: 0.18345132\n",
      "Epoch [201/2500],\n",
      " Training Loss: 0.19903639\n",
      "Evaluation Loss: 0.18222216\n",
      "Epoch [202/2500],\n",
      " Training Loss: 0.20128060\n",
      "Evaluation Loss: 0.18297689\n",
      "Epoch [203/2500],\n",
      " Training Loss: 0.19732437\n",
      "Evaluation Loss: 0.15174324\n",
      "Epoch [204/2500],\n",
      " Training Loss: 0.24792931\n",
      "Evaluation Loss: 0.22284597\n",
      "Epoch [205/2500],\n",
      " Training Loss: 0.20797791\n",
      "Evaluation Loss: 0.22145457\n",
      "Epoch [206/2500],\n",
      " Training Loss: 0.21605619\n",
      "Evaluation Loss: 0.22273901\n",
      "Epoch [207/2500],\n",
      " Training Loss: 0.20026635\n",
      "Evaluation Loss: 0.20487164\n",
      "Epoch [208/2500],\n",
      " Training Loss: 0.19885656\n",
      "Evaluation Loss: 0.20595365\n",
      "Epoch [209/2500],\n",
      " Training Loss: 0.21375622\n",
      "Evaluation Loss: 0.20203203\n",
      "Epoch [210/2500],\n",
      " Training Loss: 0.23010287\n",
      "Evaluation Loss: 0.21941912\n",
      "Epoch [211/2500],\n",
      " Training Loss: 0.24581688\n",
      "Evaluation Loss: 0.23665497\n",
      "Epoch [212/2500],\n",
      " Training Loss: 0.21638213\n",
      "Evaluation Loss: 0.21250807\n",
      "Epoch [213/2500],\n",
      " Training Loss: 0.20916065\n",
      "Evaluation Loss: 0.21144947\n",
      "Epoch [214/2500],\n",
      " Training Loss: 0.23148302\n",
      "Evaluation Loss: 0.20716637\n",
      "Epoch [215/2500],\n",
      " Training Loss: 0.18924330\n",
      "Evaluation Loss: 0.18471647\n",
      "Epoch [216/2500],\n",
      " Training Loss: 0.24106325\n",
      "Evaluation Loss: 0.22868193\n",
      "Epoch [217/2500],\n",
      " Training Loss: 0.22867384\n",
      "Evaluation Loss: 0.23426214\n",
      "Epoch [218/2500],\n",
      " Training Loss: 0.21877001\n",
      "Evaluation Loss: 0.22201579\n",
      "Epoch [219/2500],\n",
      " Training Loss: 0.21715289\n",
      "Evaluation Loss: 0.21695879\n",
      "Epoch [220/2500],\n",
      " Training Loss: 0.22093999\n",
      "Evaluation Loss: 0.23291014\n",
      "Epoch [221/2500],\n",
      " Training Loss: 0.23715100\n",
      "Evaluation Loss: 0.20592582\n",
      "Epoch [222/2500],\n",
      " Training Loss: 0.27250365\n",
      "Evaluation Loss: 0.23649447\n",
      "Epoch [223/2500],\n",
      " Training Loss: 0.23215285\n",
      "Evaluation Loss: 0.20151525\n",
      "Epoch [224/2500],\n",
      " Training Loss: 0.21120832\n",
      "Evaluation Loss: 0.21180489\n",
      "Epoch [225/2500],\n",
      " Training Loss: 0.21612252\n",
      "Evaluation Loss: 0.22432072\n",
      "Epoch [226/2500],\n",
      " Training Loss: 0.20689593\n",
      "Evaluation Loss: 0.20676941\n",
      "Epoch [227/2500],\n",
      " Training Loss: 0.19171705\n",
      "Evaluation Loss: 0.21424454\n",
      "Epoch [228/2500],\n",
      " Training Loss: 0.19589330\n",
      "Evaluation Loss: 0.18928086\n",
      "Epoch [229/2500],\n",
      " Training Loss: 0.21000203\n",
      "Evaluation Loss: 0.22362796\n",
      "Epoch [230/2500],\n",
      " Training Loss: 0.21788253\n",
      "Evaluation Loss: 0.21580971\n",
      "Epoch [231/2500],\n",
      " Training Loss: 0.22300026\n",
      "Evaluation Loss: 0.21268009\n",
      "Epoch [232/2500],\n",
      " Training Loss: 0.21509480\n",
      "Evaluation Loss: 0.19854516\n",
      "Epoch [233/2500],\n",
      " Training Loss: 0.17125530\n",
      "Evaluation Loss: 0.20105101\n",
      "Epoch [234/2500],\n",
      " Training Loss: 0.20310092\n",
      "Evaluation Loss: 0.21352605\n",
      "Epoch [235/2500],\n",
      " Training Loss: 0.18638273\n",
      "Evaluation Loss: 0.18689632\n",
      "Epoch [236/2500],\n",
      " Training Loss: 0.19578764\n",
      "Evaluation Loss: 0.20283447\n",
      "Epoch [237/2500],\n",
      " Training Loss: 0.19891243\n",
      "Evaluation Loss: 0.21456801\n",
      "Epoch [238/2500],\n",
      " Training Loss: 0.18589698\n",
      "Evaluation Loss: 0.20373199\n",
      "Epoch [239/2500],\n",
      " Training Loss: 0.18427582\n",
      "Evaluation Loss: 0.20240487\n",
      "Epoch [240/2500],\n",
      " Training Loss: 0.20768249\n",
      "Evaluation Loss: 0.17940119\n",
      "Epoch [241/2500],\n",
      " Training Loss: 0.18916749\n",
      "Evaluation Loss: 0.24365652\n",
      "Epoch [242/2500],\n",
      " Training Loss: 0.24269997\n",
      "Evaluation Loss: 0.22740084\n",
      "Epoch [243/2500],\n",
      " Training Loss: 0.21653719\n",
      "Evaluation Loss: 0.23563001\n",
      "Epoch [244/2500],\n",
      " Training Loss: 0.19874315\n",
      "Evaluation Loss: 0.21608419\n",
      "Epoch [245/2500],\n",
      " Training Loss: 0.20943212\n",
      "Evaluation Loss: 0.23451582\n",
      "Epoch [246/2500],\n",
      " Training Loss: 0.19984723\n",
      "Evaluation Loss: 0.22095741\n",
      "Epoch [247/2500],\n",
      " Training Loss: 0.23020015\n",
      "Evaluation Loss: 0.25341425\n",
      "Epoch [248/2500],\n",
      " Training Loss: 0.24333089\n",
      "Evaluation Loss: 0.22829329\n",
      "Epoch [249/2500],\n",
      " Training Loss: 0.24004149\n",
      "Evaluation Loss: 0.19589355\n",
      "Epoch [250/2500],\n",
      " Training Loss: 0.19320654\n",
      "Evaluation Loss: 0.18419728\n",
      "Epoch [251/2500],\n",
      " Training Loss: 0.19646213\n",
      "Evaluation Loss: 0.19410534\n",
      "Epoch [252/2500],\n",
      " Training Loss: 0.22187831\n",
      "Evaluation Loss: 0.16301472\n",
      "Epoch [253/2500],\n",
      " Training Loss: 0.20059712\n",
      "Evaluation Loss: 0.23590717\n",
      "Epoch [254/2500],\n",
      " Training Loss: 0.23264631\n",
      "Evaluation Loss: 0.22206589\n",
      "Epoch [255/2500],\n",
      " Training Loss: 0.21555854\n",
      "Evaluation Loss: 0.22762566\n",
      "Epoch [256/2500],\n",
      " Training Loss: 0.20931111\n",
      "Evaluation Loss: 0.21324196\n",
      "Epoch [257/2500],\n",
      " Training Loss: 0.19866854\n",
      "Evaluation Loss: 0.20694017\n",
      "Epoch [258/2500],\n",
      " Training Loss: 0.19067158\n",
      "Evaluation Loss: 0.20782797\n",
      "Epoch [259/2500],\n",
      " Training Loss: 0.22740999\n",
      "Evaluation Loss: 0.18826962\n",
      "Epoch [260/2500],\n",
      " Training Loss: 0.22051251\n",
      "Evaluation Loss: 0.18155169\n",
      "Epoch [261/2500],\n",
      " Training Loss: 0.18960701\n",
      "Evaluation Loss: 0.18753218\n",
      "Epoch [262/2500],\n",
      " Training Loss: 0.19573175\n",
      "Evaluation Loss: 0.22009142\n",
      "Epoch [263/2500],\n",
      " Training Loss: 0.23536904\n",
      "Evaluation Loss: 0.23546371\n",
      "Epoch [264/2500],\n",
      " Training Loss: 0.23143439\n",
      "Evaluation Loss: 0.22425288\n",
      "Epoch [265/2500],\n",
      " Training Loss: 0.21189244\n",
      "Evaluation Loss: 0.21848518\n",
      "Epoch [266/2500],\n",
      " Training Loss: 0.22472510\n",
      "Evaluation Loss: 0.21806507\n",
      "Epoch [267/2500],\n",
      " Training Loss: 0.19329305\n",
      "Evaluation Loss: 0.21389713\n",
      "Epoch [268/2500],\n",
      " Training Loss: 0.19600225\n",
      "Evaluation Loss: 0.22089167\n",
      "Epoch [269/2500],\n",
      " Training Loss: 0.20680161\n",
      "Evaluation Loss: 0.23137955\n",
      "Epoch [270/2500],\n",
      " Training Loss: 0.20137098\n",
      "Evaluation Loss: 0.22643898\n"
     ]
    }
   ],
   "source": [
    "train_losses = []\n",
    "eval_losses = []\n",
    "\n",
    "print(\"[INFO] training the network...\")\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(EPOCHS):\n",
    "    composite_model.train()\n",
    "    running_loss = 0.0\n",
    "    \n",
    "    for graph_batch in train_dataloader:\n",
    "        # inputs_batch, targets_batch, graph_batch = batch\n",
    "                \n",
    "        node_inputs = (graph_batch.x).to(device)\n",
    "        edge_index = graph_batch.edge_index\n",
    "        edge_attr = graph_batch.edge_attr\n",
    "        global_inputs = graph_batch.global_input\n",
    "        targets = (graph_batch.y).to(device)\n",
    "        # global_inputs = inputs_batch[\"time_varying_inputs\"]\n",
    "\n",
    "        node_inputs = node_inputs.to(device)\n",
    "        edge_index = edge_index.to(device)\n",
    "        edge_attr = edge_attr.to(device)\n",
    "        global_inputs = global_inputs.to(device)\n",
    "\n",
    "\n",
    "        # break\n",
    "\n",
    "        # Forward pass\n",
    "        # optimizer_fine_tune_wing.zero_grad()\n",
    "        # optimizer_fine_tune_rotor.zero_grad()\n",
    "\n",
    "        optimizer_composite.zero_grad()\n",
    "        outputs = composite_model(node_inputs, targets, edge_index, edge_attr, global_inputs, BATCH_SIZE, num_nodes = 3)\n",
    "        # print(\"Outputs:\", outputs.shape)\n",
    "        \n",
    "        # break\n",
    "        # print(\"Outputs:\", outputs.shape)\n",
    "        # print(\"Targets:\", targets_batch.shape)\n",
    "        \n",
    "        # Compute loss\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward()\n",
    "\n",
    "        # optimizer_fine_tune_wing.step()\n",
    "        # optimizer_fine_tune_rotor.step()\n",
    "\n",
    "        optimizer_composite.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "    avg_train_loss = running_loss/len(train_dataloader)\n",
    "    train_losses.append(avg_train_loss)\n",
    "\n",
    "    # break\n",
    "    # Evaluation loop\n",
    "    composite_model.eval()\n",
    "    eval_loss = 0.0\n",
    "\n",
    "    with torch.no_grad():\n",
    "\n",
    "        for graph_batch in val_dataloader:\n",
    "            # inputs_batch, targets_batch, graph_batch = batch\n",
    "            \n",
    "            \n",
    "            node_inputs = (graph_batch.x).to(device)\n",
    "            edge_index = graph_batch.edge_index\n",
    "            edge_attr = graph_batch.edge_attr\n",
    "            global_inputs = graph_batch.global_input\n",
    "            targets = (graph_batch.y).to(device)\n",
    "            # global_inputs = inputs_batch[\"time_varying_inputs\"]\n",
    "\n",
    "            node_inputs = node_inputs.to(device)\n",
    "            edge_index = edge_index.to(device)\n",
    "            edge_attr = edge_attr.to(device)\n",
    "            global_inputs = global_inputs.to(device)\n",
    "\n",
    "            # Forward pass\n",
    "\n",
    "            outputs = composite_model(node_inputs, targets, edge_index, edge_attr, global_inputs, BATCH_SIZE, num_nodes = 3)   \n",
    "\n",
    "            # Compute loss\n",
    "            loss = criterion(outputs, targets)\n",
    "\n",
    "            eval_loss += loss.item()\n",
    "\n",
    "        avg_eval_loss = eval_loss / len(val_dataloader)\n",
    "        eval_losses.append(avg_eval_loss)\n",
    "\n",
    "\n",
    "    \n",
    "    print(f'Epoch [{epoch+1}/{EPOCHS}],\\n Training Loss: {running_loss/len(train_dataloader):.8f}')\n",
    "    print(f'Evaluation Loss: {eval_loss/len(val_dataloader):.8f}')\n",
    "\n",
    "    \n",
    "\n",
    "print(\"[INFO] Finished training the network...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the training and evaluation losses\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot((train_losses), label='Training Loss')\n",
    "plt.plot((eval_losses), label='Evaluation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training and Evaluation Losses Over Epochs')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "date = datetime.date.today()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save_path =  '/mnt/e/eVTOL_model/eVTOL-VehicleModel/trained_models/models/vehicle/{}_sim_aircraftModel_MSELoss_lr{}_e{}_hidDim{}.pth'.format(date, LEARNING_RATE, EPOCHS, hidden_dim)\n",
    "# print(\"The model will be saved as the following:\\n {}\".format(save_path))\n",
    "\n",
    "\n",
    "# torch.save(prop_model.state_dict(), save_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " \n",
    "from sklearn.metrics import mean_squared_error \n",
    "\n",
    "root_test_base = '/mnt/e/eVTOL_model/eVTOL-VehicleModel/FLOWUnsteady_simulations/aircraft_data/testing_data/'\n",
    "batch_size_test = 1\n",
    "\n",
    "for simulation_case in os.listdir(root_test_base):\n",
    "\n",
    "    root_test_dir = root_test_base+simulation_case\n",
    "\n",
    "    # Canard dataset\n",
    "    dataset_canard_test = WingDataset(root_test_dir, \n",
    "                                    af_model_ESCNN_Cl=af_model_ESCNN_Cl, \n",
    "                                    af_model_ESCNN_Cd=af_model_ESCNN_Cd,\n",
    "                                    airfoil_cl=airfoil_cl, \n",
    "                                    airfoil_cd=airfoil_cd, \n",
    "                                    device=device,\n",
    "                                    wing_name = 'Canard',     # select 'wing_main' or 'Canard'  \n",
    "                                    subdir_condition=subdir_condition_wing)\n",
    "\n",
    "    inputs_canard_test, outputs_canard_test = dataset_canard_test[0:]\n",
    "\n",
    "    input_tensor_canard_test = inputs_canard_test\n",
    "    input_tensor_canard_test = inputs_canard_test.squeeze(1)  # Reshaping\n",
    "    # print(\"Input shape (Canard dataset):\", input_tensor_canard.shape)\n",
    "    output_tensor_canard_test = outputs_canard_test.squeeze(1)\n",
    "    # print(\"Output shape (Canard dataset):\",output_tensor_canard.shape) \n",
    "\n",
    "\n",
    "    # dataset - Rotor L1\n",
    "    dataset_rotor_L1_test = PropellerDataset(root_test_dir,\n",
    "                            rotor_notation = 'L1',                       # Select: L1, L2, L3, L4, R1, R2, R3, R4\n",
    "                            subdir_condition=subdir_condition_rotor)\n",
    "    inputs_rL1_test, outputs_rL1_test = dataset_rotor_L1_test[0:]\n",
    "\n",
    "    input_tensor_rL1_test = inputs_rL1_test.squeeze(1)  # Reshaping\n",
    "    # print(\"Input shape (rotor - L1):\", input_tensor_rL1.shape) \n",
    "    output_tensor_rL1_test = outputs_rL1_test.squeeze(1)\n",
    "    # print(\"Output shape (rotor - L1):\",output_tensor_rL1.shape)\n",
    "\n",
    "\n",
    "    # dataset - Rotor R1\n",
    "    dataset_rotor_R1_test = PropellerDataset(root_test_dir,\n",
    "                            rotor_notation = 'R1',                       # Select: L1, L2, L3, L4, R1, R2, R3, R4\n",
    "                            subdir_condition=subdir_condition_rotor)\n",
    "    inputs_rR1_test, outputs_rR1_test = dataset_rotor_R1_test[0:]\n",
    "\n",
    "    input_tensor_rR1_test = inputs_rR1_test.squeeze(1)  # Reshaping\n",
    "    # print(\"Input shape (rotor - R1):\", input_tensor_rR1.shape) \n",
    "    output_tensor_rR1_test = outputs_rR1_test.squeeze(1)\n",
    "    # print(\"Output shape (rotor - R1):\",output_tensor_rR1.shape) \n",
    "\n",
    "    dataset_aircraft_test = AircraftDataset(dataset_canard_test,\n",
    "                                            dataset_rotor_L1_test,\n",
    "                                            dataset_rotor_R1_test,\n",
    "                                            input_scaler_wing_stat,\n",
    "                                            input_scaler_rotor,\n",
    "                                            output_scaler_wing_stat,\n",
    "                                            output_scaler_rotor)\n",
    "\n",
    "    # combined_dataset_test = GraphDataset(dataset_aircraft_test)\n",
    "\n",
    "    # inputs_test, targets_test, graph_test = combined_dataset_test[0]\n",
    "\n",
    "    # targets_test = targets_test.to(device)\n",
    "\n",
    "    # node_inputs_test = (graph_test.x).to(device)\n",
    "    # edge_index_test = (graph_test.edge_index).to(device)\n",
    "    # edge_attr_test = (graph_test.edge_attr).to(device)\n",
    "    # global_inputs_test = (inputs_test[\"time_varying_inputs\"]).to(device)\n",
    "    # global_inputs_test = global_inputs_test.unsqueeze(0)\n",
    "\n",
    "    graph_dataset_test = GraphDataset(dataset_aircraft_test)\n",
    "\n",
    "    graph_dataset_test = graph_dataset_test[0]\n",
    "\n",
    "    node_inputs_test = (graph_dataset_test.x).to(device)\n",
    "    edge_index_test = (graph_dataset_test.edge_index).to(device)\n",
    "    edge_attr_test = (graph_dataset_test.edge_attr).to(device)\n",
    "    global_inputs_test = (graph_dataset_test.global_input).to(device)\n",
    "    targets_test = (graph_dataset_test.y).to(device)\n",
    "    \n",
    "\n",
    "    composite_model.eval()  # Set the model to evaluation mode\n",
    "\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs_predicted = composite_model(node_inputs_test, targets_test, edge_index_test,\n",
    "                                             edge_attr_test, global_inputs_test,\n",
    "                                             batch_size_test, num_nodes=3)\n",
    "\n",
    "    \n",
    "    \n",
    "    outputs_predicted = outputs_predicted.cpu().detach().numpy()  # Convert tensor to numpy array\n",
    "    outputs_predicted = outputs_predicted.squeeze(0)\n",
    "\n",
    "    predicted_outputs_wing = outputs_predicted[:, 4:]\n",
    "    predicted_outputs_rotor_L1 = outputs_predicted[:, 0:2]\n",
    "    predicted_outputs_rotor_R1 = outputs_predicted[:, 2:4]\n",
    "    \n",
    "    predicted_outputs_wing_og_scl = output_scaler_wing_stat.inverse_transform(predicted_outputs_wing)\n",
    "    predicted_outputs_rotor_L1_og_scl = output_scaler_rotor.inverse_transform(predicted_outputs_rotor_L1)\n",
    "    predicted_outputs_rotor_R1_og_scl = output_scaler_rotor.inverse_transform(predicted_outputs_rotor_R1)\n",
    "\n",
    "\n",
    "    time_steps = (global_inputs_test.squeeze(0))[:,0]\n",
    "\n",
    "    cl_wing_NN = predicted_outputs_wing_og_scl[:, 0]\n",
    "    cd_wing_NN = predicted_outputs_wing_og_scl[:, 1]\n",
    "\n",
    "    # fft_ct_nn_real_L1 = predicted_outputs_rotor_L1_og_scl[:, 0]\n",
    "    # fft_cq_nn_real_L1 = predicted_outputs_rotor_L1_og_scl[:, 2]\n",
    "    \n",
    "    # fft_ct_nn_imag_L1 = predicted_outputs_rotor_L1_og_scl[:, 1]\n",
    "    # fft_cq_nn_imag_L1 = predicted_outputs_rotor_L1_og_scl[:, 3]\n",
    "\n",
    "    # complex_ct_nn_L1 = fft_ct_nn_real_L1 + (1j * fft_ct_nn_imag_L1)\n",
    "    # ct_test_NN_L1 = ifft(complex_ct_nn_L1)\n",
    "\n",
    "    # complex_cq_nn_L1 = fft_cq_nn_real_L1 + (1j * fft_cq_nn_imag_L1)\n",
    "    # cq_test_NN_L1 = ifft(complex_cq_nn_L1)\n",
    "\n",
    "    ct_test_NN_L1 = predicted_outputs_rotor_L1_og_scl[:, 0]\n",
    "    cq_test_NN_L1 = predicted_outputs_rotor_L1_og_scl[:, 1]\n",
    "\n",
    "\n",
    "    # fft_ct_nn_real_R1 = predicted_outputs_rotor_R1_og_scl[:, 0]\n",
    "    # fft_cq_nn_real_R1 = predicted_outputs_rotor_R1_og_scl[:, 2]\n",
    "    \n",
    "    # fft_ct_nn_imag_R1 = predicted_outputs_rotor_R1_og_scl[:, 1]\n",
    "    # fft_cq_nn_imag_R1 = predicted_outputs_rotor_R1_og_scl[:, 3]\n",
    "\n",
    "    # complex_ct_nn_R1 = fft_ct_nn_real_R1 + (1j * fft_ct_nn_imag_R1)\n",
    "    # ct_test_NN_R1 = ifft(complex_ct_nn_R1)\n",
    "\n",
    "    # complex_cq_nn_R1 = fft_cq_nn_real_R1 + (1j * fft_cq_nn_imag_R1)\n",
    "    # cq_test_NN_R1 = ifft(complex_cq_nn_R1)\n",
    "\n",
    "    ct_test_NN_R1 = predicted_outputs_rotor_R1_og_scl[:, 0]\n",
    "    cq_test_NN_R1 = predicted_outputs_rotor_R1_og_scl[:, 1]\n",
    "    \n",
    "\n",
    "    cl_test_flowuns_wing = dataset_canard_test.get_variable('CL')\n",
    "    cd_test_flowuns_wing = dataset_canard_test.get_variable('CD')\n",
    "    ct_test_flowuns_L1 = dataset_rotor_L1_test.get_variable('CT')\n",
    "    cq_test_flowuns_L1 = dataset_rotor_L1_test.get_variable('CQ')\n",
    "    ct_test_flowuns_R1 = dataset_rotor_R1_test.get_variable('CT')\n",
    "    cq_test_flowuns_R1 = dataset_rotor_R1_test.get_variable('CQ')\n",
    "\n",
    "\n",
    "    # mse_wing_cl = mean_squared_error(cl_wing_NN[5:], cl_test_flowuns_wing[0][5:277])\n",
    "    # mse_wing_cl = mean_squared_error(cd_wing_NN[5:], cd_test_flowuns_wing[0][5:277])\n",
    "\n",
    "    # mse_ct_L1 = mean_squared_error(ct_test_NN_L1[5:], ct_test_flowuns_L1[0][5:277])\n",
    "    # mse_cq_L1 = mean_squared_error(cq_test_NN_L1[5:], cq_test_flowuns_L1[0][5:277])\n",
    "\n",
    "    # mse_ct_R1 = mean_squared_error(ct_test_NN_R1[5:], ct_test_flowuns_R1[0][5:277])\n",
    "    # mse_cq_R1 = mean_squared_error(cq_test_NN_R1[5:], cq_test_flowuns_R1[0][5:277])\n",
    "\n",
    "    # print(\"MSE Wing CL:\", mse_wing_cl)\n",
    "    # print(\"MSE Wing CD:\", mse_wing_cl)\n",
    "    # print(\"MSE CT L1:\", mse_ct_L1)\n",
    "    # print(\"MSE CQ L1:\", mse_cq_L1)\n",
    "    # print(\"MSE CT R1:\", mse_ct_R1)\n",
    "    # print(\"MSE CQ R1:\", mse_cq_R1)\n",
    "\n",
    "\n",
    "    plt.figure(figsize=(15, 5))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(cl_wing_NN, label = 'cl_NN')\n",
    "    plt.plot((cl_test_flowuns_wing[0]), label = 'cl_flowuns')\n",
    "    plt.xlabel('Time [s]')\n",
    "    plt.ylabel('Lift coefficient, $C_L$')\n",
    "    plt.title(simulation_case)\n",
    "    plt.legend()\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(cd_wing_NN, label = 'cd_NN')\n",
    "    plt.plot(cd_test_flowuns_wing[0], label = 'cd_flowuns')\n",
    "    plt.xlabel('Time [s]')\n",
    "    plt.ylabel('Drag coefficient, $C_D$')\n",
    "    plt.title(simulation_case)\n",
    "    plt.legend()\n",
    "\n",
    "\n",
    "    plt.figure(figsize=(15, 5))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(ct_test_NN_L1[5:], label = 'ct_NN')\n",
    "    plt.plot((ct_test_flowuns_L1[0][5:]), label = 'ct_flowuns')\n",
    "    plt.xlabel('Time [s]')\n",
    "    plt.ylabel('Thrust coefficient, $C_T$')\n",
    "    plt.title(simulation_case)\n",
    "    plt.legend()\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(cq_test_NN_L1[5:], label = 'cq_NN')\n",
    "    plt.plot(cq_test_flowuns_L1[0][5:], label = 'cq_flowuns')\n",
    "    plt.xlabel('Time [s]')\n",
    "    plt.ylabel('Torque coefficient, $C_Q$')\n",
    "    plt.title(simulation_case)\n",
    "    plt.legend()\n",
    "\n",
    "    plt.figure(figsize=(15, 5))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(ct_test_NN_R1[5:], label = 'ct_NN')\n",
    "    plt.plot((ct_test_flowuns_R1[0][5:]), label = 'ct_flowuns')\n",
    "    plt.xlabel('Time [s]')\n",
    "    plt.ylabel('Thrust coefficient, $C_T$')\n",
    "    plt.title(simulation_case)\n",
    "    plt.legend()\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(cq_test_NN_R1[5:], label = 'cq_NN')\n",
    "    plt.plot(cq_test_flowuns_R1[0][5:], label = 'cq_flowuns')\n",
    "    plt.xlabel('Time [s]')\n",
    "    plt.ylabel('Torque coefficient, $C_Q$')\n",
    "    plt.title(simulation_case)\n",
    "    plt.legend()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vehicle_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
