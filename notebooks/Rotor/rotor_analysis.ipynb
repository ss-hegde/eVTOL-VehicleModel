{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rotor Model Analysis\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "This Jupyter Notebook is designed to analyze the performance of a pre-trained rotor model using a Long Short-Term Memory (LSTM) neural network. The notebook includes the following steps:\n",
    "\n",
    "1. **Importing Libraries and Setting Up Paths**:\n",
    "    - Essential libraries such as `pandas`, `torch`, `numpy`, and others are imported.\n",
    "    - Paths for project, data, models, and results are defined.\n",
    "\n",
    "2. **Device Configuration**:\n",
    "    - The notebook checks if a GPU is available and sets the device accordingly.\n",
    "\n",
    "3. **Utility Functions and Dataset Class**:\n",
    "    - Utility functions for data processing are imported.\n",
    "    - A custom `PropellerDataset` class is defined to load and preprocess the rotor data.\n",
    "\n",
    "4. **Model Definition and Loading**:\n",
    "    - The LSTM model architecture is defined by extending a base class `LSTMNet_rotor`.\n",
    "    - The trained model and scalers are loaded from the specified paths.\n",
    "\n",
    "5. **Evaluation Functions**:\n",
    "    - Functions to compute evaluation metrics such as Mean Absolute Percentage Error (MAPE) and Relative L2 Norm Error are defined.\n",
    "\n",
    "6. **Testing and Evaluation**:\n",
    "    - The notebook iterates through test cases, loads the test data, and makes predictions using the trained model.\n",
    "    - Evaluation metrics are computed for each test case and results are plotted.\n",
    "    - The overall metrics across all test cases are computed and displayed.\n",
    "\n",
    "7. **Plotting and Saving Results**:\n",
    "    - If enabled, the results are plotted and optionally saved as PDF files.\n",
    "    - The evaluation results are saved to a CSV file if the option is enabled.\n",
    "\n",
    "This notebook provides a comprehensive workflow for evaluating the rotor model's performance and visualizing the results.\n",
    "\n",
    "NOTE - Change the `project_path` before running the notebook!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import torch\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.utils.data import TensorDataset\n",
    "import torch.nn.utils as nn_utils\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "# from torchviz import make_dot\n",
    "from scipy.fftpack import fft, ifft\n",
    "import sys\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import joblib\n",
    "\n",
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "project_path = \"/mnt/e/eVTOL_model/eVTOL-VehicleModel/\"     # path to the project\n",
    "save_path = project_path + \"result/rotor_model/\"            # path to save the result   \n",
    "model_path = project_path + \"trained_models/\"               # path to the saved model and scaler\n",
    "data_path = project_path + \"data/rotor_data/\"                \n",
    "\n",
    "\n",
    "PLOT_RESULT = True     # plot the result\n",
    "SAVE_PLOT = False       # save the plot\n",
    "SAVE_RESULT = False     # save the result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if GPU is available\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the path to the project to the system path\n",
    "sys.path.append(project_path + '/src')\n",
    "\n",
    "\n",
    "# Import necessary functions\n",
    "from utility_functions import downsample_to_35\n",
    "from utility_functions import organize_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Condition function to filter subdirectories\n",
    "def subdir_condition(subdir_name):\n",
    "    \"\"\"\n",
    "    Modify this function to apply a specific filtering logic.\n",
    "    \"\"\"\n",
    "    return subdir_name.startswith('rotor_dataset')  # Change this condition as needed\n",
    "\n",
    "\n",
    "class PropellerDataset(Dataset):\n",
    "    # def __init__(self, root_dir, alpha, J, theta, yaw, tilt, subdir_condition=None):\n",
    "    def __init__(self, root_dir, subdir_condition=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            root_dir (string): Root directory with subdirectories containing CSV files.\n",
    "            alpha (float): Angle of attack.\n",
    "            J (float): Advance ratio.\n",
    "            theta (float): Pitch.\n",
    "            yaw (float): Yaw.\n",
    "            tilt (float): Tilt.\n",
    "            subdir_condition (callable, optional): A function or condition to filter subdirectories by name.\n",
    "        \"\"\"\n",
    "        self.root_dir = root_dir\n",
    "        self.data = []\n",
    "        self.targets = []\n",
    "        self.time_data = []  # Store time data separately\n",
    "        self.omega_data = []  # Store omega (RPM) separately\n",
    "        self.ct_data = []\n",
    "        self.cq_data = []\n",
    "        self.fft_ct_r = []\n",
    "        self.fft_ct_i = []\n",
    "        self.fft_cq_r = []\n",
    "        self.fft_cq_i = []\n",
    "        self.subdir_condition = subdir_condition\n",
    "\n",
    "        # Traverse the root directory to gather data\n",
    "        self._load_data()\n",
    "\n",
    "    def _load_data(self):\n",
    "        \"\"\"\n",
    "        Helper function to read CSV files from each subdirectory and extract relevant columns.\n",
    "        \"\"\"\n",
    "        # Iterate through each subdirectory in the root directory\n",
    "        for subdir, _, files in os.walk(self.root_dir):\n",
    "            subdir_name = os.path.basename(subdir)\n",
    "            \n",
    "            # Apply subdirectory name condition\n",
    "            if self.subdir_condition and not self.subdir_condition(subdir_name):\n",
    "                continue\n",
    "\n",
    "            for file in files:\n",
    "                if file.endswith(\"_convergence.csv\"):\n",
    "                    # Load the CSV file\n",
    "                    csv_path = os.path.join(subdir, file)\n",
    "                    df = pd.read_csv(csv_path)\n",
    "                    # df = df[(df['ref age (deg)']) < 1800]\n",
    "                    # print(\"Length:\",len(df))\n",
    "                    \n",
    "                    # Extract necessary columns for input features\n",
    "                    time = df['T'].values  # Time\n",
    "                    omega = df['RPM_1'].values  # RPM\n",
    "                    J = df['J'].values\n",
    "                    AOA = df['AOA'].values\n",
    "                    v_inf = df['v_inf'].values\n",
    "                    pitch = df['Pitch (blade)'].values\n",
    "                    tilt = df['Tilt'].values\n",
    "                    yaw = df['Yaw'].values\n",
    "                    ref_angle = df['ref age (deg)'].values\n",
    "\n",
    "                    # Store time and omega in separate lists for easy access\n",
    "                    self.time_data.append(time)\n",
    "                    self.omega_data.append(omega)\n",
    "                    \n",
    "                    # Extract CT and CQ as output variables\n",
    "                    ct = df['CT_1'].values  # Thrust coefficient (CT)\n",
    "                    cq = df['CQ_1'].values  # Torque coefficient (CQ)\n",
    "\n",
    "                    fft_ct = fft(ct)\n",
    "                    fft_ct_real = np.real(fft_ct)\n",
    "                    fft_ct_imag = np.imag(fft_ct)\n",
    "\n",
    "                    fft_cq = fft(cq)\n",
    "                    fft_cq_real = np.real(fft_cq)\n",
    "                    fft_cq_imag = np.imag(fft_cq)\n",
    "\n",
    "                    \n",
    "                    # Store ct and cq in separate lists for easy access\n",
    "                    self.ct_data.append(ct)\n",
    "                    self.cq_data.append(cq)\n",
    "                    self.fft_ct_r.append(fft_ct_real)\n",
    "                    self.fft_ct_i.append(fft_ct_imag)\n",
    "                    self.fft_cq_r.append(fft_cq_real)\n",
    "                    self.fft_cq_i.append(fft_cq_imag)\n",
    "\n",
    "                    # For each simulation, the input sequence is structured as (n_timesteps, n_features)\n",
    "                    sequence_inputs = []\n",
    "                    sequence_outputs = []\n",
    "                    for i in range(len(time)):\n",
    "                        # Each time step has time, omega, and predefined variables: alpha, J, theta, yaw, tilt\n",
    "                        input_data = [\n",
    "                            time[i],  omega[i], AOA[i], v_inf[i], (100*np.sin(omega[i]*time[i])), \n",
    "                            (100*np.cos(omega[i]*time[i])), J[i], pitch[i], tilt[i], yaw[i]\n",
    "                        ]\n",
    "                        output_data = [ct[i], cq[i]]\n",
    "                        \n",
    "                        \n",
    "                        sequence_inputs.append(input_data)\n",
    "                        sequence_outputs.append(output_data)\n",
    "\n",
    "                    sequence_inputs = np.array([sequence_inputs], dtype=float)\n",
    "                    sequence_outputs = np.array([sequence_outputs], dtype=float)\n",
    "\n",
    "                    # Append input sequence (n_timesteps, num_features) and output (CT, CQ)\n",
    "                    self.data.append(sequence_inputs)\n",
    "                    self.targets.append(sequence_outputs)  # Append the whole CT and CQ sequences\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"\n",
    "        Returns the total number of sequences in the dataset.\n",
    "        \"\"\"\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"\n",
    "        Returns a single sequence and its targets.\n",
    "        \"\"\"\n",
    "        print(f\"Requested index: {idx}\")\n",
    "        print(f\"Dataset length: {len(self.data)}\")  # Check if idx exceeds this\n",
    "        print(f\"Targets length: {len(self.targets)}\")\n",
    "        \n",
    "        inputs = self.data[idx]  # Input sequence: (n_timesteps, n_features)\n",
    "        targets = self.targets[idx]  # Output: (n_timesteps, 2)\n",
    "        \n",
    "        # return inputs, targets\n",
    "        return torch.tensor(inputs, dtype=torch.float32), torch.tensor(targets, dtype=torch.float32)\n",
    "\n",
    "    def get_variable(self, variable_name):\n",
    "        \"\"\"\n",
    "        Returns a list of arrays for the specified variable.\n",
    "        Args:\n",
    "            'time' - timesteps\n",
    "            'omega' - rotational velocity [RPM]\n",
    "            'CT' - Thrust coefficient\n",
    "            'CQ' - Torque coefficient\n",
    "            'fft_ct_r' - Thrust ccoefficient FFT - real part\n",
    "            'fft_ct_i' - Thrust ccoefficient FFT - imag part\n",
    "            'fft_cq_r' - Torque ccoefficient FFT - real part\n",
    "            'fft_cq_i' - Torque ccoefficient FFT - imag part\n",
    "\n",
    "        \"\"\"\n",
    "        if variable_name == 'time':\n",
    "            return self.time_data  # Return all time steps for each simulation\n",
    "        elif variable_name == 'omega':\n",
    "            return self.omega_data  # Return all omega (RPM) values for each simulation\n",
    "        elif variable_name == 'CT':\n",
    "            return self.ct_data \n",
    "        elif variable_name == 'CQ':\n",
    "            return self.cq_data\n",
    "        elif variable_name == 'fft_ct':\n",
    "            return self.fft_ct_r, self.fft_ct_i \n",
    "        elif variable_name == 'fft_cq':\n",
    "            return self.fft_cq_r, self.fft_cq_i  \n",
    "        else:\n",
    "            raise ValueError(f\"Variable {variable_name} not supported.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rotor_model import LSTMNet_rotor\n",
    "\n",
    "input_size = 10\n",
    "hidden_size = 50\n",
    "output_size = 2\n",
    "num_layers = 4\n",
    "\n",
    "class PropModel(LSTMNet_rotor):\n",
    "    def __init__(self):\n",
    "        super(PropModel, self).__init__(input_size, hidden_size, output_size, num_layers)\n",
    "\n",
    "root_rotorModelsTrained = model_path + '/models/rotor/'\n",
    "root_rotorScalersTrained = model_path + '/scalers/rotor/'\n",
    "\n",
    "propeller_model = PropModel()\n",
    "propeller_model.load_state_dict(torch.load(root_rotorModelsTrained + '2025-03-06_scaled_H26FpropModel_lr0.0005_e2500_nL4_numNN50.pth'))\n",
    "propeller_model.to(device)\n",
    "\n",
    "# Load the scalers\n",
    "input_scaler_rotor = joblib.load(root_rotorScalersTrained + '2025-03-06_scaled_H26F_ipScaler_lr0.0005_e2500_nL4_numNN50.pkl')\n",
    "output_scaler_rotor = joblib.load(root_rotorScalersTrained + '2025-03-06_scaled_H26F_opScaler_lr0.0005_e2500_nL4_numNN50.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation functions\n",
    "\n",
    "def mape(y_true, y_pred):\n",
    "    \"\"\"Compute Mean Absolute Percentage Error (MAPE)\"\"\"\n",
    "    mask = y_true != 0  # Avoid division by zero\n",
    "    return np.mean(np.abs((y_true[mask] - y_pred[mask]) / y_true[mask])) * 100\n",
    "\n",
    "def relative_l2_norm(y_true, y_pred):\n",
    "    \"\"\"Compute Relative L2 Norm Error (ε)\"\"\"\n",
    "    mask = y_true != 0  # Avoid division by zero\n",
    "    numerator = np.linalg.norm(y_pred[mask] - y_true[mask], ord=2)  # ||pred - true||_2\n",
    "    denominator = np.linalg.norm(y_true[mask], ord=2)  # ||true||_2\n",
    "    return (numerator / denominator) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "# Root directory where simulation subdirectories are stored\n",
    "root_dir_test_base = data_path + \"testing_data/\"\n",
    "\n",
    "\n",
    "# Initialize lists to store evaluation results\n",
    "mape_ct_list, mape_cq_list = [], []\n",
    "r2_ct_list, r2_cq_list = [], []\n",
    "relative_l2_norm_ct_list, relative_l2_norm_cq_list = [], []\n",
    "case_names = []\n",
    "\n",
    "for simulation_case in os.listdir(root_dir_test_base):\n",
    "    # Root directory where simulation subdirectories are stored\n",
    "    root_dir_test_sim = root_dir_test_base+simulation_case\n",
    "  \n",
    "\n",
    "    # Create the dataset with a subdirectory condition\n",
    "    dataset_test = PropellerDataset(root_dir_test_sim, subdir_condition=subdir_condition)\n",
    "    inputs_test, outputs_test = dataset_test[0:]\n",
    "\n",
    "    # Assuming your input tensor is named `input_tensor`\n",
    "    input_tensor_test = inputs_test.squeeze(1)  # Remove the singleton dimension at index 1\n",
    "    # print(\"Input shape:\", input_tensor_test.shape)  # Should print: torch.Size([6, 145, 7])\n",
    "\n",
    "    output_tensor_test = outputs_test.squeeze(1)\n",
    "    # print(\"Output shape:\",output_tensor_test.shape)\n",
    "\n",
    "    inputs_test_reshaped = input_tensor_test.reshape(-1, input_size)\n",
    "\n",
    "    test_inputs_normalized = input_scaler_rotor.transform(inputs_test_reshaped.reshape(-1, input_size)).reshape(input_tensor_test.shape)\n",
    "\n",
    "    test_inputs_tensor = torch.tensor(test_inputs_normalized, dtype=torch.float32).to(device)\n",
    "\n",
    "    # Make predictions using the trained model\n",
    "    propeller_model.eval()  # Set the model to evaluation mode\n",
    "    with torch.no_grad():\n",
    "        predicted_outputs = propeller_model(test_inputs_tensor)\n",
    "\n",
    "\n",
    "    # Convert the predictions back to numpy and inverse scale the outputs\n",
    "    predicted_outputs = predicted_outputs.cpu().detach().numpy()  # Convert tensor to numpy array\n",
    "    predicted_outputs_original_scale = output_scaler_rotor.inverse_transform(predicted_outputs.reshape(-1, output_size))\n",
    "\n",
    "    # Reshape the predictions to match the original sequence structure if needed\n",
    "    predicted_outputs_original_scale = predicted_outputs_original_scale.reshape(input_tensor_test.shape[0], input_tensor_test.shape[1], output_size)\n",
    "    predicted_outputs_original_scale = predicted_outputs_original_scale[0]\n",
    "\n",
    "    # print(predicted_outputs_original_scale.shape)\n",
    "\n",
    "    # Model predicted values\n",
    "    ct_test_NN = predicted_outputs_original_scale[:,0]\n",
    "    cq_test_NN = predicted_outputs_original_scale[:,1]\n",
    "\n",
    "\n",
    "\n",
    "    # Load timesteps, CT and CQ from FLOWUnsteady simualtions\n",
    "    time_steps = dataset_test.get_variable('time')\n",
    "\n",
    "    ct_test_flowuns = dataset_test.get_variable('CT')\n",
    "    cq_test_flowuns = dataset_test.get_variable('CQ')\n",
    "\n",
    "    fft_ct_fu_real, fft_ct_fu_imag = dataset_test.get_variable('fft_ct')\n",
    "    fft_cq_fu_real, fft_cq_fu_imag = dataset_test.get_variable('fft_cq')\n",
    "\n",
    "\n",
    "    mape_ct = mape(ct_test_flowuns[0], ct_test_NN)\n",
    "    mape_cq = mape(cq_test_flowuns[0], cq_test_NN)\n",
    "    r2_ct = r2_score(ct_test_flowuns[0], ct_test_NN)\n",
    "    r2_cq = r2_score(cq_test_flowuns[0], cq_test_NN)\n",
    "    relative_l2_norm_ct = relative_l2_norm(ct_test_flowuns[0], ct_test_NN)\n",
    "    relative_l2_norm_cq = relative_l2_norm(cq_test_flowuns[0], cq_test_NN)\n",
    "    \n",
    "\n",
    "\n",
    "    # Store results\n",
    "    mape_ct_list.append(mape_ct)\n",
    "    mape_cq_list.append(mape_cq)\n",
    "    r2_ct_list.append(r2_ct)\n",
    "    r2_cq_list.append(r2_cq)\n",
    "    relative_l2_norm_ct_list.append(relative_l2_norm_ct)\n",
    "    relative_l2_norm_cq_list.append(relative_l2_norm_cq)\n",
    "    case_names.append(simulation_case)\n",
    "\n",
    "    # Print metrics for this simulation case\n",
    "    print(f\"Simulation Case: {simulation_case}\")\n",
    "    print(f\"  MAPE Ct: {mape_ct:.2f}%, MAPE Cq: {mape_cq:.2f}%\")\n",
    "    print(f\"  R² Ct: {r2_ct:.4f}, R² Cq: {r2_cq:.4f}\")\n",
    "    print(f\"  ε Ct: {relative_l2_norm_ct:.2f}%, ε Cq: {relative_l2_norm_cq:.2f}%\")\n",
    "\n",
    "\n",
    "\n",
    "    # Plot the results\n",
    "\n",
    "    \n",
    "    if PLOT_RESULT:\n",
    "        plt.figure()\n",
    "        plt.figure(figsize=(15, 5))\n",
    "        legend_labels = simulation_case.split('_')\n",
    "        rpm_label = legend_labels[4]\n",
    "        v_inf_label = legend_labels[6]\n",
    "        tilt = legend_labels[8]\n",
    "        # Plot for Thrust coefficient, $C_T$\n",
    "        plt.subplot(1, 2, 1)\n",
    "        plt.plot(time_steps[0], ct_test_NN, label='Predicted $C_T$', color='black', linestyle='--', linewidth=2)\n",
    "        plt.plot(time_steps[0], ct_test_flowuns[0], label='Actual $C_T$', color='red', linestyle='-', linewidth=2)\n",
    "        plt.xlabel('Time [s]', fontsize=16)\n",
    "        plt.ylabel('Thrust coefficient, $C_T$', fontsize=16)\n",
    "        plt.title(f'Thrust Coefficient Comparison', fontsize=20)\n",
    "        plt.legend(loc='upper center', fontsize=16, title='RPM = {}, $V_{{\\infty}}$ = ${} m/s$, Tilt = ${}^{{\\circ}}$'.format(rpm_label, v_inf_label, tilt), fancybox=True, borderpad=1, title_fontsize='16', ncol=3)\n",
    "        plt.ylim([min(ct_test_NN.min(), ct_test_flowuns[0].min()) - 0.005, max(ct_test_NN.max(), ct_test_flowuns[0].max()) + 0.01])\n",
    "        plt.grid(True, linestyle='--', linewidth=0.5)\n",
    "        \n",
    "        # Plot for Torque coefficient, $C_Q$\n",
    "        plt.subplot(1, 2, 2)\n",
    "        plt.plot(time_steps[0], cq_test_NN, label='Predicted $C_Q$', color='black', linestyle='--', linewidth=2)\n",
    "        plt.plot(time_steps[0], cq_test_flowuns[0], label='Actual $C_Q$', color='red', linestyle='-', linewidth=2)\n",
    "        plt.xlabel('Time [s]', fontsize=16)\n",
    "        plt.ylabel('Torque coefficient, $C_Q$', fontsize=16)\n",
    "        plt.title(f'Torque Coefficient Comparison', fontsize=20)\n",
    "        plt.legend(loc='upper center', fontsize=16, title='RPM = {}, $V_{{\\infty}}$ = ${} m/s$, Tilt = ${}^{{\\circ}}$'.format(rpm_label, v_inf_label, tilt), fancybox=True, borderpad=1, title_fontsize='16', ncol=3)\n",
    "        plt.ylim([min(cq_test_NN.min(), cq_test_flowuns[0].min()) - 0.0002, max(cq_test_NN.max(), cq_test_flowuns[0].max()) + 0.0006])\n",
    "        plt.grid(True, linestyle='--', linewidth=0.5)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        if SAVE_PLOT:\n",
    "            plt.savefig(f\"{save_path}{simulation_case}_comparison.pdf\", format=\"pdf\", dpi=300, bbox_inches=\"tight\")\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "    # plt.show()\n",
    "\n",
    "# Compute average metrics across all test cases\n",
    "print(\"\\nOverall Metrics Across All Test Cases:\")\n",
    "print(f\"  Avg MAPE Ct: {np.mean(mape_ct_list):.2f}%, Avg MAPE Cq: {np.mean(mape_cq_list):.2f}%\")\n",
    "print(f\"  Avg R² Ct: {np.mean(r2_ct_list):.4f}, Avg R² Cq: {np.mean(r2_cq_list):.4f}\")\n",
    "print(f\"  Avg ε Ct: {np.mean(relative_l2_norm_ct_list):.2f}%, Avg ε Cq: {np.mean(relative_l2_norm_cq_list):.2f}%\")\n",
    "\n",
    "if SAVE_RESULT:\n",
    "    # Convert results to a DataFrame\n",
    "    results_df = pd.DataFrame({\n",
    "        \"Case\": case_names,\n",
    "        \"Relative L2 Norm CT (%)\": relative_l2_norm_ct_list,\n",
    "        \"Relative L2 Norm CQ (%)\": relative_l2_norm_cq_list,\n",
    "        \"MAPE CT (%)\": mape_ct_list,\n",
    "        \"MAPE CQ (%)\": mape_cq_list,\n",
    "        \"R² CT\": r2_ct_list,\n",
    "        \"R² CQ\": r2_cq_list\n",
    "    })\n",
    "\n",
    "    # Append mean values to the DataFrame\n",
    "    mean_row = pd.DataFrame({\n",
    "        \"Case\": [\"Mean\"], \n",
    "        \"Relative L2 Norm CT (%)\": np.mean(relative_l2_norm_ct_list),\n",
    "        \"Relative L2 Norm CQ (%)\": np.mean(relative_l2_norm_cq_list),\n",
    "        \"MAPE CT (%)\": np.mean(mape_ct_list),\n",
    "        \"MAPE CQ (%)\": np.mean(mape_cq_list),\n",
    "        \"R² CT\": np.mean(r2_ct_list),\n",
    "        \"R² CQ\": np.mean(r2_cq_list)\n",
    "    })\n",
    "\n",
    "    results_df = pd.concat([results_df, mean_row], ignore_index=True)\n",
    "\n",
    "    # Define CSV file path\n",
    "    csv_filename = os.path.join(save_path, \"rotorModel_evaluation_results.csv\")\n",
    "\n",
    "    # Save to CSV\n",
    "    results_df.to_csv(csv_filename, index=False)\n",
    "\n",
    "    print(f\"Results (including mean values) saved to {csv_filename}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vehicle_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
